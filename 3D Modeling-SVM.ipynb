{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in standard packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in ML packages/modules\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bwils\\anaconda3\\envs\\pumpitup\\lib\\site-packages\\distributed\\node.py:151: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 60205 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Scheduler: \"tcp://127.0.0.1:60208\" processes: 3 cores: 6>,\n",
       " {0: <Nanny: tcp://127.0.0.1:60234, threads: 2>,\n",
       "  1: <Nanny: tcp://127.0.0.1:60228, threads: 2>,\n",
       "  2: <Nanny: tcp://127.0.0.1:60231, threads: 2>})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in dask package and set up to allow for faster compute times. Distributes computing among all available preocessors\n",
    "from dask import dataframe as dd\n",
    "import joblib\n",
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "cluster.scheduler, cluster.workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in training/testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in train/test data\n",
    "train_X = pd.read_pickle('Data/train_test/train_X.pkl')\n",
    "test_X = pd.read_pickle('Data/train_test/test_X.pkl')\n",
    "train_y = pd.read_pickle('Data/train_test/train_y.pkl')\n",
    "test_y = pd.read_pickle('Data/train_test/test_y.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y.map({'functional':2, 'non functional':0, 'functional needs repair':1})\n",
    "test_y = test_y.map({'functional':2, 'non functional':0, 'functional needs repair':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier\n",
    "\n",
    "We will start with the Random Forest Classifier which is pretty common becuase of it's predicitive power. We will run using all features first and then we can compare the different amount of features to see what performs best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 28.45, NNZs: 369, Bias: -10.216000, T: 44550, Avg. loss: 4.427436\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 18.60, NNZs: 370, Bias: -9.005433, T: 89100, Avg. loss: 1.159706\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 14.88, NNZs: 370, Bias: -8.019181, T: 133650, Avg. loss: 0.853279\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13.18, NNZs: 370, Bias: -7.250066, T: 178200, Avg. loss: 0.734526\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.04, NNZs: 370, Bias: -6.961177, T: 222750, Avg. loss: 0.666873\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 11.39, NNZs: 370, Bias: -6.693199, T: 267300, Avg. loss: 0.627240\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 10.86, NNZs: 370, Bias: -6.366267, T: 311850, Avg. loss: 0.598769\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 10.17, NNZs: 370, Bias: -6.395145, T: 356400, Avg. loss: 0.570820\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 9.81, NNZs: 370, Bias: -6.153447, T: 400950, Avg. loss: 0.558382\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 9.74, NNZs: 370, Bias: -5.946030, T: 445500, Avg. loss: 0.544154\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 9.46, NNZs: 370, Bias: -5.887011, T: 490050, Avg. loss: 0.534605\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 9.18, NNZs: 370, Bias: -5.807174, T: 534600, Avg. loss: 0.524342\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 9.04, NNZs: 370, Bias: -5.628186, T: 579150, Avg. loss: 0.516995\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 8.91, NNZs: 370, Bias: -5.530023, T: 623700, Avg. loss: 0.512829\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 8.61, NNZs: 370, Bias: -5.482044, T: 668250, Avg. loss: 0.505768\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 8.48, NNZs: 370, Bias: -5.379980, T: 712800, Avg. loss: 0.501582\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 8.50, NNZs: 370, Bias: -5.258235, T: 757350, Avg. loss: 0.495286\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 8.33, NNZs: 370, Bias: -5.170896, T: 801900, Avg. loss: 0.494616\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 8.19, NNZs: 370, Bias: -5.160504, T: 846450, Avg. loss: 0.490565\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 8.07, NNZs: 370, Bias: -5.090725, T: 891000, Avg. loss: 0.488570\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 8.05, NNZs: 370, Bias: -5.026694, T: 935550, Avg. loss: 0.484730\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 7.95, NNZs: 370, Bias: -5.005673, T: 980100, Avg. loss: 0.483370\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 7.90, NNZs: 370, Bias: -4.964144, T: 1024650, Avg. loss: 0.480879\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 7.82, NNZs: 370, Bias: -4.878530, T: 1069200, Avg. loss: 0.478027\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 7.76, NNZs: 370, Bias: -4.886833, T: 1113750, Avg. loss: 0.476275\n",
      "Total training time: 1.32 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 7.80, NNZs: 370, Bias: -4.755612, T: 1158300, Avg. loss: 0.474616\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 7.67, NNZs: 370, Bias: -4.806437, T: 1202850, Avg. loss: 0.474373\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 7.71, NNZs: 370, Bias: -4.747955, T: 1247400, Avg. loss: 0.472110\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 7.59, NNZs: 370, Bias: -4.754234, T: 1291950, Avg. loss: 0.470285\n",
      "Total training time: 1.51 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 7.50, NNZs: 370, Bias: -4.691693, T: 1336500, Avg. loss: 0.469583\n",
      "Total training time: 1.56 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 7.55, NNZs: 370, Bias: -4.603292, T: 1381050, Avg. loss: 0.468972\n",
      "Total training time: 1.64 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 7.47, NNZs: 370, Bias: -4.603413, T: 1425600, Avg. loss: 0.466742\n",
      "Total training time: 1.69 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 7.47, NNZs: 370, Bias: -4.514128, T: 1470150, Avg. loss: 0.466501\n",
      "Total training time: 1.75 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 7.43, NNZs: 370, Bias: -4.488864, T: 1514700, Avg. loss: 0.464076\n",
      "Total training time: 1.79 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 7.36, NNZs: 370, Bias: -4.515372, T: 1559250, Avg. loss: 0.465124\n",
      "Total training time: 1.84 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 7.35, NNZs: 370, Bias: -4.464938, T: 1603800, Avg. loss: 0.463134\n",
      "Total training time: 1.90 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 7.32, NNZs: 370, Bias: -4.428695, T: 1648350, Avg. loss: 0.462708\n",
      "Total training time: 1.93 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 7.31, NNZs: 370, Bias: -4.393473, T: 1692900, Avg. loss: 0.461343\n",
      "Total training time: 1.99 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 7.22, NNZs: 370, Bias: -4.445240, T: 1737450, Avg. loss: 0.461000\n",
      "Total training time: 2.04 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 7.25, NNZs: 370, Bias: -4.376889, T: 1782000, Avg. loss: 0.460033\n",
      "Total training time: 2.09 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 7.23, NNZs: 370, Bias: -4.343746, T: 1826550, Avg. loss: 0.459995\n",
      "Total training time: 2.14 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 7.21, NNZs: 370, Bias: -4.343409, T: 1871100, Avg. loss: 0.459420\n",
      "Total training time: 2.19 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 7.22, NNZs: 370, Bias: -4.316520, T: 1915650, Avg. loss: 0.459104\n",
      "Total training time: 2.24 seconds.\n",
      "Convergence after 43 epochs took 2.24 seconds\n",
      "-- Epoch 1\n",
      "Norm: 19.31, NNZs: 361, Bias: -16.119804, T: 44550, Avg. loss: 1.886274\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.54, NNZs: 363, Bias: -13.571332, T: 89100, Avg. loss: 0.467804\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 11.42, NNZs: 365, Bias: -12.414376, T: 133650, Avg. loss: 0.337432\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 10.01, NNZs: 366, Bias: -11.366026, T: 178200, Avg. loss: 0.287943\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.94, NNZs: 366, Bias: -10.815506, T: 222750, Avg. loss: 0.257242\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 8.35, NNZs: 367, Bias: -10.328867, T: 267300, Avg. loss: 0.237277\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 7.74, NNZs: 367, Bias: -10.082213, T: 311850, Avg. loss: 0.227119\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 7.52, NNZs: 367, Bias: -9.632717, T: 356400, Avg. loss: 0.214862\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 7.11, NNZs: 367, Bias: -9.370505, T: 400950, Avg. loss: 0.207220\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 6.72, NNZs: 368, Bias: -9.249557, T: 445500, Avg. loss: 0.201361\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 6.55, NNZs: 368, Bias: -8.994165, T: 490050, Avg. loss: 0.196526\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 6.35, NNZs: 368, Bias: -8.800714, T: 534600, Avg. loss: 0.192306\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 6.11, NNZs: 368, Bias: -8.692548, T: 579150, Avg. loss: 0.189316\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 5.93, NNZs: 368, Bias: -8.524561, T: 623700, Avg. loss: 0.186193\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 5.82, NNZs: 368, Bias: -8.324378, T: 668250, Avg. loss: 0.183332\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 5.64, NNZs: 368, Bias: -8.252331, T: 712800, Avg. loss: 0.180591\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 5.48, NNZs: 368, Bias: -8.156373, T: 757350, Avg. loss: 0.179020\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 5.47, NNZs: 368, Bias: -7.976469, T: 801900, Avg. loss: 0.176879\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 5.37, NNZs: 368, Bias: -7.869052, T: 846450, Avg. loss: 0.175178\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 5.17, NNZs: 368, Bias: -7.824102, T: 891000, Avg. loss: 0.174029\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 5.10, NNZs: 368, Bias: -7.746442, T: 935550, Avg. loss: 0.172432\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 5.02, NNZs: 368, Bias: -7.651533, T: 980100, Avg. loss: 0.171843\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 5.00, NNZs: 368, Bias: -7.541841, T: 1024650, Avg. loss: 0.170315\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 4.88, NNZs: 368, Bias: -7.474475, T: 1069200, Avg. loss: 0.169139\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 4.83, NNZs: 368, Bias: -7.400918, T: 1113750, Avg. loss: 0.167911\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 4.74, NNZs: 368, Bias: -7.339296, T: 1158300, Avg. loss: 0.167474\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 4.73, NNZs: 368, Bias: -7.254508, T: 1202850, Avg. loss: 0.166115\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 4.64, NNZs: 368, Bias: -7.205687, T: 1247400, Avg. loss: 0.166181\n",
      "Total training time: 1.28 seconds.\n",
      "-- Epoch 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 4.61, NNZs: 368, Bias: -7.134967, T: 1291950, Avg. loss: 0.164830\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4.51, NNZs: 368, Bias: -7.104091, T: 1336500, Avg. loss: 0.164279\n",
      "Total training time: 1.38 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 4.51, NNZs: 368, Bias: -7.037519, T: 1381050, Avg. loss: 0.163424\n",
      "Total training time: 1.43 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 4.48, NNZs: 368, Bias: -6.966580, T: 1425600, Avg. loss: 0.162889\n",
      "Total training time: 1.48 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 4.42, NNZs: 368, Bias: -6.938782, T: 1470150, Avg. loss: 0.162525\n",
      "Total training time: 1.51 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 4.37, NNZs: 368, Bias: -6.897883, T: 1514700, Avg. loss: 0.162220\n",
      "Total training time: 1.57 seconds.\n",
      "Convergence after 34 epochs took 1.57 seconds\n",
      "-- Epoch 1\n",
      "Norm: 27.77, NNZs: 370, Bias: 3.012093, T: 44550, Avg. loss: 5.153504\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 18.79, NNZs: 370, Bias: 2.172743, T: 89100, Avg. loss: 1.337379\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 14.94, NNZs: 370, Bias: 2.197125, T: 133650, Avg. loss: 0.991283\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13.52, NNZs: 370, Bias: 1.955434, T: 178200, Avg. loss: 0.856413\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12.31, NNZs: 370, Bias: 2.105945, T: 222750, Avg. loss: 0.772628\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 11.72, NNZs: 370, Bias: 1.902770, T: 267300, Avg. loss: 0.728804\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 10.80, NNZs: 370, Bias: 2.038271, T: 311850, Avg. loss: 0.699297\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 10.45, NNZs: 370, Bias: 1.913322, T: 356400, Avg. loss: 0.675114\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 9.99, NNZs: 370, Bias: 1.887658, T: 400950, Avg. loss: 0.656035\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 9.70, NNZs: 370, Bias: 1.769227, T: 445500, Avg. loss: 0.638623\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 9.42, NNZs: 370, Bias: 1.750099, T: 490050, Avg. loss: 0.629115\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 9.30, NNZs: 370, Bias: 1.826694, T: 534600, Avg. loss: 0.618675\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 9.15, NNZs: 370, Bias: 1.701200, T: 579150, Avg. loss: 0.611244\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 8.90, NNZs: 370, Bias: 1.767916, T: 623700, Avg. loss: 0.603175\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 8.88, NNZs: 370, Bias: 1.702757, T: 668250, Avg. loss: 0.598299\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 8.80, NNZs: 370, Bias: 1.688818, T: 712800, Avg. loss: 0.591297\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 8.65, NNZs: 370, Bias: 1.699410, T: 757350, Avg. loss: 0.586911\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 8.61, NNZs: 370, Bias: 1.571917, T: 801900, Avg. loss: 0.584858\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 8.58, NNZs: 370, Bias: 1.692770, T: 846450, Avg. loss: 0.582077\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 8.52, NNZs: 370, Bias: 1.631940, T: 891000, Avg. loss: 0.580107\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 8.41, NNZs: 370, Bias: 1.608540, T: 935550, Avg. loss: 0.573691\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 8.39, NNZs: 370, Bias: 1.558056, T: 980100, Avg. loss: 0.572479\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 8.39, NNZs: 370, Bias: 1.577913, T: 1024650, Avg. loss: 0.571687\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 8.26, NNZs: 370, Bias: 1.558478, T: 1069200, Avg. loss: 0.567268\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 8.26, NNZs: 370, Bias: 1.495711, T: 1113750, Avg. loss: 0.565899\n",
      "Total training time: 1.32 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 8.20, NNZs: 370, Bias: 1.575350, T: 1158300, Avg. loss: 0.564442\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 8.18, NNZs: 370, Bias: 1.564897, T: 1202850, Avg. loss: 0.562843\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 8.16, NNZs: 370, Bias: 1.547464, T: 1247400, Avg. loss: 0.560977\n",
      "Total training time: 1.49 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 8.16, NNZs: 370, Bias: 1.507431, T: 1291950, Avg. loss: 0.559979\n",
      "Total training time: 1.54 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 8.09, NNZs: 370, Bias: 1.447832, T: 1336500, Avg. loss: 0.557953\n",
      "Total training time: 1.59 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 8.08, NNZs: 370, Bias: 1.420881, T: 1381050, Avg. loss: 0.555673\n",
      "Total training time: 1.63 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 8.04, NNZs: 370, Bias: 1.458040, T: 1425600, Avg. loss: 0.555690\n",
      "Total training time: 1.69 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 8.00, NNZs: 370, Bias: 1.465378, T: 1470150, Avg. loss: 0.553643\n",
      "Total training time: 1.74 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 7.92, NNZs: 370, Bias: 1.459568, T: 1514700, Avg. loss: 0.553138\n",
      "Total training time: 1.82 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 7.95, NNZs: 370, Bias: 1.453565, T: 1559250, Avg. loss: 0.551911\n",
      "Total training time: 1.88 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 7.89, NNZs: 370, Bias: 1.447307, T: 1603800, Avg. loss: 0.551457\n",
      "Total training time: 1.92 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 7.87, NNZs: 370, Bias: 1.404786, T: 1648350, Avg. loss: 0.549804\n",
      "Total training time: 1.99 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 7.86, NNZs: 370, Bias: 1.399821, T: 1692900, Avg. loss: 0.549384\n",
      "Total training time: 2.04 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 7.83, NNZs: 370, Bias: 1.377681, T: 1737450, Avg. loss: 0.548927\n",
      "Total training time: 2.09 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 7.84, NNZs: 370, Bias: 1.379197, T: 1782000, Avg. loss: 0.547493\n",
      "Total training time: 2.13 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 7.76, NNZs: 370, Bias: 1.456352, T: 1826550, Avg. loss: 0.546098\n",
      "Total training time: 2.19 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 7.80, NNZs: 370, Bias: 1.385542, T: 1871100, Avg. loss: 0.546702\n",
      "Total training time: 2.24 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 7.78, NNZs: 370, Bias: 1.375577, T: 1915650, Avg. loss: 0.545733\n",
      "Total training time: 2.29 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 7.75, NNZs: 370, Bias: 1.366017, T: 1960200, Avg. loss: 0.545161\n",
      "Total training time: 2.33 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 7.77, NNZs: 370, Bias: 1.396265, T: 2004750, Avg. loss: 0.543641\n",
      "Total training time: 2.40 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 7.76, NNZs: 370, Bias: 1.405856, T: 2049300, Avg. loss: 0.543674\n",
      "Total training time: 2.46 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 7.78, NNZs: 370, Bias: 1.405573, T: 2093850, Avg. loss: 0.542596\n",
      "Total training time: 2.51 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 7.75, NNZs: 370, Bias: 1.363344, T: 2138400, Avg. loss: 0.542529\n",
      "Total training time: 2.57 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 7.72, NNZs: 370, Bias: 1.359135, T: 2182950, Avg. loss: 0.541529\n",
      "Total training time: 2.60 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 7.74, NNZs: 370, Bias: 1.354933, T: 2227500, Avg. loss: 0.541927\n",
      "Total training time: 2.67 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 7.70, NNZs: 370, Bias: 1.385943, T: 2272050, Avg. loss: 0.541152\n",
      "Total training time: 2.72 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 7.70, NNZs: 370, Bias: 1.385587, T: 2316600, Avg. loss: 0.540421\n",
      "Total training time: 2.77 seconds.\n",
      "Convergence after 52 epochs took 2.77 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7482154882154882"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier(verbose=1)\n",
    "with joblib.parallel_backend('dask'):\n",
    "    sgd.fit(train_X, train_y)\n",
    "sgd.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>alpha</th>\n",
       "      <th>average</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>early_stopping</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>eta0</th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>n_iter_no_change</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>penalty</th>\n",
       "      <th>power_t</th>\n",
       "      <th>random_state</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>tol</th>\n",
       "      <th>validation_fraction</th>\n",
       "      <th>verbose</th>\n",
       "      <th>warm_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SGD_OBO</th>\n",
       "      <td>0.748215</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Accuracy   alpha  average class_weight  early_stopping  epsilon  \\\n",
       "SGD_OBO  0.748215  0.0001    False         None           False      0.1   \n",
       "\n",
       "         eta0  fit_intercept  l1_ratio learning_rate  ... n_iter_no_change  \\\n",
       "SGD_OBO   0.0           True      0.15       optimal  ...                5   \n",
       "\n",
       "         n_jobs  penalty power_t random_state  shuffle    tol  \\\n",
       "SGD_OBO    None       l2     0.5         None     True  0.001   \n",
       "\n",
       "         validation_fraction  verbose  warm_start  \n",
       "SGD_OBO                  0.1        1       False  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_deets = pd.DataFrame(sgd.get_params(), index=['SGD_OBO'])\n",
    "sgd_deets.insert(0, value=sgd.score(test_X, test_y), column='Accuracy')\n",
    "sgd_deets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 25.74, NNZs: 369, Bias: -9.740978, T: 44550, Avg. loss: 4.197966\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 17.38, NNZs: 370, Bias: -8.670630, T: 89100, Avg. loss: 1.101210\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 13.83, NNZs: 370, Bias: -7.878063, T: 133650, Avg. loss: 0.829880\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 12.29, NNZs: 370, Bias: -7.260446, T: 178200, Avg. loss: 0.712455\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 11.18, NNZs: 370, Bias: -6.980700, T: 222750, Avg. loss: 0.645683\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10.65, NNZs: 370, Bias: -6.717078, T: 267300, Avg. loss: 0.609503\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 9.95, NNZs: 370, Bias: -6.463749, T: 311850, Avg. loss: 0.581865\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 9.60, NNZs: 370, Bias: -6.256807, T: 356400, Avg. loss: 0.563307\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 9.28, NNZs: 370, Bias: -6.100357, T: 400950, Avg. loss: 0.548146\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 8.90, NNZs: 370, Bias: -6.039653, T: 445500, Avg. loss: 0.536328\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 8.68, NNZs: 370, Bias: -6.008240, T: 490050, Avg. loss: 0.524035\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 8.59, NNZs: 370, Bias: -5.783268, T: 534600, Avg. loss: 0.517388\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 8.42, NNZs: 370, Bias: -5.580337, T: 579150, Avg. loss: 0.510296\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 8.41, NNZs: 370, Bias: -5.536363, T: 623700, Avg. loss: 0.504237\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 8.12, NNZs: 370, Bias: -5.414880, T: 668250, Avg. loss: 0.501923\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 8.02, NNZs: 370, Bias: -5.321167, T: 712800, Avg. loss: 0.497578\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 7.91, NNZs: 370, Bias: -5.267828, T: 757350, Avg. loss: 0.491999\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 7.78, NNZs: 370, Bias: -5.186276, T: 801900, Avg. loss: 0.489814\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 7.72, NNZs: 370, Bias: -5.158857, T: 846450, Avg. loss: 0.486966\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 7.63, NNZs: 370, Bias: -5.109414, T: 891000, Avg. loss: 0.482407\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 7.58, NNZs: 370, Bias: -5.030447, T: 935550, Avg. loss: 0.480781\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 7.48, NNZs: 370, Bias: -4.944033, T: 980100, Avg. loss: 0.478586\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 7.39, NNZs: 370, Bias: -5.000569, T: 1024650, Avg. loss: 0.476000\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 7.39, NNZs: 370, Bias: -4.901987, T: 1069200, Avg. loss: 0.475196\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 7.31, NNZs: 370, Bias: -4.852806, T: 1113750, Avg. loss: 0.473334\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 7.26, NNZs: 370, Bias: -4.852026, T: 1158300, Avg. loss: 0.471443\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 7.21, NNZs: 370, Bias: -4.783306, T: 1202850, Avg. loss: 0.470817\n",
      "Total training time: 1.36 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 7.29, NNZs: 370, Bias: -4.662645, T: 1247400, Avg. loss: 0.468580\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 7.14, NNZs: 370, Bias: -4.716401, T: 1291950, Avg. loss: 0.469066\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 7.15, NNZs: 370, Bias: -4.654652, T: 1336500, Avg. loss: 0.466898\n",
      "Total training time: 1.51 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 7.06, NNZs: 370, Bias: -4.581514, T: 1381050, Avg. loss: 0.467347\n",
      "Total training time: 1.55 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 7.00, NNZs: 370, Bias: -4.628212, T: 1425600, Avg. loss: 0.464023\n",
      "Total training time: 1.61 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 6.99, NNZs: 370, Bias: -4.566067, T: 1470150, Avg. loss: 0.463604\n",
      "Total training time: 1.65 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 6.99, NNZs: 370, Bias: -4.565946, T: 1514700, Avg. loss: 0.462889\n",
      "Total training time: 1.69 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 6.98, NNZs: 370, Bias: -4.496680, T: 1559250, Avg. loss: 0.461366\n",
      "Total training time: 1.75 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 6.90, NNZs: 370, Bias: -4.496625, T: 1603800, Avg. loss: 0.461741\n",
      "Total training time: 1.81 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 6.88, NNZs: 370, Bias: -4.480865, T: 1648350, Avg. loss: 0.460581\n",
      "Total training time: 1.86 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 6.89, NNZs: 370, Bias: -4.439866, T: 1692900, Avg. loss: 0.459593\n",
      "Total training time: 1.91 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 6.86, NNZs: 370, Bias: -4.391260, T: 1737450, Avg. loss: 0.459565\n",
      "Total training time: 1.96 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 6.83, NNZs: 370, Bias: -4.365738, T: 1782000, Avg. loss: 0.458368\n",
      "Total training time: 2.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 6.81, NNZs: 370, Bias: -4.369388, T: 1826550, Avg. loss: 0.457867\n",
      "Total training time: 2.06 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 6.79, NNZs: 370, Bias: -4.311771, T: 1871100, Avg. loss: 0.457830\n",
      "Total training time: 2.09 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 6.77, NNZs: 370, Bias: -4.292161, T: 1915650, Avg. loss: 0.456374\n",
      "Total training time: 2.15 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 6.75, NNZs: 370, Bias: -4.283246, T: 1960200, Avg. loss: 0.456018\n",
      "Total training time: 2.18 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 6.72, NNZs: 370, Bias: -4.281845, T: 2004750, Avg. loss: 0.455880\n",
      "Total training time: 2.23 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 6.70, NNZs: 370, Bias: -4.278765, T: 2049300, Avg. loss: 0.455221\n",
      "Total training time: 2.30 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 6.69, NNZs: 370, Bias: -4.236327, T: 2093850, Avg. loss: 0.454975\n",
      "Total training time: 2.35 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 6.67, NNZs: 370, Bias: -4.180424, T: 2138400, Avg. loss: 0.453789\n",
      "Total training time: 2.39 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 6.65, NNZs: 370, Bias: -4.175479, T: 2182950, Avg. loss: 0.454171\n",
      "Total training time: 2.45 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 6.62, NNZs: 370, Bias: -4.162765, T: 2227500, Avg. loss: 0.453308\n",
      "Total training time: 2.50 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 6.63, NNZs: 370, Bias: -4.156182, T: 2272050, Avg. loss: 0.453090\n",
      "Total training time: 2.55 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 6.61, NNZs: 370, Bias: -4.124616, T: 2316600, Avg. loss: 0.453281\n",
      "Total training time: 2.59 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 6.58, NNZs: 370, Bias: -4.140636, T: 2361150, Avg. loss: 0.452019\n",
      "Total training time: 2.63 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 6.60, NNZs: 370, Bias: -4.102740, T: 2405700, Avg. loss: 0.452367\n",
      "Total training time: 2.67 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 6.59, NNZs: 370, Bias: -4.102280, T: 2450250, Avg. loss: 0.451676\n",
      "Total training time: 2.75 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 6.60, NNZs: 370, Bias: -4.045044, T: 2494800, Avg. loss: 0.451985\n",
      "Total training time: 2.79 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 6.60, NNZs: 370, Bias: -4.039406, T: 2539350, Avg. loss: 0.450996\n",
      "Total training time: 2.83 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 6.59, NNZs: 370, Bias: -4.040433, T: 2583900, Avg. loss: 0.451408\n",
      "Total training time: 2.88 seconds.\n",
      "Convergence after 58 epochs took 2.88 seconds\n",
      "-- Epoch 1\n",
      "Norm: 65.33, NNZs: 369, Bias: -14.920659, T: 44550, Avg. loss: 8.787666\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 38.42, NNZs: 369, Bias: -12.555898, T: 89100, Avg. loss: 1.688397\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 31.84, NNZs: 369, Bias: -11.260181, T: 133650, Avg. loss: 1.140959\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.21, NNZs: 369, Bias: -10.329424, T: 178200, Avg. loss: 0.875835\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23.97, NNZs: 369, Bias: -9.886482, T: 222750, Avg. loss: 0.760543\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.77, NNZs: 369, Bias: -9.482279, T: 267300, Avg. loss: 0.661957\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 20.48, NNZs: 369, Bias: -9.061955, T: 311850, Avg. loss: 0.605259\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 19.19, NNZs: 369, Bias: -8.996069, T: 356400, Avg. loss: 0.565310\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 18.30, NNZs: 369, Bias: -8.591526, T: 400950, Avg. loss: 0.532256\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 17.20, NNZs: 369, Bias: -8.531895, T: 445500, Avg. loss: 0.503790\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 16.44, NNZs: 369, Bias: -8.520342, T: 490050, Avg. loss: 0.481753\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 16.06, NNZs: 369, Bias: -8.079150, T: 534600, Avg. loss: 0.459289\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 15.58, NNZs: 369, Bias: -8.015397, T: 579150, Avg. loss: 0.451374\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 14.98, NNZs: 369, Bias: -7.903899, T: 623700, Avg. loss: 0.430676\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 14.61, NNZs: 369, Bias: -7.863362, T: 668250, Avg. loss: 0.429012\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 14.24, NNZs: 369, Bias: -7.662885, T: 712800, Avg. loss: 0.414674\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 13.94, NNZs: 369, Bias: -7.703592, T: 757350, Avg. loss: 0.402793\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 13.68, NNZs: 369, Bias: -7.399308, T: 801900, Avg. loss: 0.392136\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 13.55, NNZs: 369, Bias: -7.391700, T: 846450, Avg. loss: 0.396598\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 13.15, NNZs: 369, Bias: -7.348449, T: 891000, Avg. loss: 0.390634\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 12.91, NNZs: 369, Bias: -7.202597, T: 935550, Avg. loss: 0.378332\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 12.81, NNZs: 369, Bias: -7.155457, T: 980100, Avg. loss: 0.377257\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 12.70, NNZs: 369, Bias: -7.152933, T: 1024650, Avg. loss: 0.370230\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 12.61, NNZs: 369, Bias: -7.002190, T: 1069200, Avg. loss: 0.368579\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 12.45, NNZs: 369, Bias: -6.982890, T: 1113750, Avg. loss: 0.364449\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 12.29, NNZs: 369, Bias: -6.838715, T: 1158300, Avg. loss: 0.357550\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 12.20, NNZs: 369, Bias: -6.775785, T: 1202850, Avg. loss: 0.355597\n",
      "Total training time: 1.28 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 11.92, NNZs: 369, Bias: -6.974419, T: 1247400, Avg. loss: 0.356630\n",
      "Total training time: 1.31 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 11.94, NNZs: 369, Bias: -6.793491, T: 1291950, Avg. loss: 0.347408\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 11.71, NNZs: 369, Bias: -6.767381, T: 1336500, Avg. loss: 0.350218\n",
      "Total training time: 1.41 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 11.60, NNZs: 369, Bias: -6.720474, T: 1381050, Avg. loss: 0.344128\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 11.56, NNZs: 369, Bias: -6.657827, T: 1425600, Avg. loss: 0.343897\n",
      "Total training time: 1.51 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 11.54, NNZs: 369, Bias: -6.499796, T: 1470150, Avg. loss: 0.345126\n",
      "Total training time: 1.56 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 11.52, NNZs: 369, Bias: -6.426586, T: 1514700, Avg. loss: 0.343018\n",
      "Total training time: 1.60 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 11.35, NNZs: 369, Bias: -6.397522, T: 1559250, Avg. loss: 0.337696\n",
      "Total training time: 1.63 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 11.28, NNZs: 369, Bias: -6.332637, T: 1603800, Avg. loss: 0.334359\n",
      "Total training time: 1.69 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 11.22, NNZs: 369, Bias: -6.314458, T: 1648350, Avg. loss: 0.332734\n",
      "Total training time: 1.73 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 11.13, NNZs: 369, Bias: -6.291765, T: 1692900, Avg. loss: 0.332627\n",
      "Total training time: 1.77 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 11.09, NNZs: 369, Bias: -6.235072, T: 1737450, Avg. loss: 0.329868\n",
      "Total training time: 1.81 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 11.01, NNZs: 369, Bias: -6.235330, T: 1782000, Avg. loss: 0.330418\n",
      "Total training time: 1.86 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 10.95, NNZs: 369, Bias: -6.110153, T: 1826550, Avg. loss: 0.327850\n",
      "Total training time: 1.92 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 10.85, NNZs: 369, Bias: -6.246286, T: 1871100, Avg. loss: 0.330131\n",
      "Total training time: 1.96 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 10.84, NNZs: 369, Bias: -6.075391, T: 1915650, Avg. loss: 0.321238\n",
      "Total training time: 2.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 10.75, NNZs: 369, Bias: -6.142017, T: 1960200, Avg. loss: 0.324017\n",
      "Total training time: 2.06 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 10.77, NNZs: 369, Bias: -6.000010, T: 2004750, Avg. loss: 0.323352\n",
      "Total training time: 2.09 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 10.56, NNZs: 369, Bias: -6.148610, T: 2049300, Avg. loss: 0.322237\n",
      "Total training time: 2.15 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 10.56, NNZs: 369, Bias: -6.038036, T: 2093850, Avg. loss: 0.318919\n",
      "Total training time: 2.18 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 10.61, NNZs: 369, Bias: -5.959675, T: 2138400, Avg. loss: 0.317660\n",
      "Total training time: 2.23 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 10.54, NNZs: 369, Bias: -5.992373, T: 2182950, Avg. loss: 0.317974\n",
      "Total training time: 2.28 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 10.55, NNZs: 369, Bias: -5.953047, T: 2227500, Avg. loss: 0.315976\n",
      "Total training time: 2.31 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 10.44, NNZs: 369, Bias: -5.987996, T: 2272050, Avg. loss: 0.313950\n",
      "Total training time: 2.37 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 10.46, NNZs: 369, Bias: -5.870176, T: 2316600, Avg. loss: 0.310617\n",
      "Total training time: 2.43 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 10.43, NNZs: 369, Bias: -5.845968, T: 2361150, Avg. loss: 0.313401\n",
      "Total training time: 2.46 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 10.35, NNZs: 369, Bias: -5.830989, T: 2405700, Avg. loss: 0.311395\n",
      "Total training time: 2.51 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 10.32, NNZs: 369, Bias: -5.869734, T: 2450250, Avg. loss: 0.309752\n",
      "Total training time: 2.56 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 10.35, NNZs: 369, Bias: -5.768879, T: 2494800, Avg. loss: 0.313107\n",
      "Total training time: 2.61 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 10.23, NNZs: 369, Bias: -5.841216, T: 2539350, Avg. loss: 0.310233\n",
      "Total training time: 2.65 seconds.\n",
      "Convergence after 57 epochs took 2.65 seconds\n",
      "-- Epoch 1\n",
      "Norm: 23.10, NNZs: 370, Bias: -0.970956, T: 44550, Avg. loss: 4.518614\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 16.15, NNZs: 370, Bias: -0.166611, T: 89100, Avg. loss: 1.252363\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 13.10, NNZs: 370, Bias: -0.248805, T: 133650, Avg. loss: 0.956452\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 11.88, NNZs: 370, Bias: -0.220487, T: 178200, Avg. loss: 0.837022\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 11.07, NNZs: 370, Bias: -0.322867, T: 222750, Avg. loss: 0.764214\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10.62, NNZs: 370, Bias: -0.047475, T: 267300, Avg. loss: 0.731182\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 10.20, NNZs: 370, Bias: 0.001976, T: 311850, Avg. loss: 0.705234\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 9.83, NNZs: 370, Bias: 0.000930, T: 356400, Avg. loss: 0.684239\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 9.53, NNZs: 370, Bias: 0.037905, T: 400950, Avg. loss: 0.666883\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 9.43, NNZs: 370, Bias: -0.059251, T: 445500, Avg. loss: 0.654874\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 9.16, NNZs: 370, Bias: -0.019248, T: 490050, Avg. loss: 0.647804\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 9.14, NNZs: 370, Bias: 0.015667, T: 534600, Avg. loss: 0.636767\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 8.96, NNZs: 370, Bias: 0.035495, T: 579150, Avg. loss: 0.627023\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 8.89, NNZs: 370, Bias: -0.004843, T: 623700, Avg. loss: 0.625690\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 8.84, NNZs: 370, Bias: -0.022560, T: 668250, Avg. loss: 0.618554\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 8.80, NNZs: 370, Bias: 0.102530, T: 712800, Avg. loss: 0.617328\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 8.69, NNZs: 370, Bias: 0.075156, T: 757350, Avg. loss: 0.611373\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 8.68, NNZs: 370, Bias: 0.023520, T: 801900, Avg. loss: 0.609119\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 8.64, NNZs: 370, Bias: 0.072787, T: 846450, Avg. loss: 0.605516\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 8.53, NNZs: 370, Bias: 0.017858, T: 891000, Avg. loss: 0.603272\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 8.56, NNZs: 370, Bias: 0.096006, T: 935550, Avg. loss: 0.599255\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 8.50, NNZs: 370, Bias: 0.053834, T: 980100, Avg. loss: 0.596946\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 8.46, NNZs: 370, Bias: 0.160527, T: 1024650, Avg. loss: 0.595336\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 8.45, NNZs: 370, Bias: 0.133756, T: 1069200, Avg. loss: 0.593864\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 8.45, NNZs: 370, Bias: 0.112808, T: 1113750, Avg. loss: 0.592460\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 8.49, NNZs: 370, Bias: 0.051703, T: 1158300, Avg. loss: 0.590683\n",
      "Total training time: 1.28 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 8.42, NNZs: 370, Bias: 0.153569, T: 1202850, Avg. loss: 0.588777\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 8.47, NNZs: 370, Bias: 0.151594, T: 1247400, Avg. loss: 0.589020\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 8.38, NNZs: 370, Bias: 0.117274, T: 1291950, Avg. loss: 0.587596\n",
      "Total training time: 1.45 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 8.36, NNZs: 370, Bias: 0.131591, T: 1336500, Avg. loss: 0.583492\n",
      "Total training time: 1.48 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 8.32, NNZs: 370, Bias: 0.140454, T: 1381050, Avg. loss: 0.581189\n",
      "Total training time: 1.53 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 8.31, NNZs: 370, Bias: 0.123502, T: 1425600, Avg. loss: 0.583827\n",
      "Total training time: 1.58 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 8.31, NNZs: 370, Bias: 0.175010, T: 1470150, Avg. loss: 0.582565\n",
      "Total training time: 1.64 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 8.30, NNZs: 370, Bias: 0.181450, T: 1514700, Avg. loss: 0.581501\n",
      "Total training time: 1.68 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 8.27, NNZs: 370, Bias: 0.148685, T: 1559250, Avg. loss: 0.582117\n",
      "Total training time: 1.73 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 8.29, NNZs: 370, Bias: 0.162509, T: 1603800, Avg. loss: 0.578101\n",
      "Total training time: 1.79 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 8.28, NNZs: 370, Bias: 0.144209, T: 1648350, Avg. loss: 0.579022\n",
      "Total training time: 1.83 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 8.29, NNZs: 370, Bias: 0.169205, T: 1692900, Avg. loss: 0.578770\n",
      "Total training time: 1.90 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 8.26, NNZs: 370, Bias: 0.155824, T: 1737450, Avg. loss: 0.577369\n",
      "Total training time: 1.95 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 8.25, NNZs: 370, Bias: 0.174375, T: 1782000, Avg. loss: 0.576581\n",
      "Total training time: 2.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 8.23, NNZs: 370, Bias: 0.205758, T: 1826550, Avg. loss: 0.576662\n",
      "Total training time: 2.05 seconds.\n",
      "Convergence after 41 epochs took 2.05 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    7.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7346127946127946"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_bal = SGDClassifier(class_weight='balanced', verbose=True)\n",
    "with joblib.parallel_backend('dask'):\n",
    "    sgd_bal.fit(train_X, train_y)\n",
    "sgd_bal.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This performs pretty well. We can further tune some hyperparamters to possibly get higher accuracy. Let's start with class weights. But we need to first save the parameters and score for later review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>alpha</th>\n",
       "      <th>average</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>early_stopping</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>eta0</th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>n_iter_no_change</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>penalty</th>\n",
       "      <th>power_t</th>\n",
       "      <th>random_state</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>tol</th>\n",
       "      <th>validation_fraction</th>\n",
       "      <th>verbose</th>\n",
       "      <th>warm_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SGD_OBO</th>\n",
       "      <td>0.748215</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_BAL</th>\n",
       "      <td>0.734613</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Accuracy   alpha  average class_weight  early_stopping  epsilon  \\\n",
       "SGD_OBO  0.748215  0.0001    False         None           False      0.1   \n",
       "SGD_BAL  0.734613  0.0001    False     balanced           False      0.1   \n",
       "\n",
       "         eta0  fit_intercept  l1_ratio learning_rate  ... n_iter_no_change  \\\n",
       "SGD_OBO   0.0           True      0.15       optimal  ...                5   \n",
       "SGD_BAL   0.0           True      0.15       optimal  ...                5   \n",
       "\n",
       "         n_jobs  penalty power_t random_state  shuffle    tol  \\\n",
       "SGD_OBO    None       l2     0.5         None     True  0.001   \n",
       "SGD_BAL    None       l2     0.5         None     True  0.001   \n",
       "\n",
       "         validation_fraction  verbose  warm_start  \n",
       "SGD_OBO                  0.1        1       False  \n",
       "SGD_BAL                  0.1        1       False  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = sgd_bal.get_params()\n",
    "a['Accuracy'] = sgd_bal.score(test_X, test_y)\n",
    "sgd_deets = pd.concat([sgd_deets, pd.DataFrame(a, index=['SGD_BAL'])], axis=0, join='outer')\n",
    "sgd_deets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 63.40, NNZs: 293, Bias: -4.240787, T: 44550, Avg. loss: 4.325091\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 57.26, NNZs: 270, Bias: -3.518457, T: 89100, Avg. loss: 0.953986\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 52.49, NNZs: 261, Bias: -3.228333, T: 133650, Avg. loss: 0.728883\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 48.40, NNZs: 271, Bias: -3.059384, T: 178200, Avg. loss: 0.635169\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 44.84, NNZs: 279, Bias: -2.871723, T: 222750, Avg. loss: 0.595293\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 42.03, NNZs: 267, Bias: -2.509829, T: 267300, Avg. loss: 0.565082\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 39.66, NNZs: 275, Bias: -2.475840, T: 311850, Avg. loss: 0.549326\n",
      "Total training time: 1.63 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 37.63, NNZs: 276, Bias: -2.387907, T: 356400, Avg. loss: 0.532411\n",
      "Total training time: 1.85 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 35.78, NNZs: 272, Bias: -2.352460, T: 400950, Avg. loss: 0.523568\n",
      "Total training time: 2.10 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 34.25, NNZs: 275, Bias: -2.327502, T: 445500, Avg. loss: 0.514639\n",
      "Total training time: 2.30 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 32.78, NNZs: 281, Bias: -2.216995, T: 490050, Avg. loss: 0.509002\n",
      "Total training time: 2.55 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 31.59, NNZs: 280, Bias: -2.328921, T: 534600, Avg. loss: 0.500199\n",
      "Total training time: 2.79 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 30.44, NNZs: 283, Bias: -2.218691, T: 579150, Avg. loss: 0.498281\n",
      "Total training time: 3.02 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 29.46, NNZs: 284, Bias: -2.117912, T: 623700, Avg. loss: 0.490941\n",
      "Total training time: 3.24 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 28.54, NNZs: 289, Bias: -2.043070, T: 668250, Avg. loss: 0.489743\n",
      "Total training time: 3.47 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 27.69, NNZs: 287, Bias: -2.060700, T: 712800, Avg. loss: 0.486923\n",
      "Total training time: 3.70 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 26.93, NNZs: 289, Bias: -2.020302, T: 757350, Avg. loss: 0.482114\n",
      "Total training time: 3.91 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 26.20, NNZs: 284, Bias: -2.045154, T: 801900, Avg. loss: 0.480277\n",
      "Total training time: 4.14 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 25.57, NNZs: 294, Bias: -2.056985, T: 846450, Avg. loss: 0.478707\n",
      "Total training time: 4.34 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 24.95, NNZs: 291, Bias: -1.985951, T: 891000, Avg. loss: 0.474559\n",
      "Total training time: 4.59 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 24.41, NNZs: 294, Bias: -1.974879, T: 935550, Avg. loss: 0.473807\n",
      "Total training time: 4.81 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 23.87, NNZs: 295, Bias: -1.983519, T: 980100, Avg. loss: 0.472931\n",
      "Total training time: 5.03 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 23.37, NNZs: 294, Bias: -1.912457, T: 1024650, Avg. loss: 0.470900\n",
      "Total training time: 5.26 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 22.89, NNZs: 295, Bias: -1.883982, T: 1069200, Avg. loss: 0.468727\n",
      "Total training time: 5.49 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 22.46, NNZs: 293, Bias: -1.866921, T: 1113750, Avg. loss: 0.468184\n",
      "Total training time: 5.73 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 22.04, NNZs: 300, Bias: -1.875547, T: 1158300, Avg. loss: 0.466964\n",
      "Total training time: 5.97 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 21.65, NNZs: 299, Bias: -1.808176, T: 1202850, Avg. loss: 0.466613\n",
      "Total training time: 6.20 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 21.25, NNZs: 296, Bias: -1.841473, T: 1247400, Avg. loss: 0.465117\n",
      "Total training time: 6.41 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 20.90, NNZs: 299, Bias: -1.787849, T: 1291950, Avg. loss: 0.463685\n",
      "Total training time: 6.66 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 20.53, NNZs: 296, Bias: -1.833757, T: 1336500, Avg. loss: 0.463141\n",
      "Total training time: 6.88 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 20.20, NNZs: 293, Bias: -1.847689, T: 1381050, Avg. loss: 0.462581\n",
      "Total training time: 7.11 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 19.89, NNZs: 297, Bias: -1.818233, T: 1425600, Avg. loss: 0.461822\n",
      "Total training time: 7.33 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 19.59, NNZs: 301, Bias: -1.811125, T: 1470150, Avg. loss: 0.459962\n",
      "Total training time: 7.55 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 19.32, NNZs: 296, Bias: -1.816743, T: 1514700, Avg. loss: 0.460310\n",
      "Total training time: 7.78 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 19.08, NNZs: 301, Bias: -1.802252, T: 1559250, Avg. loss: 0.458309\n",
      "Total training time: 8.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 18.81, NNZs: 293, Bias: -1.763733, T: 1603800, Avg. loss: 0.458439\n",
      "Total training time: 8.24 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 18.58, NNZs: 297, Bias: -1.751527, T: 1648350, Avg. loss: 0.457190\n",
      "Total training time: 8.47 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 18.34, NNZs: 293, Bias: -1.739822, T: 1692900, Avg. loss: 0.456302\n",
      "Total training time: 8.70 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 18.12, NNZs: 297, Bias: -1.774400, T: 1737450, Avg. loss: 0.456701\n",
      "Total training time: 8.96 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 17.91, NNZs: 297, Bias: -1.734017, T: 1782000, Avg. loss: 0.455758\n",
      "Total training time: 9.18 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 17.71, NNZs: 298, Bias: -1.711750, T: 1826550, Avg. loss: 0.455922\n",
      "Total training time: 9.41 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 17.50, NNZs: 299, Bias: -1.717388, T: 1871100, Avg. loss: 0.455599\n",
      "Total training time: 9.65 seconds.\n",
      "Convergence after 42 epochs took 9.65 seconds\n",
      "-- Epoch 1\n",
      "Norm: 45.65, NNZs: 270, Bias: -13.701377, T: 44550, Avg. loss: 1.705401\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 39.68, NNZs: 273, Bias: -10.455880, T: 89100, Avg. loss: 0.372550\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.91, NNZs: 260, Bias: -9.676965, T: 133650, Avg. loss: 0.282335\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 31.73, NNZs: 259, Bias: -8.999400, T: 178200, Avg. loss: 0.242836\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 29.52, NNZs: 258, Bias: -8.134762, T: 222750, Avg. loss: 0.218906\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 27.60, NNZs: 254, Bias: -7.614759, T: 267300, Avg. loss: 0.207706\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 26.14, NNZs: 254, Bias: -7.272055, T: 311850, Avg. loss: 0.197186\n",
      "Total training time: 1.50 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 24.85, NNZs: 257, Bias: -6.975106, T: 356400, Avg. loss: 0.190835\n",
      "Total training time: 1.69 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 23.68, NNZs: 259, Bias: -6.814027, T: 400950, Avg. loss: 0.186439\n",
      "Total training time: 1.91 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 22.68, NNZs: 255, Bias: -6.526818, T: 445500, Avg. loss: 0.182527\n",
      "Total training time: 2.10 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 21.73, NNZs: 255, Bias: -6.273004, T: 490050, Avg. loss: 0.180248\n",
      "Total training time: 2.30 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 20.93, NNZs: 253, Bias: -6.175467, T: 534600, Avg. loss: 0.176101\n",
      "Total training time: 2.51 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 20.23, NNZs: 254, Bias: -5.977570, T: 579150, Avg. loss: 0.173946\n",
      "Total training time: 2.70 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 19.61, NNZs: 251, Bias: -5.844221, T: 623700, Avg. loss: 0.171377\n",
      "Total training time: 2.92 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 19.03, NNZs: 253, Bias: -5.703475, T: 668250, Avg. loss: 0.170039\n",
      "Total training time: 3.12 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 18.50, NNZs: 250, Bias: -5.544332, T: 712800, Avg. loss: 0.168532\n",
      "Total training time: 3.33 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 17.99, NNZs: 254, Bias: -5.435965, T: 757350, Avg. loss: 0.167472\n",
      "Total training time: 3.53 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 17.52, NNZs: 249, Bias: -5.383812, T: 801900, Avg. loss: 0.166177\n",
      "Total training time: 3.72 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 17.12, NNZs: 253, Bias: -5.178181, T: 846450, Avg. loss: 0.165539\n",
      "Total training time: 3.92 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 16.70, NNZs: 248, Bias: -5.144130, T: 891000, Avg. loss: 0.164691\n",
      "Total training time: 4.12 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 16.33, NNZs: 247, Bias: -5.044552, T: 935550, Avg. loss: 0.163204\n",
      "Total training time: 4.31 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 16.00, NNZs: 251, Bias: -4.899065, T: 980100, Avg. loss: 0.162316\n",
      "Total training time: 4.51 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 15.64, NNZs: 255, Bias: -4.840496, T: 1024650, Avg. loss: 0.162173\n",
      "Total training time: 4.69 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 15.33, NNZs: 251, Bias: -4.811263, T: 1069200, Avg. loss: 0.161134\n",
      "Total training time: 4.91 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 15.05, NNZs: 246, Bias: -4.710628, T: 1113750, Avg. loss: 0.160421\n",
      "Total training time: 5.11 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 14.78, NNZs: 253, Bias: -4.623053, T: 1158300, Avg. loss: 0.160163\n",
      "Total training time: 5.30 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 14.52, NNZs: 254, Bias: -4.589190, T: 1202850, Avg. loss: 0.159339\n",
      "Total training time: 5.51 seconds.\n",
      "-- Epoch 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 14.27, NNZs: 249, Bias: -4.499606, T: 1247400, Avg. loss: 0.159315\n",
      "Total training time: 5.70 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 14.03, NNZs: 248, Bias: -4.468445, T: 1291950, Avg. loss: 0.158232\n",
      "Total training time: 5.91 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 13.80, NNZs: 250, Bias: -4.415444, T: 1336500, Avg. loss: 0.158003\n",
      "Total training time: 6.12 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 13.58, NNZs: 255, Bias: -4.371041, T: 1381050, Avg. loss: 0.157763\n",
      "Total training time: 6.31 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 13.37, NNZs: 249, Bias: -4.307223, T: 1425600, Avg. loss: 0.157350\n",
      "Total training time: 6.51 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 13.18, NNZs: 250, Bias: -4.245745, T: 1470150, Avg. loss: 0.156810\n",
      "Total training time: 6.70 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 12.98, NNZs: 247, Bias: -4.212734, T: 1514700, Avg. loss: 0.156596\n",
      "Total training time: 6.90 seconds.\n",
      "Convergence after 34 epochs took 6.90 seconds\n",
      "-- Epoch 1\n",
      "Norm: 69.57, NNZs: 277, Bias: 4.476317, T: 44550, Avg. loss: 4.917799\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 62.87, NNZs: 275, Bias: 2.670161, T: 89100, Avg. loss: 1.107509\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 57.54, NNZs: 267, Bias: 2.761537, T: 133650, Avg. loss: 0.828217\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 53.20, NNZs: 270, Bias: 2.566701, T: 178200, Avg. loss: 0.737098\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 49.59, NNZs: 269, Bias: 2.462558, T: 222750, Avg. loss: 0.687276\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 46.57, NNZs: 269, Bias: 2.215653, T: 267300, Avg. loss: 0.659692\n",
      "Total training time: 1.43 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 43.94, NNZs: 283, Bias: 2.221274, T: 311850, Avg. loss: 0.638467\n",
      "Total training time: 1.68 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 41.56, NNZs: 287, Bias: 2.247374, T: 356400, Avg. loss: 0.629649\n",
      "Total training time: 1.93 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 39.55, NNZs: 285, Bias: 2.208024, T: 400950, Avg. loss: 0.612027\n",
      "Total training time: 2.16 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 37.83, NNZs: 279, Bias: 2.177995, T: 445500, Avg. loss: 0.606007\n",
      "Total training time: 2.38 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 36.43, NNZs: 287, Bias: 2.048259, T: 490050, Avg. loss: 0.594468\n",
      "Total training time: 2.61 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 35.17, NNZs: 284, Bias: 2.026723, T: 534600, Avg. loss: 0.587638\n",
      "Total training time: 2.87 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 34.00, NNZs: 292, Bias: 1.936259, T: 579150, Avg. loss: 0.585732\n",
      "Total training time: 3.10 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 32.88, NNZs: 286, Bias: 1.920795, T: 623700, Avg. loss: 0.582219\n",
      "Total training time: 3.32 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 31.91, NNZs: 284, Bias: 1.920910, T: 668250, Avg. loss: 0.578840\n",
      "Total training time: 3.56 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 30.98, NNZs: 288, Bias: 1.904993, T: 712800, Avg. loss: 0.573803\n",
      "Total training time: 3.78 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 30.15, NNZs: 287, Bias: 1.890883, T: 757350, Avg. loss: 0.568502\n",
      "Total training time: 4.03 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 29.36, NNZs: 295, Bias: 1.936769, T: 801900, Avg. loss: 0.568397\n",
      "Total training time: 4.26 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 28.66, NNZs: 286, Bias: 1.741566, T: 846450, Avg. loss: 0.566438\n",
      "Total training time: 4.50 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 28.01, NNZs: 288, Bias: 1.710777, T: 891000, Avg. loss: 0.563134\n",
      "Total training time: 4.72 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 27.39, NNZs: 294, Bias: 1.723574, T: 935550, Avg. loss: 0.562280\n",
      "Total training time: 4.97 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 26.79, NNZs: 295, Bias: 1.744349, T: 980100, Avg. loss: 0.558070\n",
      "Total training time: 5.20 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 26.24, NNZs: 300, Bias: 1.792804, T: 1024650, Avg. loss: 0.555949\n",
      "Total training time: 5.44 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 25.75, NNZs: 293, Bias: 1.678423, T: 1069200, Avg. loss: 0.556103\n",
      "Total training time: 5.68 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 25.26, NNZs: 293, Bias: 1.714818, T: 1113750, Avg. loss: 0.555424\n",
      "Total training time: 5.92 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 24.78, NNZs: 299, Bias: 1.721942, T: 1158300, Avg. loss: 0.553078\n",
      "Total training time: 6.16 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 24.35, NNZs: 298, Bias: 1.636421, T: 1202850, Avg. loss: 0.552279\n",
      "Total training time: 6.39 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 23.92, NNZs: 302, Bias: 1.661302, T: 1247400, Avg. loss: 0.552004\n",
      "Total training time: 6.62 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 23.51, NNZs: 301, Bias: 1.645914, T: 1291950, Avg. loss: 0.551320\n",
      "Total training time: 6.86 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 23.12, NNZs: 301, Bias: 1.630251, T: 1336500, Avg. loss: 0.549402\n",
      "Total training time: 7.10 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 22.76, NNZs: 302, Bias: 1.594597, T: 1381050, Avg. loss: 0.549454\n",
      "Total training time: 7.32 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 22.41, NNZs: 302, Bias: 1.616655, T: 1425600, Avg. loss: 0.547819\n",
      "Total training time: 7.56 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 22.09, NNZs: 303, Bias: 1.596284, T: 1470150, Avg. loss: 0.546585\n",
      "Total training time: 7.79 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 21.77, NNZs: 301, Bias: 1.596688, T: 1514700, Avg. loss: 0.547016\n",
      "Total training time: 8.04 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 21.49, NNZs: 306, Bias: 1.570677, T: 1559250, Avg. loss: 0.544705\n",
      "Total training time: 8.26 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 21.18, NNZs: 301, Bias: 1.614164, T: 1603800, Avg. loss: 0.544014\n",
      "Total training time: 8.50 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 20.91, NNZs: 310, Bias: 1.600942, T: 1648350, Avg. loss: 0.543318\n",
      "Total training time: 8.72 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 20.65, NNZs: 303, Bias: 1.612149, T: 1692900, Avg. loss: 0.543157\n",
      "Total training time: 8.95 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 20.41, NNZs: 305, Bias: 1.541679, T: 1737450, Avg. loss: 0.542377\n",
      "Total training time: 9.19 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 20.17, NNZs: 301, Bias: 1.530430, T: 1782000, Avg. loss: 0.541069\n",
      "Total training time: 9.42 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 19.94, NNZs: 301, Bias: 1.574302, T: 1826550, Avg. loss: 0.542074\n",
      "Total training time: 9.67 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 19.72, NNZs: 305, Bias: 1.551905, T: 1871100, Avg. loss: 0.540135\n",
      "Total training time: 9.91 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 19.50, NNZs: 304, Bias: 1.530520, T: 1915650, Avg. loss: 0.539820\n",
      "Total training time: 10.14 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 19.30, NNZs: 304, Bias: 1.525589, T: 1960200, Avg. loss: 0.540266\n",
      "Total training time: 10.38 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 19.11, NNZs: 305, Bias: 1.495076, T: 2004750, Avg. loss: 0.538899\n",
      "Total training time: 10.63 seconds.\n",
      "Convergence after 45 epochs took 10.63 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   27.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.749023569023569"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_el = SGDClassifier(verbose=True, penalty='elasticnet', learning_rate='optimal', l1_ratio=0.15)\n",
    "with joblib.parallel_backend('dask'):\n",
    "    sgd_el.fit(train_X, train_y)\n",
    "sgd_el.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>alpha</th>\n",
       "      <th>average</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>early_stopping</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>eta0</th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>n_iter_no_change</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>penalty</th>\n",
       "      <th>power_t</th>\n",
       "      <th>random_state</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>tol</th>\n",
       "      <th>validation_fraction</th>\n",
       "      <th>verbose</th>\n",
       "      <th>warm_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SGD_OBO</th>\n",
       "      <td>0.748215</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_BAL</th>\n",
       "      <td>0.734613</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_EL</th>\n",
       "      <td>0.749024</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Accuracy   alpha  average class_weight  early_stopping  epsilon  \\\n",
       "SGD_OBO  0.748215  0.0001    False         None           False      0.1   \n",
       "SGD_BAL  0.734613  0.0001    False     balanced           False      0.1   \n",
       "SGD_EL   0.749024  0.0001    False         None           False      0.1   \n",
       "\n",
       "         eta0  fit_intercept  l1_ratio learning_rate  ... n_iter_no_change  \\\n",
       "SGD_OBO   0.0           True      0.15       optimal  ...                5   \n",
       "SGD_BAL   0.0           True      0.15       optimal  ...                5   \n",
       "SGD_EL    0.0           True      0.15       optimal  ...                5   \n",
       "\n",
       "         n_jobs     penalty power_t random_state  shuffle    tol  \\\n",
       "SGD_OBO    None          l2     0.5         None     True  0.001   \n",
       "SGD_BAL    None          l2     0.5         None     True  0.001   \n",
       "SGD_EL     None  elasticnet     0.5         None     True  0.001   \n",
       "\n",
       "         validation_fraction  verbose  warm_start  \n",
       "SGD_OBO                  0.1        1       False  \n",
       "SGD_BAL                  0.1        1       False  \n",
       "SGD_EL                   0.1        1       False  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = sgd_el.get_params()\n",
    "a['Accuracy'] = sgd_el.score(test_X, test_y)\n",
    "sgd_deets = pd.concat([sgd_deets, pd.DataFrame(a, index=['SGD_EL'])], axis=0, join='outer')\n",
    "sgd_deets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 284.53, NNZs: 295, Bias: -30.000000, T: 44550, Avg. loss: 21.699176\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 321.80, NNZs: 244, Bias: -30.000000, T: 89100, Avg. loss: 19.222923\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 340.09, NNZs: 197, Bias: -20.000000, T: 133650, Avg. loss: 17.221352\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 383.11, NNZs: 202, Bias: -25.000000, T: 178200, Avg. loss: 15.872652\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 395.25, NNZs: 191, Bias: -15.000000, T: 222750, Avg. loss: 14.690560\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 400.90, NNZs: 163, Bias: -30.000000, T: 267300, Avg. loss: 13.751594\n",
      "Total training time: 1.50 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 396.89, NNZs: 175, Bias: -45.000000, T: 311850, Avg. loss: 13.051051\n",
      "Total training time: 1.75 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 413.29, NNZs: 185, Bias: -15.000000, T: 356400, Avg. loss: 12.854008\n",
      "Total training time: 1.99 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 423.44, NNZs: 164, Bias: -15.000000, T: 400950, Avg. loss: 12.158677\n",
      "Total training time: 2.23 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 415.62, NNZs: 161, Bias: -25.000000, T: 445500, Avg. loss: 12.147777\n",
      "Total training time: 2.50 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 427.64, NNZs: 151, Bias: -30.000000, T: 490050, Avg. loss: 11.446159\n",
      "Total training time: 2.74 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 422.42, NNZs: 141, Bias: -15.000000, T: 534600, Avg. loss: 11.723273\n",
      "Total training time: 2.99 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 424.74, NNZs: 155, Bias: -25.000000, T: 579150, Avg. loss: 10.991283\n",
      "Total training time: 3.23 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 429.21, NNZs: 177, Bias: -25.000000, T: 623700, Avg. loss: 11.379106\n",
      "Total training time: 3.47 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 450.65, NNZs: 168, Bias: -25.000000, T: 668250, Avg. loss: 11.180742\n",
      "Total training time: 3.73 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 430.24, NNZs: 147, Bias: -10.000000, T: 712800, Avg. loss: 10.978597\n",
      "Total training time: 3.99 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 424.77, NNZs: 157, Bias: -10.000000, T: 757350, Avg. loss: 11.189800\n",
      "Total training time: 4.23 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 422.31, NNZs: 153, Bias: -15.000000, T: 801900, Avg. loss: 10.510927\n",
      "Total training time: 4.45 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 426.07, NNZs: 152, Bias: -20.000000, T: 846450, Avg. loss: 11.076859\n",
      "Total training time: 4.68 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 453.33, NNZs: 142, Bias: -25.000000, T: 891000, Avg. loss: 10.456901\n",
      "Total training time: 4.91 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 421.09, NNZs: 152, Bias: -25.000000, T: 935550, Avg. loss: 10.653481\n",
      "Total training time: 5.13 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 430.70, NNZs: 157, Bias: -25.000000, T: 980100, Avg. loss: 10.575325\n",
      "Total training time: 5.35 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 421.48, NNZs: 154, Bias: -5.000000, T: 1024650, Avg. loss: 10.771916\n",
      "Total training time: 5.57 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 414.16, NNZs: 146, Bias: -30.000000, T: 1069200, Avg. loss: 10.351428\n",
      "Total training time: 5.79 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 440.00, NNZs: 146, Bias: -20.000000, T: 1113750, Avg. loss: 10.569583\n",
      "Total training time: 6.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 436.11, NNZs: 165, Bias: -15.000000, T: 1158300, Avg. loss: 10.569138\n",
      "Total training time: 6.24 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 440.29, NNZs: 148, Bias: -25.000000, T: 1202850, Avg. loss: 10.478491\n",
      "Total training time: 6.47 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 418.01, NNZs: 160, Bias: -5.000000, T: 1247400, Avg. loss: 10.263984\n",
      "Total training time: 6.71 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 436.84, NNZs: 142, Bias: -35.000000, T: 1291950, Avg. loss: 10.800737\n",
      "Total training time: 6.93 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 452.30, NNZs: 143, Bias: -10.000000, T: 1336500, Avg. loss: 10.233359\n",
      "Total training time: 7.16 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 457.90, NNZs: 143, Bias: -25.000000, T: 1381050, Avg. loss: 10.062418\n",
      "Total training time: 7.39 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 417.63, NNZs: 160, Bias: -15.000000, T: 1425600, Avg. loss: 10.719587\n",
      "Total training time: 7.62 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 450.29, NNZs: 148, Bias: -25.000000, T: 1470150, Avg. loss: 10.107470\n",
      "Total training time: 7.84 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 426.84, NNZs: 167, Bias: -20.000000, T: 1514700, Avg. loss: 10.448915\n",
      "Total training time: 8.06 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 438.40, NNZs: 163, Bias: -30.000000, T: 1559250, Avg. loss: 10.539278\n",
      "Total training time: 8.28 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 431.64, NNZs: 152, Bias: -5.000000, T: 1603800, Avg. loss: 10.359496\n",
      "Total training time: 8.50 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 190.38, NNZs: 174, Bias: -6.000000, T: 1648350, Avg. loss: 2.555287\n",
      "Total training time: 8.73 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 184.44, NNZs: 160, Bias: -10.000000, T: 1692900, Avg. loss: 2.693769\n",
      "Total training time: 8.94 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 184.00, NNZs: 163, Bias: -10.000000, T: 1737450, Avg. loss: 2.689133\n",
      "Total training time: 9.17 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 188.80, NNZs: 162, Bias: -9.000000, T: 1782000, Avg. loss: 2.637643\n",
      "Total training time: 9.40 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 182.89, NNZs: 176, Bias: -8.000000, T: 1826550, Avg. loss: 2.762958\n",
      "Total training time: 9.64 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 188.69, NNZs: 155, Bias: -10.000000, T: 1871100, Avg. loss: 2.677221\n",
      "Total training time: 9.87 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 115.05, NNZs: 184, Bias: -4.600000, T: 1915650, Avg. loss: 0.929854\n",
      "Total training time: 10.10 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 90.77, NNZs: 198, Bias: -4.400000, T: 1960200, Avg. loss: 0.923527\n",
      "Total training time: 10.35 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 85.69, NNZs: 192, Bias: -4.200000, T: 2004750, Avg. loss: 0.912443\n",
      "Total training time: 10.60 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 85.47, NNZs: 211, Bias: -4.600000, T: 2049300, Avg. loss: 0.900852\n",
      "Total training time: 10.84 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 82.58, NNZs: 213, Bias: -4.600000, T: 2093850, Avg. loss: 0.930635\n",
      "Total training time: 11.07 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 82.98, NNZs: 194, Bias: -3.600000, T: 2138400, Avg. loss: 0.933327\n",
      "Total training time: 11.31 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 81.88, NNZs: 204, Bias: -4.400000, T: 2182950, Avg. loss: 0.931175\n",
      "Total training time: 11.55 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 82.43, NNZs: 199, Bias: -5.000000, T: 2227500, Avg. loss: 0.930372\n",
      "Total training time: 11.79 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 82.77, NNZs: 213, Bias: -4.000000, T: 2272050, Avg. loss: 0.927982\n",
      "Total training time: 12.03 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 72.91, NNZs: 218, Bias: -3.160000, T: 2316600, Avg. loss: 0.565571\n",
      "Total training time: 12.27 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 65.35, NNZs: 218, Bias: -2.800000, T: 2361150, Avg. loss: 0.549833\n",
      "Total training time: 12.51 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 59.17, NNZs: 226, Bias: -2.800000, T: 2405700, Avg. loss: 0.547808\n",
      "Total training time: 12.76 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 53.99, NNZs: 224, Bias: -2.800000, T: 2450250, Avg. loss: 0.555247\n",
      "Total training time: 12.99 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 49.81, NNZs: 222, Bias: -2.720000, T: 2494800, Avg. loss: 0.556025\n",
      "Total training time: 13.23 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 46.67, NNZs: 222, Bias: -2.640000, T: 2539350, Avg. loss: 0.551911\n",
      "Total training time: 13.45 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 44.06, NNZs: 226, Bias: -2.640000, T: 2583900, Avg. loss: 0.555493\n",
      "Total training time: 13.70 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 42.08, NNZs: 226, Bias: -2.240000, T: 2628450, Avg. loss: 0.553597\n",
      "Total training time: 13.93 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 40.86, NNZs: 231, Bias: -2.400000, T: 2673000, Avg. loss: 0.466737\n",
      "Total training time: 14.17 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 39.79, NNZs: 235, Bias: -2.320000, T: 2717550, Avg. loss: 0.463192\n",
      "Total training time: 14.40 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 38.77, NNZs: 233, Bias: -2.200000, T: 2762100, Avg. loss: 0.463322\n",
      "Total training time: 14.62 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 37.80, NNZs: 232, Bias: -2.192000, T: 2806650, Avg. loss: 0.462223\n",
      "Total training time: 14.86 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 36.87, NNZs: 232, Bias: -2.128000, T: 2851200, Avg. loss: 0.462930\n",
      "Total training time: 15.10 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 35.97, NNZs: 229, Bias: -2.128000, T: 2895750, Avg. loss: 0.463399\n",
      "Total training time: 15.33 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 35.12, NNZs: 227, Bias: -2.088000, T: 2940300, Avg. loss: 0.460761\n",
      "Total training time: 15.58 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 34.29, NNZs: 229, Bias: -2.104000, T: 2984850, Avg. loss: 0.462411\n",
      "Total training time: 15.82 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 33.50, NNZs: 227, Bias: -2.128000, T: 3029400, Avg. loss: 0.462933\n",
      "Total training time: 16.05 seconds.\n",
      "-- Epoch 69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 32.73, NNZs: 228, Bias: -2.152000, T: 3073950, Avg. loss: 0.462070\n",
      "Total training time: 16.29 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 31.98, NNZs: 226, Bias: -2.064000, T: 3118500, Avg. loss: 0.462777\n",
      "Total training time: 16.51 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 31.28, NNZs: 229, Bias: -2.008000, T: 3163050, Avg. loss: 0.461223\n",
      "Total training time: 16.75 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 31.09, NNZs: 230, Bias: -2.017600, T: 3207600, Avg. loss: 0.444006\n",
      "Total training time: 16.96 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 30.91, NNZs: 229, Bias: -1.979200, T: 3252150, Avg. loss: 0.443065\n",
      "Total training time: 17.20 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 30.72, NNZs: 231, Bias: -1.979200, T: 3296700, Avg. loss: 0.442153\n",
      "Total training time: 17.43 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 30.55, NNZs: 229, Bias: -1.969600, T: 3341250, Avg. loss: 0.442159\n",
      "Total training time: 17.67 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 30.37, NNZs: 227, Bias: -1.955200, T: 3385800, Avg. loss: 0.442041\n",
      "Total training time: 17.90 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 30.20, NNZs: 231, Bias: -1.945600, T: 3430350, Avg. loss: 0.441514\n",
      "Total training time: 18.13 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 30.16, NNZs: 229, Bias: -1.956480, T: 3474900, Avg. loss: 0.437917\n",
      "Total training time: 18.35 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 30.13, NNZs: 229, Bias: -1.957120, T: 3519450, Avg. loss: 0.437477\n",
      "Total training time: 18.58 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 30.09, NNZs: 229, Bias: -1.964160, T: 3564000, Avg. loss: 0.437562\n",
      "Total training time: 18.81 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 30.05, NNZs: 229, Bias: -1.957760, T: 3608550, Avg. loss: 0.437627\n",
      "Total training time: 19.05 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 30.02, NNZs: 229, Bias: -1.955840, T: 3653100, Avg. loss: 0.437557\n",
      "Total training time: 19.27 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 29.98, NNZs: 229, Bias: -1.955840, T: 3697650, Avg. loss: 0.437291\n",
      "Total training time: 19.50 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 29.98, NNZs: 229, Bias: -1.950912, T: 3742200, Avg. loss: 0.436705\n",
      "Total training time: 19.73 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 29.97, NNZs: 229, Bias: -1.950848, T: 3786750, Avg. loss: 0.436470\n",
      "Total training time: 19.95 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 29.96, NNZs: 229, Bias: -1.952448, T: 3831300, Avg. loss: 0.436472\n",
      "Total training time: 20.18 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 29.95, NNZs: 229, Bias: -1.952000, T: 3875850, Avg. loss: 0.436430\n",
      "Total training time: 20.40 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 29.95, NNZs: 229, Bias: -1.953024, T: 3920400, Avg. loss: 0.436424\n",
      "Total training time: 20.63 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 29.94, NNZs: 229, Bias: -1.950259, T: 3964950, Avg. loss: 0.436265\n",
      "Total training time: 20.87 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 29.94, NNZs: 229, Bias: -1.950298, T: 4009500, Avg. loss: 0.436229\n",
      "Total training time: 21.09 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 29.94, NNZs: 229, Bias: -1.950554, T: 4054050, Avg. loss: 0.436219\n",
      "Total training time: 21.32 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 29.94, NNZs: 229, Bias: -1.950886, T: 4098600, Avg. loss: 0.436215\n",
      "Total training time: 21.54 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 29.94, NNZs: 229, Bias: -1.950451, T: 4143150, Avg. loss: 0.436218\n",
      "Total training time: 21.78 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 29.94, NNZs: 229, Bias: -1.950367, T: 4187700, Avg. loss: 0.436160\n",
      "Total training time: 22.00 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 29.94, NNZs: 229, Bias: -1.950218, T: 4232250, Avg. loss: 0.436159\n",
      "Total training time: 22.24 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 29.94, NNZs: 229, Bias: -1.950236, T: 4276800, Avg. loss: 0.436158\n",
      "Total training time: 22.47 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 29.94, NNZs: 229, Bias: -1.950193, T: 4321350, Avg. loss: 0.436158\n",
      "Total training time: 22.73 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 29.94, NNZs: 229, Bias: -1.950211, T: 4365900, Avg. loss: 0.436158\n",
      "Total training time: 22.94 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 29.94, NNZs: 229, Bias: -1.950206, T: 4410450, Avg. loss: 0.436145\n",
      "Total training time: 23.18 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 29.94, NNZs: 229, Bias: -1.950202, T: 4455000, Avg. loss: 0.436145\n",
      "Total training time: 23.41 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 29.94, NNZs: 229, Bias: -1.950191, T: 4499550, Avg. loss: 0.436145\n",
      "Total training time: 23.65 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 29.94, NNZs: 229, Bias: -1.950179, T: 4544100, Avg. loss: 0.436145\n",
      "Total training time: 23.87 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 29.94, NNZs: 229, Bias: -1.950173, T: 4588650, Avg. loss: 0.436145\n",
      "Total training time: 24.10 seconds.\n",
      "Convergence after 103 epochs took 24.10 seconds\n",
      "-- Epoch 1\n",
      "Norm: 197.21, NNZs: 238, Bias: -80.000000, T: 44550, Avg. loss: 8.430281\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 224.48, NNZs: 210, Bias: -80.000000, T: 89100, Avg. loss: 7.092317\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 242.67, NNZs: 190, Bias: -70.000000, T: 133650, Avg. loss: 6.294979\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 264.82, NNZs: 178, Bias: -70.000000, T: 178200, Avg. loss: 5.443724\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 258.49, NNZs: 176, Bias: -65.000000, T: 222750, Avg. loss: 4.887268\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 261.09, NNZs: 150, Bias: -45.000000, T: 267300, Avg. loss: 4.599534\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 271.92, NNZs: 162, Bias: -45.000000, T: 311850, Avg. loss: 4.417634\n",
      "Total training time: 1.56 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 283.15, NNZs: 167, Bias: -50.000000, T: 356400, Avg. loss: 4.174103\n",
      "Total training time: 1.77 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 255.20, NNZs: 152, Bias: -40.000000, T: 400950, Avg. loss: 3.949307\n",
      "Total training time: 1.98 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 279.50, NNZs: 160, Bias: -45.000000, T: 445500, Avg. loss: 3.872267\n",
      "Total training time: 2.20 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 277.91, NNZs: 136, Bias: -40.000000, T: 490050, Avg. loss: 3.902735\n",
      "Total training time: 2.40 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 307.02, NNZs: 125, Bias: -35.000000, T: 534600, Avg. loss: 3.669303\n",
      "Total training time: 2.61 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 298.01, NNZs: 125, Bias: -40.000000, T: 579150, Avg. loss: 3.648462\n",
      "Total training time: 2.82 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 290.27, NNZs: 136, Bias: -40.000000, T: 623700, Avg. loss: 3.659942\n",
      "Total training time: 3.02 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 274.26, NNZs: 137, Bias: -50.000000, T: 668250, Avg. loss: 3.460946\n",
      "Total training time: 3.23 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 269.89, NNZs: 141, Bias: -30.000000, T: 712800, Avg. loss: 3.773321\n",
      "Total training time: 3.44 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 288.41, NNZs: 129, Bias: -20.000000, T: 757350, Avg. loss: 3.430252\n",
      "Total training time: 3.65 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 275.73, NNZs: 118, Bias: -35.000000, T: 801900, Avg. loss: 3.553922\n",
      "Total training time: 3.88 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 279.20, NNZs: 123, Bias: -45.000000, T: 846450, Avg. loss: 3.478912\n",
      "Total training time: 4.10 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 286.55, NNZs: 134, Bias: -45.000000, T: 891000, Avg. loss: 3.517631\n",
      "Total training time: 4.30 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 305.07, NNZs: 144, Bias: -35.000000, T: 935550, Avg. loss: 3.516250\n",
      "Total training time: 4.51 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 302.15, NNZs: 138, Bias: -35.000000, T: 980100, Avg. loss: 3.399943\n",
      "Total training time: 4.71 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 276.22, NNZs: 121, Bias: -45.000000, T: 1024650, Avg. loss: 3.424656\n",
      "Total training time: 4.91 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 319.61, NNZs: 154, Bias: -45.000000, T: 1069200, Avg. loss: 3.404874\n",
      "Total training time: 5.12 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 323.20, NNZs: 141, Bias: -35.000000, T: 1113750, Avg. loss: 3.449344\n",
      "Total training time: 5.31 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 298.24, NNZs: 130, Bias: -35.000000, T: 1158300, Avg. loss: 3.247544\n",
      "Total training time: 5.53 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 308.90, NNZs: 129, Bias: -25.000000, T: 1202850, Avg. loss: 3.248714\n",
      "Total training time: 5.74 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 286.80, NNZs: 134, Bias: -40.000000, T: 1247400, Avg. loss: 3.423291\n",
      "Total training time: 5.94 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 280.22, NNZs: 141, Bias: -45.000000, T: 1291950, Avg. loss: 3.218803\n",
      "Total training time: 6.15 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 279.38, NNZs: 130, Bias: -40.000000, T: 1336500, Avg. loss: 3.329781\n",
      "Total training time: 6.34 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 317.08, NNZs: 140, Bias: -35.000000, T: 1381050, Avg. loss: 3.459080\n",
      "Total training time: 6.56 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 293.83, NNZs: 134, Bias: -40.000000, T: 1425600, Avg. loss: 3.404171\n",
      "Total training time: 6.75 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 299.63, NNZs: 152, Bias: -35.000000, T: 1470150, Avg. loss: 3.374450\n",
      "Total training time: 6.96 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 294.90, NNZs: 137, Bias: -45.000000, T: 1514700, Avg. loss: 3.527688\n",
      "Total training time: 7.16 seconds.\n",
      "-- Epoch 35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 143.56, NNZs: 120, Bias: -12.000000, T: 1559250, Avg. loss: 0.689735\n",
      "Total training time: 7.35 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 136.96, NNZs: 137, Bias: -10.000000, T: 1603800, Avg. loss: 0.706887\n",
      "Total training time: 7.55 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 133.67, NNZs: 138, Bias: -10.000000, T: 1648350, Avg. loss: 0.793640\n",
      "Total training time: 7.75 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 132.68, NNZs: 136, Bias: -8.000000, T: 1692900, Avg. loss: 0.798901\n",
      "Total training time: 7.95 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 127.46, NNZs: 160, Bias: -9.000000, T: 1737450, Avg. loss: 0.861716\n",
      "Total training time: 8.16 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 124.92, NNZs: 167, Bias: -9.000000, T: 1782000, Avg. loss: 0.918331\n",
      "Total training time: 8.38 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 79.86, NNZs: 158, Bias: -4.200000, T: 1826550, Avg. loss: 0.300164\n",
      "Total training time: 8.59 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 66.79, NNZs: 165, Bias: -4.200000, T: 1871100, Avg. loss: 0.287611\n",
      "Total training time: 8.80 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 63.33, NNZs: 157, Bias: -4.400000, T: 1915650, Avg. loss: 0.286389\n",
      "Total training time: 9.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 61.37, NNZs: 159, Bias: -4.200000, T: 1960200, Avg. loss: 0.301238\n",
      "Total training time: 9.23 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 60.81, NNZs: 173, Bias: -3.800000, T: 2004750, Avg. loss: 0.306299\n",
      "Total training time: 9.45 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 60.08, NNZs: 177, Bias: -3.400000, T: 2049300, Avg. loss: 0.311382\n",
      "Total training time: 9.67 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 59.79, NNZs: 180, Bias: -3.200000, T: 2093850, Avg. loss: 0.305924\n",
      "Total training time: 9.89 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 60.11, NNZs: 179, Bias: -4.000000, T: 2138400, Avg. loss: 0.304472\n",
      "Total training time: 10.13 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 53.17, NNZs: 170, Bias: -2.520000, T: 2182950, Avg. loss: 0.196111\n",
      "Total training time: 10.35 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 47.78, NNZs: 181, Bias: -2.160000, T: 2227500, Avg. loss: 0.183112\n",
      "Total training time: 10.58 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 43.33, NNZs: 186, Bias: -1.960000, T: 2272050, Avg. loss: 0.184822\n",
      "Total training time: 10.80 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 39.69, NNZs: 176, Bias: -1.840000, T: 2316600, Avg. loss: 0.184946\n",
      "Total training time: 11.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 36.77, NNZs: 187, Bias: -2.000000, T: 2361150, Avg. loss: 0.185092\n",
      "Total training time: 11.23 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 34.41, NNZs: 190, Bias: -1.760000, T: 2405700, Avg. loss: 0.185652\n",
      "Total training time: 11.44 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 32.67, NNZs: 184, Bias: -2.000000, T: 2450250, Avg. loss: 0.183378\n",
      "Total training time: 11.71 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 31.77, NNZs: 187, Bias: -1.592000, T: 2494800, Avg. loss: 0.159147\n",
      "Total training time: 11.94 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 30.95, NNZs: 187, Bias: -1.448000, T: 2539350, Avg. loss: 0.155061\n",
      "Total training time: 12.17 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 30.17, NNZs: 183, Bias: -1.360000, T: 2583900, Avg. loss: 0.154043\n",
      "Total training time: 12.41 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 29.43, NNZs: 172, Bias: -1.376000, T: 2628450, Avg. loss: 0.152972\n",
      "Total training time: 12.65 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 28.71, NNZs: 171, Bias: -1.272000, T: 2673000, Avg. loss: 0.152715\n",
      "Total training time: 12.88 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 28.03, NNZs: 175, Bias: -1.240000, T: 2717550, Avg. loss: 0.152309\n",
      "Total training time: 13.11 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 27.36, NNZs: 173, Bias: -1.216000, T: 2762100, Avg. loss: 0.152197\n",
      "Total training time: 13.32 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 26.73, NNZs: 175, Bias: -1.232000, T: 2806650, Avg. loss: 0.152035\n",
      "Total training time: 13.56 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 26.10, NNZs: 182, Bias: -1.256000, T: 2851200, Avg. loss: 0.152809\n",
      "Total training time: 13.78 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 25.95, NNZs: 185, Bias: -1.172800, T: 2895750, Avg. loss: 0.147858\n",
      "Total training time: 14.02 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 25.80, NNZs: 187, Bias: -1.126400, T: 2940300, Avg. loss: 0.147141\n",
      "Total training time: 14.25 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 25.65, NNZs: 179, Bias: -1.104000, T: 2984850, Avg. loss: 0.146857\n",
      "Total training time: 14.47 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 25.50, NNZs: 174, Bias: -1.081600, T: 3029400, Avg. loss: 0.146716\n",
      "Total training time: 14.70 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 25.36, NNZs: 177, Bias: -1.070400, T: 3073950, Avg. loss: 0.146436\n",
      "Total training time: 14.92 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 25.22, NNZs: 176, Bias: -1.062400, T: 3118500, Avg. loss: 0.146299\n",
      "Total training time: 15.23 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 25.19, NNZs: 180, Bias: -1.044800, T: 3163050, Avg. loss: 0.145510\n",
      "Total training time: 15.47 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 25.16, NNZs: 172, Bias: -1.036480, T: 3207600, Avg. loss: 0.145337\n",
      "Total training time: 15.71 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 25.13, NNZs: 180, Bias: -1.030080, T: 3252150, Avg. loss: 0.145255\n",
      "Total training time: 15.94 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 25.10, NNZs: 171, Bias: -1.023360, T: 3296700, Avg. loss: 0.145193\n",
      "Total training time: 16.17 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 25.07, NNZs: 173, Bias: -1.018560, T: 3341250, Avg. loss: 0.145145\n",
      "Total training time: 16.40 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 25.06, NNZs: 175, Bias: -1.015232, T: 3385800, Avg. loss: 0.144957\n",
      "Total training time: 16.63 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 25.06, NNZs: 176, Bias: -1.013632, T: 3430350, Avg. loss: 0.144927\n",
      "Total training time: 16.91 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 25.05, NNZs: 179, Bias: -1.011456, T: 3474900, Avg. loss: 0.144911\n",
      "Total training time: 17.16 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 25.04, NNZs: 176, Bias: -1.009536, T: 3519450, Avg. loss: 0.144895\n",
      "Total training time: 17.40 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 25.04, NNZs: 176, Bias: -1.008000, T: 3564000, Avg. loss: 0.144879\n",
      "Total training time: 17.67 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 25.04, NNZs: 177, Bias: -1.007462, T: 3608550, Avg. loss: 0.144837\n",
      "Total training time: 17.89 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 25.04, NNZs: 177, Bias: -1.007027, T: 3653100, Avg. loss: 0.144832\n",
      "Total training time: 18.13 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 25.03, NNZs: 177, Bias: -1.006438, T: 3697650, Avg. loss: 0.144828\n",
      "Total training time: 18.40 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 25.03, NNZs: 177, Bias: -1.006016, T: 3742200, Avg. loss: 0.144825\n",
      "Total training time: 18.67 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 25.03, NNZs: 176, Bias: -1.005709, T: 3786750, Avg. loss: 0.144820\n",
      "Total training time: 18.92 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 25.03, NNZs: 177, Bias: -1.005571, T: 3831300, Avg. loss: 0.144812\n",
      "Total training time: 19.18 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 25.03, NNZs: 177, Bias: -1.005453, T: 3875850, Avg. loss: 0.144810\n",
      "Total training time: 19.45 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 25.03, NNZs: 176, Bias: -1.005299, T: 3920400, Avg. loss: 0.144809\n",
      "Total training time: 19.71 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 25.03, NNZs: 177, Bias: -1.005233, T: 3964950, Avg. loss: 0.144808\n",
      "Total training time: 19.97 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 25.03, NNZs: 177, Bias: -1.005123, T: 4009500, Avg. loss: 0.144808\n",
      "Total training time: 20.22 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 25.03, NNZs: 177, Bias: -1.005102, T: 4054050, Avg. loss: 0.144806\n",
      "Total training time: 20.45 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 25.03, NNZs: 177, Bias: -1.005075, T: 4098600, Avg. loss: 0.144805\n",
      "Total training time: 20.68 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 25.03, NNZs: 177, Bias: -1.005062, T: 4143150, Avg. loss: 0.144805\n",
      "Total training time: 20.97 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 25.03, NNZs: 177, Bias: -1.005039, T: 4187700, Avg. loss: 0.144805\n",
      "Total training time: 21.19 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 25.03, NNZs: 177, Bias: -1.005032, T: 4232250, Avg. loss: 0.144805\n",
      "Total training time: 21.41 seconds.\n",
      "Convergence after 95 epochs took 21.41 seconds\n",
      "-- Epoch 1\n",
      "Norm: 295.66, NNZs: 281, Bias: 0.000000, T: 44550, Avg. loss: 24.622195\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 346.60, NNZs: 238, Bias: 10.000000, T: 89100, Avg. loss: 21.756347\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 359.80, NNZs: 206, Bias: 0.000000, T: 133650, Avg. loss: 19.370536\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 398.59, NNZs: 197, Bias: -5.000000, T: 178200, Avg. loss: 18.120291\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 427.75, NNZs: 156, Bias: -5.000000, T: 222750, Avg. loss: 16.351673\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 427.67, NNZs: 173, Bias: 0.000000, T: 267300, Avg. loss: 15.443701\n",
      "Total training time: 1.50 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 422.46, NNZs: 171, Bias: 5.000000, T: 311850, Avg. loss: 14.559936\n",
      "Total training time: 1.77 seconds.\n",
      "-- Epoch 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 438.49, NNZs: 177, Bias: 5.000000, T: 356400, Avg. loss: 13.600506\n",
      "Total training time: 2.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 443.53, NNZs: 148, Bias: 10.000000, T: 400950, Avg. loss: 13.494617\n",
      "Total training time: 2.26 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 448.89, NNZs: 147, Bias: -10.000000, T: 445500, Avg. loss: 13.042550\n",
      "Total training time: 2.48 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 447.87, NNZs: 131, Bias: 20.000000, T: 490050, Avg. loss: 12.855857\n",
      "Total training time: 2.72 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 479.17, NNZs: 152, Bias: 10.000000, T: 534600, Avg. loss: 12.081544\n",
      "Total training time: 2.94 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 467.34, NNZs: 151, Bias: 5.000000, T: 579150, Avg. loss: 12.337164\n",
      "Total training time: 3.17 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 466.10, NNZs: 143, Bias: 10.000000, T: 623700, Avg. loss: 12.032287\n",
      "Total training time: 3.38 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 479.90, NNZs: 131, Bias: 10.000000, T: 668250, Avg. loss: 11.600915\n",
      "Total training time: 3.61 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 459.34, NNZs: 146, Bias: 15.000000, T: 712800, Avg. loss: 11.427874\n",
      "Total training time: 3.83 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 442.95, NNZs: 161, Bias: -5.000000, T: 757350, Avg. loss: 11.260351\n",
      "Total training time: 4.06 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 463.44, NNZs: 164, Bias: -10.000000, T: 801900, Avg. loss: 11.550608\n",
      "Total training time: 4.30 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 473.68, NNZs: 139, Bias: 5.000000, T: 846450, Avg. loss: 11.475692\n",
      "Total training time: 4.53 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 492.00, NNZs: 134, Bias: 10.000000, T: 891000, Avg. loss: 11.262143\n",
      "Total training time: 4.77 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 469.73, NNZs: 129, Bias: 5.000000, T: 935550, Avg. loss: 10.947073\n",
      "Total training time: 5.02 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 462.65, NNZs: 157, Bias: 5.000000, T: 980100, Avg. loss: 10.934403\n",
      "Total training time: 5.24 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 458.66, NNZs: 136, Bias: 0.000000, T: 1024650, Avg. loss: 11.334483\n",
      "Total training time: 5.47 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 460.69, NNZs: 146, Bias: 0.000000, T: 1069200, Avg. loss: 11.061638\n",
      "Total training time: 5.70 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 479.13, NNZs: 143, Bias: 5.000000, T: 1113750, Avg. loss: 11.066444\n",
      "Total training time: 5.92 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 486.43, NNZs: 143, Bias: 5.000000, T: 1158300, Avg. loss: 10.743723\n",
      "Total training time: 6.14 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 484.93, NNZs: 123, Bias: 10.000000, T: 1202850, Avg. loss: 10.879992\n",
      "Total training time: 6.36 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 472.15, NNZs: 136, Bias: 0.000000, T: 1247400, Avg. loss: 11.002363\n",
      "Total training time: 6.58 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 474.73, NNZs: 135, Bias: 10.000000, T: 1291950, Avg. loss: 10.709792\n",
      "Total training time: 6.80 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 483.03, NNZs: 146, Bias: -10.000000, T: 1336500, Avg. loss: 10.845287\n",
      "Total training time: 7.02 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 470.60, NNZs: 140, Bias: 10.000000, T: 1381050, Avg. loss: 10.926611\n",
      "Total training time: 7.25 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 457.14, NNZs: 131, Bias: 25.000000, T: 1425600, Avg. loss: 10.770570\n",
      "Total training time: 7.47 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 472.35, NNZs: 137, Bias: 5.000000, T: 1470150, Avg. loss: 10.954585\n",
      "Total training time: 7.68 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 469.05, NNZs: 143, Bias: 10.000000, T: 1514700, Avg. loss: 10.814119\n",
      "Total training time: 7.90 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 217.66, NNZs: 155, Bias: 5.000000, T: 1559250, Avg. loss: 2.570381\n",
      "Total training time: 8.12 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 211.19, NNZs: 157, Bias: 0.000000, T: 1603800, Avg. loss: 2.652471\n",
      "Total training time: 8.34 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 203.66, NNZs: 160, Bias: -1.000000, T: 1648350, Avg. loss: 2.735979\n",
      "Total training time: 8.55 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 215.13, NNZs: 166, Bias: 3.000000, T: 1692900, Avg. loss: 2.718953\n",
      "Total training time: 8.78 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 210.30, NNZs: 152, Bias: -1.000000, T: 1737450, Avg. loss: 2.768081\n",
      "Total training time: 9.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 206.59, NNZs: 164, Bias: 2.000000, T: 1782000, Avg. loss: 2.741573\n",
      "Total training time: 9.25 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 128.21, NNZs: 171, Bias: 0.000000, T: 1826550, Avg. loss: 1.015041\n",
      "Total training time: 9.48 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 103.63, NNZs: 185, Bias: 1.600000, T: 1871100, Avg. loss: 1.003841\n",
      "Total training time: 9.73 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 96.73, NNZs: 178, Bias: 1.400000, T: 1915650, Avg. loss: 0.996562\n",
      "Total training time: 9.98 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 95.08, NNZs: 186, Bias: 1.200000, T: 1960200, Avg. loss: 1.010475\n",
      "Total training time: 10.23 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 93.67, NNZs: 196, Bias: 1.600000, T: 2004750, Avg. loss: 1.025154\n",
      "Total training time: 10.47 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 92.57, NNZs: 199, Bias: 1.600000, T: 2049300, Avg. loss: 1.024310\n",
      "Total training time: 10.72 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 92.47, NNZs: 191, Bias: 1.600000, T: 2093850, Avg. loss: 1.034896\n",
      "Total training time: 10.98 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 93.27, NNZs: 194, Bias: 0.400000, T: 2138400, Avg. loss: 1.008622\n",
      "Total training time: 11.22 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 82.49, NNZs: 215, Bias: 0.760000, T: 2182950, Avg. loss: 0.643532\n",
      "Total training time: 11.46 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 74.09, NNZs: 205, Bias: 0.680000, T: 2227500, Avg. loss: 0.633923\n",
      "Total training time: 11.72 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 67.12, NNZs: 215, Bias: 0.800000, T: 2272050, Avg. loss: 0.637184\n",
      "Total training time: 11.97 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 61.52, NNZs: 217, Bias: 0.560000, T: 2316600, Avg. loss: 0.639202\n",
      "Total training time: 12.21 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 56.94, NNZs: 218, Bias: 0.840000, T: 2361150, Avg. loss: 0.639993\n",
      "Total training time: 12.45 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 53.38, NNZs: 225, Bias: 0.760000, T: 2405700, Avg. loss: 0.638827\n",
      "Total training time: 12.70 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 50.54, NNZs: 210, Bias: 0.920000, T: 2450250, Avg. loss: 0.638281\n",
      "Total training time: 12.93 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 49.12, NNZs: 227, Bias: 0.824000, T: 2494800, Avg. loss: 0.551444\n",
      "Total training time: 13.18 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 47.81, NNZs: 230, Bias: 0.792000, T: 2539350, Avg. loss: 0.550182\n",
      "Total training time: 13.42 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 46.59, NNZs: 234, Bias: 0.672000, T: 2583900, Avg. loss: 0.547082\n",
      "Total training time: 13.67 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 45.40, NNZs: 230, Bias: 0.712000, T: 2628450, Avg. loss: 0.550331\n",
      "Total training time: 13.91 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 44.26, NNZs: 231, Bias: 0.664000, T: 2673000, Avg. loss: 0.548507\n",
      "Total training time: 14.18 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 43.16, NNZs: 231, Bias: 0.704000, T: 2717550, Avg. loss: 0.548918\n",
      "Total training time: 14.42 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 42.08, NNZs: 228, Bias: 0.672000, T: 2762100, Avg. loss: 0.547950\n",
      "Total training time: 14.67 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 41.07, NNZs: 232, Bias: 0.632000, T: 2806650, Avg. loss: 0.548773\n",
      "Total training time: 14.89 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 40.81, NNZs: 234, Bias: 0.635200, T: 2851200, Avg. loss: 0.528457\n",
      "Total training time: 15.14 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 40.57, NNZs: 233, Bias: 0.644800, T: 2895750, Avg. loss: 0.526691\n",
      "Total training time: 15.38 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 40.34, NNZs: 234, Bias: 0.632000, T: 2940300, Avg. loss: 0.526582\n",
      "Total training time: 15.62 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 40.10, NNZs: 231, Bias: 0.614400, T: 2984850, Avg. loss: 0.526764\n",
      "Total training time: 15.87 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 39.88, NNZs: 233, Bias: 0.620800, T: 3029400, Avg. loss: 0.526449\n",
      "Total training time: 16.12 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 39.64, NNZs: 232, Bias: 0.625600, T: 3073950, Avg. loss: 0.526090\n",
      "Total training time: 16.36 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 39.42, NNZs: 230, Bias: 0.600000, T: 3118500, Avg. loss: 0.526360\n",
      "Total training time: 16.61 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 39.37, NNZs: 232, Bias: 0.588160, T: 3163050, Avg. loss: 0.521442\n",
      "Total training time: 16.86 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 39.32, NNZs: 234, Bias: 0.588480, T: 3207600, Avg. loss: 0.521390\n",
      "Total training time: 17.10 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 39.28, NNZs: 233, Bias: 0.590400, T: 3252150, Avg. loss: 0.521311\n",
      "Total training time: 17.36 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 39.23, NNZs: 233, Bias: 0.583360, T: 3296700, Avg. loss: 0.521153\n",
      "Total training time: 17.61 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 39.19, NNZs: 233, Bias: 0.586240, T: 3341250, Avg. loss: 0.521328\n",
      "Total training time: 17.86 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 39.14, NNZs: 232, Bias: 0.569600, T: 3385800, Avg. loss: 0.521198\n",
      "Total training time: 18.10 seconds.\n",
      "-- Epoch 77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 39.13, NNZs: 232, Bias: 0.578816, T: 3430350, Avg. loss: 0.520260\n",
      "Total training time: 18.36 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 39.12, NNZs: 232, Bias: 0.581760, T: 3474900, Avg. loss: 0.520058\n",
      "Total training time: 18.61 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 39.11, NNZs: 232, Bias: 0.576448, T: 3519450, Avg. loss: 0.520081\n",
      "Total training time: 18.85 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 39.10, NNZs: 232, Bias: 0.579520, T: 3564000, Avg. loss: 0.520046\n",
      "Total training time: 19.09 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 39.09, NNZs: 232, Bias: 0.578304, T: 3608550, Avg. loss: 0.520024\n",
      "Total training time: 19.36 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 39.09, NNZs: 232, Bias: 0.577766, T: 3653100, Avg. loss: 0.519809\n",
      "Total training time: 19.61 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 39.09, NNZs: 232, Bias: 0.577446, T: 3697650, Avg. loss: 0.519770\n",
      "Total training time: 19.86 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 39.09, NNZs: 232, Bias: 0.577498, T: 3742200, Avg. loss: 0.519783\n",
      "Total training time: 20.10 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 39.09, NNZs: 232, Bias: 0.577728, T: 3786750, Avg. loss: 0.519779\n",
      "Total training time: 20.35 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 39.08, NNZs: 232, Bias: 0.576243, T: 3831300, Avg. loss: 0.519760\n",
      "Total training time: 20.60 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 39.08, NNZs: 232, Bias: 0.576653, T: 3875850, Avg. loss: 0.519720\n",
      "Total training time: 20.83 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 39.08, NNZs: 232, Bias: 0.576783, T: 3920400, Avg. loss: 0.519711\n",
      "Total training time: 21.08 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 39.08, NNZs: 232, Bias: 0.576975, T: 3964950, Avg. loss: 0.519707\n",
      "Total training time: 21.33 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 39.08, NNZs: 232, Bias: 0.577039, T: 4009500, Avg. loss: 0.519706\n",
      "Total training time: 21.57 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 39.08, NNZs: 232, Bias: 0.577019, T: 4054050, Avg. loss: 0.519706\n",
      "Total training time: 21.82 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 39.08, NNZs: 232, Bias: 0.577014, T: 4098600, Avg. loss: 0.519692\n",
      "Total training time: 22.06 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 39.08, NNZs: 232, Bias: 0.577007, T: 4143150, Avg. loss: 0.519692\n",
      "Total training time: 22.31 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 39.08, NNZs: 232, Bias: 0.577005, T: 4187700, Avg. loss: 0.519692\n",
      "Total training time: 22.54 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 39.08, NNZs: 232, Bias: 0.577002, T: 4232250, Avg. loss: 0.519691\n",
      "Total training time: 22.79 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 39.08, NNZs: 232, Bias: 0.576998, T: 4276800, Avg. loss: 0.519691\n",
      "Total training time: 23.03 seconds.\n",
      "Convergence after 96 epochs took 23.03 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7486195286195286"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_adapt = SGDClassifier(verbose=True, penalty='elasticnet', learning_rate='adaptive', l1_ratio=0.15, eta0=5)\n",
    "with joblib.parallel_backend('dask'):\n",
    "    sgd_adapt.fit(train_X, train_y)\n",
    "sgd_adapt.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>alpha</th>\n",
       "      <th>average</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>early_stopping</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>eta0</th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>n_iter_no_change</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>penalty</th>\n",
       "      <th>power_t</th>\n",
       "      <th>random_state</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>tol</th>\n",
       "      <th>validation_fraction</th>\n",
       "      <th>verbose</th>\n",
       "      <th>warm_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SGD_OBO</th>\n",
       "      <td>0.748215</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_BAL</th>\n",
       "      <td>0.734613</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_EL</th>\n",
       "      <td>0.749024</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_ADP</th>\n",
       "      <td>0.749630</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Accuracy   alpha  average class_weight  early_stopping  epsilon  \\\n",
       "SGD_OBO  0.748215  0.0001    False         None           False      0.1   \n",
       "SGD_BAL  0.734613  0.0001    False     balanced           False      0.1   \n",
       "SGD_EL   0.749024  0.0001    False         None           False      0.1   \n",
       "SGD_ADP  0.749630  0.0001    False         None           False      0.1   \n",
       "\n",
       "         eta0  fit_intercept  l1_ratio learning_rate  ... n_iter_no_change  \\\n",
       "SGD_OBO   0.0           True      0.15       optimal  ...                5   \n",
       "SGD_BAL   0.0           True      0.15       optimal  ...                5   \n",
       "SGD_EL    0.0           True      0.15       optimal  ...                5   \n",
       "SGD_ADP   0.0           True      0.15       optimal  ...                5   \n",
       "\n",
       "         n_jobs     penalty power_t random_state  shuffle    tol  \\\n",
       "SGD_OBO    None          l2     0.5         None     True  0.001   \n",
       "SGD_BAL    None          l2     0.5         None     True  0.001   \n",
       "SGD_EL     None  elasticnet     0.5         None     True  0.001   \n",
       "SGD_ADP    None  elasticnet     0.5         None     True  0.001   \n",
       "\n",
       "         validation_fraction  verbose  warm_start  \n",
       "SGD_OBO                  0.1        1       False  \n",
       "SGD_BAL                  0.1        1       False  \n",
       "SGD_EL                   0.1        1       False  \n",
       "SGD_ADP                  0.1        1       False  \n",
       "\n",
       "[4 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = sgd_adapt.get_params()\n",
    "a['Accuracy'] = sgd_adapt.score(test_X, test_y)\n",
    "sgd_deets = pd.concat([sgd_deets, pd.DataFrame(a, index=['SGD_ADP'])], axis=0, join='outer')\n",
    "sgd_deets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7346801346801347"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_huber = SGDClassifier(loss='modified_huber', learning_rate='optimal', l1_ratio=0.15)\n",
    "with joblib.parallel_backend('dask'):\n",
    "    sgd_huber.fit(train_X, train_y)\n",
    "sgd_huber.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>alpha</th>\n",
       "      <th>average</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>early_stopping</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>eta0</th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>n_iter_no_change</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>penalty</th>\n",
       "      <th>power_t</th>\n",
       "      <th>random_state</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>tol</th>\n",
       "      <th>validation_fraction</th>\n",
       "      <th>verbose</th>\n",
       "      <th>warm_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SGD_OBO</th>\n",
       "      <td>0.748215</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_BAL</th>\n",
       "      <td>0.734613</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_EL</th>\n",
       "      <td>0.749024</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_ADP</th>\n",
       "      <td>0.749630</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_HUB</th>\n",
       "      <td>0.734680</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Accuracy   alpha  average class_weight  early_stopping  epsilon  \\\n",
       "SGD_OBO  0.748215  0.0001    False         None           False      0.1   \n",
       "SGD_BAL  0.734613  0.0001    False     balanced           False      0.1   \n",
       "SGD_EL   0.749024  0.0001    False         None           False      0.1   \n",
       "SGD_ADP  0.749630  0.0001    False         None           False      0.1   \n",
       "SGD_HUB  0.734680  0.0001    False         None           False      0.1   \n",
       "\n",
       "         eta0  fit_intercept  l1_ratio learning_rate  ... n_iter_no_change  \\\n",
       "SGD_OBO   0.0           True      0.15       optimal  ...                5   \n",
       "SGD_BAL   0.0           True      0.15       optimal  ...                5   \n",
       "SGD_EL    0.0           True      0.15       optimal  ...                5   \n",
       "SGD_ADP   0.0           True      0.15       optimal  ...                5   \n",
       "SGD_HUB   0.0           True      0.15       optimal  ...                5   \n",
       "\n",
       "         n_jobs     penalty power_t random_state  shuffle    tol  \\\n",
       "SGD_OBO    None          l2     0.5         None     True  0.001   \n",
       "SGD_BAL    None          l2     0.5         None     True  0.001   \n",
       "SGD_EL     None  elasticnet     0.5         None     True  0.001   \n",
       "SGD_ADP    None  elasticnet     0.5         None     True  0.001   \n",
       "SGD_HUB    None          l2     0.5         None     True  0.001   \n",
       "\n",
       "         validation_fraction  verbose  warm_start  \n",
       "SGD_OBO                  0.1        1       False  \n",
       "SGD_BAL                  0.1        1       False  \n",
       "SGD_EL                   0.1        1       False  \n",
       "SGD_ADP                  0.1        1       False  \n",
       "SGD_HUB                  0.1        0       False  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = sgd_huber.get_params()\n",
    "a['Accuracy'] = sgd_huber.score(test_X, test_y)\n",
    "sgd_deets = pd.concat([sgd_deets, pd.DataFrame(a, index=['SGD_HUB'])], axis=0, join='outer')\n",
    "sgd_deets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bwils\\anaconda3\\envs\\pumpitup\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "C:\\Users\\bwils\\anaconda3\\envs\\pumpitup\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "C:\\Users\\bwils\\anaconda3\\envs\\pumpitup\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "C:\\Users\\bwils\\anaconda3\\envs\\pumpitup\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:574: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    }
   ],
   "source": [
    "#run through loop for hyperparameter tuning\n",
    "loss_opt = ['hinge', 'squared_hinge', 'modified_huber'] \n",
    "l1_ratio = [0, .1, .3, .5, .7, 1]\n",
    "penalty = 'elasticnet'\n",
    "class_weight=[None, 'balanced']\n",
    "for weight in class_weight:\n",
    "    for loss in loss_opt:\n",
    "        for l1 in l1_ratio:\n",
    "            sgd = SGDClassifier(loss=loss, l1_ratio=l1, penalty=penalty, class_weight=weight)\n",
    "            with joblib.parallel_backend('dask'):\n",
    "                sgd.fit(train_X, train_y)    \n",
    "            deets = sgd.get_params()\n",
    "            deets['Accuracy']=sgd.score(test_X, test_y)\n",
    "            sgd_deets = pd.concat([sgd_deets, pd.DataFrame(deets, \n",
    "                    index=['SGD_{loss}_{l1}_{weight}'.format(loss=loss,l1=l1, weight=weight)])], axis=0, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>alpha</th>\n",
       "      <th>average</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>early_stopping</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>eta0</th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>n_iter_no_change</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>penalty</th>\n",
       "      <th>power_t</th>\n",
       "      <th>random_state</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>tol</th>\n",
       "      <th>validation_fraction</th>\n",
       "      <th>verbose</th>\n",
       "      <th>warm_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SGD_OBO</th>\n",
       "      <td>0.748215</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_BAL</th>\n",
       "      <td>0.734613</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_EL</th>\n",
       "      <td>0.749024</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_ADP</th>\n",
       "      <td>0.749630</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_HUB</th>\n",
       "      <td>0.734680</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_hinge_0_None</th>\n",
       "      <td>0.750303</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_hinge_0.1_None</th>\n",
       "      <td>0.748350</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.10</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_hinge_0.3_None</th>\n",
       "      <td>0.749024</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.30</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_hinge_0.5_None</th>\n",
       "      <td>0.748552</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.50</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_hinge_0.7_None</th>\n",
       "      <td>0.746936</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.70</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_hinge_1_None</th>\n",
       "      <td>0.743030</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_squared_hinge_0_None</th>\n",
       "      <td>0.619394</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_squared_hinge_0.1_None</th>\n",
       "      <td>0.634478</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.10</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_squared_hinge_0.3_None</th>\n",
       "      <td>0.608620</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.30</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_squared_hinge_0.5_None</th>\n",
       "      <td>0.604781</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.50</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_squared_hinge_0.7_None</th>\n",
       "      <td>0.629226</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.70</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_squared_hinge_1_None</th>\n",
       "      <td>0.617104</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_modified_huber_0_None</th>\n",
       "      <td>0.743300</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_modified_huber_0.1_None</th>\n",
       "      <td>0.745859</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.10</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_modified_huber_0.3_None</th>\n",
       "      <td>0.744108</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.30</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_modified_huber_0.5_None</th>\n",
       "      <td>0.742088</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.50</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_modified_huber_0.7_None</th>\n",
       "      <td>0.741077</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.70</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_modified_huber_1_None</th>\n",
       "      <td>0.745522</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_hinge_0_balanced</th>\n",
       "      <td>0.691785</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_hinge_0.1_balanced</th>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.10</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_hinge_0.3_balanced</th>\n",
       "      <td>0.698855</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.30</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_hinge_0.5_balanced</th>\n",
       "      <td>0.721077</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.50</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_hinge_0.7_balanced</th>\n",
       "      <td>0.697441</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.70</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_hinge_1_balanced</th>\n",
       "      <td>0.711852</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_squared_hinge_0_balanced</th>\n",
       "      <td>0.555421</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_squared_hinge_0.1_balanced</th>\n",
       "      <td>0.563367</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.10</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_squared_hinge_0.3_balanced</th>\n",
       "      <td>0.566195</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.30</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_squared_hinge_0.5_balanced</th>\n",
       "      <td>0.634411</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.50</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_squared_hinge_0.7_balanced</th>\n",
       "      <td>0.549091</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.70</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_squared_hinge_1_balanced</th>\n",
       "      <td>0.601347</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_modified_huber_0_balanced</th>\n",
       "      <td>0.723973</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_modified_huber_0.1_balanced</th>\n",
       "      <td>0.715219</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.10</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_modified_huber_0.3_balanced</th>\n",
       "      <td>0.731515</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.30</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_modified_huber_0.5_balanced</th>\n",
       "      <td>0.690168</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.50</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_modified_huber_0.7_balanced</th>\n",
       "      <td>0.708283</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.70</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD_modified_huber_1_balanced</th>\n",
       "      <td>0.723838</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>False</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "      <td>optimal</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Accuracy   alpha  average class_weight  \\\n",
       "SGD_OBO                          0.748215  0.0001    False         None   \n",
       "SGD_BAL                          0.734613  0.0001    False     balanced   \n",
       "SGD_EL                           0.749024  0.0001    False         None   \n",
       "SGD_ADP                          0.749630  0.0001    False         None   \n",
       "SGD_HUB                          0.734680  0.0001    False         None   \n",
       "SGD_hinge_0_None                 0.750303  0.0001    False         None   \n",
       "SGD_hinge_0.1_None               0.748350  0.0001    False         None   \n",
       "SGD_hinge_0.3_None               0.749024  0.0001    False         None   \n",
       "SGD_hinge_0.5_None               0.748552  0.0001    False         None   \n",
       "SGD_hinge_0.7_None               0.746936  0.0001    False         None   \n",
       "SGD_hinge_1_None                 0.743030  0.0001    False         None   \n",
       "SGD_squared_hinge_0_None         0.619394  0.0001    False         None   \n",
       "SGD_squared_hinge_0.1_None       0.634478  0.0001    False         None   \n",
       "SGD_squared_hinge_0.3_None       0.608620  0.0001    False         None   \n",
       "SGD_squared_hinge_0.5_None       0.604781  0.0001    False         None   \n",
       "SGD_squared_hinge_0.7_None       0.629226  0.0001    False         None   \n",
       "SGD_squared_hinge_1_None         0.617104  0.0001    False         None   \n",
       "SGD_modified_huber_0_None        0.743300  0.0001    False         None   \n",
       "SGD_modified_huber_0.1_None      0.745859  0.0001    False         None   \n",
       "SGD_modified_huber_0.3_None      0.744108  0.0001    False         None   \n",
       "SGD_modified_huber_0.5_None      0.742088  0.0001    False         None   \n",
       "SGD_modified_huber_0.7_None      0.741077  0.0001    False         None   \n",
       "SGD_modified_huber_1_None        0.745522  0.0001    False         None   \n",
       "SGD_hinge_0_balanced             0.691785  0.0001    False     balanced   \n",
       "SGD_hinge_0.1_balanced           0.726667  0.0001    False     balanced   \n",
       "SGD_hinge_0.3_balanced           0.698855  0.0001    False     balanced   \n",
       "SGD_hinge_0.5_balanced           0.721077  0.0001    False     balanced   \n",
       "SGD_hinge_0.7_balanced           0.697441  0.0001    False     balanced   \n",
       "SGD_hinge_1_balanced             0.711852  0.0001    False     balanced   \n",
       "SGD_squared_hinge_0_balanced     0.555421  0.0001    False     balanced   \n",
       "SGD_squared_hinge_0.1_balanced   0.563367  0.0001    False     balanced   \n",
       "SGD_squared_hinge_0.3_balanced   0.566195  0.0001    False     balanced   \n",
       "SGD_squared_hinge_0.5_balanced   0.634411  0.0001    False     balanced   \n",
       "SGD_squared_hinge_0.7_balanced   0.549091  0.0001    False     balanced   \n",
       "SGD_squared_hinge_1_balanced     0.601347  0.0001    False     balanced   \n",
       "SGD_modified_huber_0_balanced    0.723973  0.0001    False     balanced   \n",
       "SGD_modified_huber_0.1_balanced  0.715219  0.0001    False     balanced   \n",
       "SGD_modified_huber_0.3_balanced  0.731515  0.0001    False     balanced   \n",
       "SGD_modified_huber_0.5_balanced  0.690168  0.0001    False     balanced   \n",
       "SGD_modified_huber_0.7_balanced  0.708283  0.0001    False     balanced   \n",
       "SGD_modified_huber_1_balanced    0.723838  0.0001    False     balanced   \n",
       "\n",
       "                                 early_stopping  epsilon  eta0  fit_intercept  \\\n",
       "SGD_OBO                                   False      0.1   0.0           True   \n",
       "SGD_BAL                                   False      0.1   0.0           True   \n",
       "SGD_EL                                    False      0.1   0.0           True   \n",
       "SGD_ADP                                   False      0.1   0.0           True   \n",
       "SGD_HUB                                   False      0.1   0.0           True   \n",
       "SGD_hinge_0_None                          False      0.1   0.0           True   \n",
       "SGD_hinge_0.1_None                        False      0.1   0.0           True   \n",
       "SGD_hinge_0.3_None                        False      0.1   0.0           True   \n",
       "SGD_hinge_0.5_None                        False      0.1   0.0           True   \n",
       "SGD_hinge_0.7_None                        False      0.1   0.0           True   \n",
       "SGD_hinge_1_None                          False      0.1   0.0           True   \n",
       "SGD_squared_hinge_0_None                  False      0.1   0.0           True   \n",
       "SGD_squared_hinge_0.1_None                False      0.1   0.0           True   \n",
       "SGD_squared_hinge_0.3_None                False      0.1   0.0           True   \n",
       "SGD_squared_hinge_0.5_None                False      0.1   0.0           True   \n",
       "SGD_squared_hinge_0.7_None                False      0.1   0.0           True   \n",
       "SGD_squared_hinge_1_None                  False      0.1   0.0           True   \n",
       "SGD_modified_huber_0_None                 False      0.1   0.0           True   \n",
       "SGD_modified_huber_0.1_None               False      0.1   0.0           True   \n",
       "SGD_modified_huber_0.3_None               False      0.1   0.0           True   \n",
       "SGD_modified_huber_0.5_None               False      0.1   0.0           True   \n",
       "SGD_modified_huber_0.7_None               False      0.1   0.0           True   \n",
       "SGD_modified_huber_1_None                 False      0.1   0.0           True   \n",
       "SGD_hinge_0_balanced                      False      0.1   0.0           True   \n",
       "SGD_hinge_0.1_balanced                    False      0.1   0.0           True   \n",
       "SGD_hinge_0.3_balanced                    False      0.1   0.0           True   \n",
       "SGD_hinge_0.5_balanced                    False      0.1   0.0           True   \n",
       "SGD_hinge_0.7_balanced                    False      0.1   0.0           True   \n",
       "SGD_hinge_1_balanced                      False      0.1   0.0           True   \n",
       "SGD_squared_hinge_0_balanced              False      0.1   0.0           True   \n",
       "SGD_squared_hinge_0.1_balanced            False      0.1   0.0           True   \n",
       "SGD_squared_hinge_0.3_balanced            False      0.1   0.0           True   \n",
       "SGD_squared_hinge_0.5_balanced            False      0.1   0.0           True   \n",
       "SGD_squared_hinge_0.7_balanced            False      0.1   0.0           True   \n",
       "SGD_squared_hinge_1_balanced              False      0.1   0.0           True   \n",
       "SGD_modified_huber_0_balanced             False      0.1   0.0           True   \n",
       "SGD_modified_huber_0.1_balanced           False      0.1   0.0           True   \n",
       "SGD_modified_huber_0.3_balanced           False      0.1   0.0           True   \n",
       "SGD_modified_huber_0.5_balanced           False      0.1   0.0           True   \n",
       "SGD_modified_huber_0.7_balanced           False      0.1   0.0           True   \n",
       "SGD_modified_huber_1_balanced             False      0.1   0.0           True   \n",
       "\n",
       "                                 l1_ratio learning_rate  ... n_iter_no_change  \\\n",
       "SGD_OBO                              0.15       optimal  ...                5   \n",
       "SGD_BAL                              0.15       optimal  ...                5   \n",
       "SGD_EL                               0.15       optimal  ...                5   \n",
       "SGD_ADP                              0.15       optimal  ...                5   \n",
       "SGD_HUB                              0.15       optimal  ...                5   \n",
       "SGD_hinge_0_None                     0.00       optimal  ...                5   \n",
       "SGD_hinge_0.1_None                   0.10       optimal  ...                5   \n",
       "SGD_hinge_0.3_None                   0.30       optimal  ...                5   \n",
       "SGD_hinge_0.5_None                   0.50       optimal  ...                5   \n",
       "SGD_hinge_0.7_None                   0.70       optimal  ...                5   \n",
       "SGD_hinge_1_None                     1.00       optimal  ...                5   \n",
       "SGD_squared_hinge_0_None             0.00       optimal  ...                5   \n",
       "SGD_squared_hinge_0.1_None           0.10       optimal  ...                5   \n",
       "SGD_squared_hinge_0.3_None           0.30       optimal  ...                5   \n",
       "SGD_squared_hinge_0.5_None           0.50       optimal  ...                5   \n",
       "SGD_squared_hinge_0.7_None           0.70       optimal  ...                5   \n",
       "SGD_squared_hinge_1_None             1.00       optimal  ...                5   \n",
       "SGD_modified_huber_0_None            0.00       optimal  ...                5   \n",
       "SGD_modified_huber_0.1_None          0.10       optimal  ...                5   \n",
       "SGD_modified_huber_0.3_None          0.30       optimal  ...                5   \n",
       "SGD_modified_huber_0.5_None          0.50       optimal  ...                5   \n",
       "SGD_modified_huber_0.7_None          0.70       optimal  ...                5   \n",
       "SGD_modified_huber_1_None            1.00       optimal  ...                5   \n",
       "SGD_hinge_0_balanced                 0.00       optimal  ...                5   \n",
       "SGD_hinge_0.1_balanced               0.10       optimal  ...                5   \n",
       "SGD_hinge_0.3_balanced               0.30       optimal  ...                5   \n",
       "SGD_hinge_0.5_balanced               0.50       optimal  ...                5   \n",
       "SGD_hinge_0.7_balanced               0.70       optimal  ...                5   \n",
       "SGD_hinge_1_balanced                 1.00       optimal  ...                5   \n",
       "SGD_squared_hinge_0_balanced         0.00       optimal  ...                5   \n",
       "SGD_squared_hinge_0.1_balanced       0.10       optimal  ...                5   \n",
       "SGD_squared_hinge_0.3_balanced       0.30       optimal  ...                5   \n",
       "SGD_squared_hinge_0.5_balanced       0.50       optimal  ...                5   \n",
       "SGD_squared_hinge_0.7_balanced       0.70       optimal  ...                5   \n",
       "SGD_squared_hinge_1_balanced         1.00       optimal  ...                5   \n",
       "SGD_modified_huber_0_balanced        0.00       optimal  ...                5   \n",
       "SGD_modified_huber_0.1_balanced      0.10       optimal  ...                5   \n",
       "SGD_modified_huber_0.3_balanced      0.30       optimal  ...                5   \n",
       "SGD_modified_huber_0.5_balanced      0.50       optimal  ...                5   \n",
       "SGD_modified_huber_0.7_balanced      0.70       optimal  ...                5   \n",
       "SGD_modified_huber_1_balanced        1.00       optimal  ...                5   \n",
       "\n",
       "                                 n_jobs     penalty power_t random_state  \\\n",
       "SGD_OBO                            None          l2     0.5         None   \n",
       "SGD_BAL                            None          l2     0.5         None   \n",
       "SGD_EL                             None  elasticnet     0.5         None   \n",
       "SGD_ADP                            None  elasticnet     0.5         None   \n",
       "SGD_HUB                            None          l2     0.5         None   \n",
       "SGD_hinge_0_None                   None  elasticnet     0.5         None   \n",
       "SGD_hinge_0.1_None                 None  elasticnet     0.5         None   \n",
       "SGD_hinge_0.3_None                 None  elasticnet     0.5         None   \n",
       "SGD_hinge_0.5_None                 None  elasticnet     0.5         None   \n",
       "SGD_hinge_0.7_None                 None  elasticnet     0.5         None   \n",
       "SGD_hinge_1_None                   None  elasticnet     0.5         None   \n",
       "SGD_squared_hinge_0_None           None  elasticnet     0.5         None   \n",
       "SGD_squared_hinge_0.1_None         None  elasticnet     0.5         None   \n",
       "SGD_squared_hinge_0.3_None         None  elasticnet     0.5         None   \n",
       "SGD_squared_hinge_0.5_None         None  elasticnet     0.5         None   \n",
       "SGD_squared_hinge_0.7_None         None  elasticnet     0.5         None   \n",
       "SGD_squared_hinge_1_None           None  elasticnet     0.5         None   \n",
       "SGD_modified_huber_0_None          None  elasticnet     0.5         None   \n",
       "SGD_modified_huber_0.1_None        None  elasticnet     0.5         None   \n",
       "SGD_modified_huber_0.3_None        None  elasticnet     0.5         None   \n",
       "SGD_modified_huber_0.5_None        None  elasticnet     0.5         None   \n",
       "SGD_modified_huber_0.7_None        None  elasticnet     0.5         None   \n",
       "SGD_modified_huber_1_None          None  elasticnet     0.5         None   \n",
       "SGD_hinge_0_balanced               None  elasticnet     0.5         None   \n",
       "SGD_hinge_0.1_balanced             None  elasticnet     0.5         None   \n",
       "SGD_hinge_0.3_balanced             None  elasticnet     0.5         None   \n",
       "SGD_hinge_0.5_balanced             None  elasticnet     0.5         None   \n",
       "SGD_hinge_0.7_balanced             None  elasticnet     0.5         None   \n",
       "SGD_hinge_1_balanced               None  elasticnet     0.5         None   \n",
       "SGD_squared_hinge_0_balanced       None  elasticnet     0.5         None   \n",
       "SGD_squared_hinge_0.1_balanced     None  elasticnet     0.5         None   \n",
       "SGD_squared_hinge_0.3_balanced     None  elasticnet     0.5         None   \n",
       "SGD_squared_hinge_0.5_balanced     None  elasticnet     0.5         None   \n",
       "SGD_squared_hinge_0.7_balanced     None  elasticnet     0.5         None   \n",
       "SGD_squared_hinge_1_balanced       None  elasticnet     0.5         None   \n",
       "SGD_modified_huber_0_balanced      None  elasticnet     0.5         None   \n",
       "SGD_modified_huber_0.1_balanced    None  elasticnet     0.5         None   \n",
       "SGD_modified_huber_0.3_balanced    None  elasticnet     0.5         None   \n",
       "SGD_modified_huber_0.5_balanced    None  elasticnet     0.5         None   \n",
       "SGD_modified_huber_0.7_balanced    None  elasticnet     0.5         None   \n",
       "SGD_modified_huber_1_balanced      None  elasticnet     0.5         None   \n",
       "\n",
       "                                 shuffle    tol  validation_fraction  verbose  \\\n",
       "SGD_OBO                             True  0.001                  0.1        1   \n",
       "SGD_BAL                             True  0.001                  0.1        1   \n",
       "SGD_EL                              True  0.001                  0.1        1   \n",
       "SGD_ADP                             True  0.001                  0.1        1   \n",
       "SGD_HUB                             True  0.001                  0.1        0   \n",
       "SGD_hinge_0_None                    True  0.001                  0.1        0   \n",
       "SGD_hinge_0.1_None                  True  0.001                  0.1        0   \n",
       "SGD_hinge_0.3_None                  True  0.001                  0.1        0   \n",
       "SGD_hinge_0.5_None                  True  0.001                  0.1        0   \n",
       "SGD_hinge_0.7_None                  True  0.001                  0.1        0   \n",
       "SGD_hinge_1_None                    True  0.001                  0.1        0   \n",
       "SGD_squared_hinge_0_None            True  0.001                  0.1        0   \n",
       "SGD_squared_hinge_0.1_None          True  0.001                  0.1        0   \n",
       "SGD_squared_hinge_0.3_None          True  0.001                  0.1        0   \n",
       "SGD_squared_hinge_0.5_None          True  0.001                  0.1        0   \n",
       "SGD_squared_hinge_0.7_None          True  0.001                  0.1        0   \n",
       "SGD_squared_hinge_1_None            True  0.001                  0.1        0   \n",
       "SGD_modified_huber_0_None           True  0.001                  0.1        0   \n",
       "SGD_modified_huber_0.1_None         True  0.001                  0.1        0   \n",
       "SGD_modified_huber_0.3_None         True  0.001                  0.1        0   \n",
       "SGD_modified_huber_0.5_None         True  0.001                  0.1        0   \n",
       "SGD_modified_huber_0.7_None         True  0.001                  0.1        0   \n",
       "SGD_modified_huber_1_None           True  0.001                  0.1        0   \n",
       "SGD_hinge_0_balanced                True  0.001                  0.1        0   \n",
       "SGD_hinge_0.1_balanced              True  0.001                  0.1        0   \n",
       "SGD_hinge_0.3_balanced              True  0.001                  0.1        0   \n",
       "SGD_hinge_0.5_balanced              True  0.001                  0.1        0   \n",
       "SGD_hinge_0.7_balanced              True  0.001                  0.1        0   \n",
       "SGD_hinge_1_balanced                True  0.001                  0.1        0   \n",
       "SGD_squared_hinge_0_balanced        True  0.001                  0.1        0   \n",
       "SGD_squared_hinge_0.1_balanced      True  0.001                  0.1        0   \n",
       "SGD_squared_hinge_0.3_balanced      True  0.001                  0.1        0   \n",
       "SGD_squared_hinge_0.5_balanced      True  0.001                  0.1        0   \n",
       "SGD_squared_hinge_0.7_balanced      True  0.001                  0.1        0   \n",
       "SGD_squared_hinge_1_balanced        True  0.001                  0.1        0   \n",
       "SGD_modified_huber_0_balanced       True  0.001                  0.1        0   \n",
       "SGD_modified_huber_0.1_balanced     True  0.001                  0.1        0   \n",
       "SGD_modified_huber_0.3_balanced     True  0.001                  0.1        0   \n",
       "SGD_modified_huber_0.5_balanced     True  0.001                  0.1        0   \n",
       "SGD_modified_huber_0.7_balanced     True  0.001                  0.1        0   \n",
       "SGD_modified_huber_1_balanced       True  0.001                  0.1        0   \n",
       "\n",
       "                                 warm_start  \n",
       "SGD_OBO                               False  \n",
       "SGD_BAL                               False  \n",
       "SGD_EL                                False  \n",
       "SGD_ADP                               False  \n",
       "SGD_HUB                               False  \n",
       "SGD_hinge_0_None                      False  \n",
       "SGD_hinge_0.1_None                    False  \n",
       "SGD_hinge_0.3_None                    False  \n",
       "SGD_hinge_0.5_None                    False  \n",
       "SGD_hinge_0.7_None                    False  \n",
       "SGD_hinge_1_None                      False  \n",
       "SGD_squared_hinge_0_None              False  \n",
       "SGD_squared_hinge_0.1_None            False  \n",
       "SGD_squared_hinge_0.3_None            False  \n",
       "SGD_squared_hinge_0.5_None            False  \n",
       "SGD_squared_hinge_0.7_None            False  \n",
       "SGD_squared_hinge_1_None              False  \n",
       "SGD_modified_huber_0_None             False  \n",
       "SGD_modified_huber_0.1_None           False  \n",
       "SGD_modified_huber_0.3_None           False  \n",
       "SGD_modified_huber_0.5_None           False  \n",
       "SGD_modified_huber_0.7_None           False  \n",
       "SGD_modified_huber_1_None             False  \n",
       "SGD_hinge_0_balanced                  False  \n",
       "SGD_hinge_0.1_balanced                False  \n",
       "SGD_hinge_0.3_balanced                False  \n",
       "SGD_hinge_0.5_balanced                False  \n",
       "SGD_hinge_0.7_balanced                False  \n",
       "SGD_hinge_1_balanced                  False  \n",
       "SGD_squared_hinge_0_balanced          False  \n",
       "SGD_squared_hinge_0.1_balanced        False  \n",
       "SGD_squared_hinge_0.3_balanced        False  \n",
       "SGD_squared_hinge_0.5_balanced        False  \n",
       "SGD_squared_hinge_0.7_balanced        False  \n",
       "SGD_squared_hinge_1_balanced          False  \n",
       "SGD_modified_huber_0_balanced         False  \n",
       "SGD_modified_huber_0.1_balanced       False  \n",
       "SGD_modified_huber_0.3_balanced       False  \n",
       "SGD_modified_huber_0.5_balanced       False  \n",
       "SGD_modified_huber_0.7_balanced       False  \n",
       "SGD_modified_huber_1_balanced         False  \n",
       "\n",
       "[41 rows x 22 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_deets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.65      0.72      5678\n",
      "           1       0.48      0.02      0.04      1074\n",
      "           2       0.72      0.92      0.81      8098\n",
      "\n",
      "    accuracy                           0.75     14850\n",
      "   macro avg       0.67      0.53      0.52     14850\n",
      "weighted avg       0.74      0.75      0.72     14850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#visual metrics on class basis for best model using confusion matrix and classificaiton report\n",
    "y_pred = sgd_adapt.predict(test_X)\n",
    "cm=confusion_matrix(test_y, y_pred, labels=sgd_adapt.classes_)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=sgd_adapt.classes_)\n",
    "plt.figure(figsize=(40,8))\n",
    "disp.plot()\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "print(classification_report(test_y, y_pred, labels=sgd_adapt.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 287.55, NNZs: 304, Bias: -35.000000, T: 35640, Avg. loss: 21.925194\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 299.61, NNZs: 264, Bias: -20.000000, T: 71280, Avg. loss: 19.832615\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 348.22, NNZs: 218, Bias: -35.000000, T: 106920, Avg. loss: 18.092534\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 369.29, NNZs: 199, Bias: -35.000000, T: 142560, Avg. loss: 16.799689\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 366.27, NNZs: 207, Bias: -25.000000, T: 178200, Avg. loss: 15.507760\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 418.72, NNZs: 184, Bias: -30.000000, T: 213840, Avg. loss: 14.387578\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 411.26, NNZs: 192, Bias: -25.000000, T: 249480, Avg. loss: 13.833711\n",
      "Total training time: 1.38 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 403.62, NNZs: 188, Bias: -20.000000, T: 285120, Avg. loss: 13.631066\n",
      "Total training time: 1.57 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 418.92, NNZs: 153, Bias: -20.000000, T: 320760, Avg. loss: 12.722644\n",
      "Total training time: 1.75 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 403.59, NNZs: 161, Bias: -35.000000, T: 356400, Avg. loss: 12.624509\n",
      "Total training time: 1.93 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 416.24, NNZs: 149, Bias: -25.000000, T: 392040, Avg. loss: 12.531327\n",
      "Total training time: 2.12 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 426.12, NNZs: 162, Bias: -20.000000, T: 427680, Avg. loss: 11.714269\n",
      "Total training time: 2.31 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 410.20, NNZs: 153, Bias: -5.000000, T: 463320, Avg. loss: 11.888143\n",
      "Total training time: 2.51 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 429.52, NNZs: 163, Bias: -20.000000, T: 498960, Avg. loss: 11.936676\n",
      "Total training time: 2.70 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 446.48, NNZs: 142, Bias: -20.000000, T: 534600, Avg. loss: 11.631643\n",
      "Total training time: 2.88 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 435.64, NNZs: 139, Bias: -20.000000, T: 570240, Avg. loss: 10.830506\n",
      "Total training time: 3.08 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 432.71, NNZs: 160, Bias: -15.000000, T: 605880, Avg. loss: 10.909742\n",
      "Total training time: 3.26 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 414.85, NNZs: 149, Bias: -10.000000, T: 641520, Avg. loss: 11.196072\n",
      "Total training time: 3.44 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 447.52, NNZs: 170, Bias: -30.000000, T: 677160, Avg. loss: 11.414064\n",
      "Total training time: 3.63 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 446.11, NNZs: 163, Bias: -20.000000, T: 712800, Avg. loss: 10.962480\n",
      "Total training time: 3.80 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 440.43, NNZs: 161, Bias: -30.000000, T: 748440, Avg. loss: 10.558210\n",
      "Total training time: 3.98 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 433.31, NNZs: 150, Bias: -20.000000, T: 784080, Avg. loss: 10.739616\n",
      "Total training time: 4.17 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 443.00, NNZs: 158, Bias: -15.000000, T: 819720, Avg. loss: 10.724768\n",
      "Total training time: 4.35 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 430.00, NNZs: 142, Bias: -5.000000, T: 855360, Avg. loss: 10.860744\n",
      "Total training time: 4.53 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 428.84, NNZs: 157, Bias: -15.000000, T: 891000, Avg. loss: 10.286970\n",
      "Total training time: 4.72 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 450.18, NNZs: 152, Bias: -15.000000, T: 926640, Avg. loss: 10.783210\n",
      "Total training time: 4.92 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 434.18, NNZs: 144, Bias: -20.000000, T: 962280, Avg. loss: 10.475248\n",
      "Total training time: 5.10 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 430.74, NNZs: 160, Bias: -25.000000, T: 997920, Avg. loss: 10.851813\n",
      "Total training time: 5.29 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 419.82, NNZs: 157, Bias: -25.000000, T: 1033560, Avg. loss: 10.619558\n",
      "Total training time: 5.46 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 428.40, NNZs: 171, Bias: -15.000000, T: 1069200, Avg. loss: 10.413953\n",
      "Total training time: 5.65 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 195.79, NNZs: 149, Bias: -8.000000, T: 1104840, Avg. loss: 2.545042\n",
      "Total training time: 5.81 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 190.26, NNZs: 165, Bias: -13.000000, T: 1140480, Avg. loss: 2.441840\n",
      "Total training time: 6.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 186.18, NNZs: 168, Bias: -5.000000, T: 1176120, Avg. loss: 2.661063\n",
      "Total training time: 6.19 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 185.40, NNZs: 179, Bias: -9.000000, T: 1211760, Avg. loss: 2.746020\n",
      "Total training time: 6.36 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 183.45, NNZs: 178, Bias: -9.000000, T: 1247400, Avg. loss: 2.610980\n",
      "Total training time: 6.55 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 188.30, NNZs: 177, Bias: -7.000000, T: 1283040, Avg. loss: 2.693585\n",
      "Total training time: 6.75 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 181.36, NNZs: 176, Bias: -9.000000, T: 1318680, Avg. loss: 2.640867\n",
      "Total training time: 6.94 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 119.75, NNZs: 182, Bias: -4.000000, T: 1354320, Avg. loss: 0.962541\n",
      "Total training time: 7.12 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 95.85, NNZs: 183, Bias: -4.800000, T: 1389960, Avg. loss: 0.915174\n",
      "Total training time: 7.32 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 87.30, NNZs: 195, Bias: -4.600000, T: 1425600, Avg. loss: 0.910624\n",
      "Total training time: 7.51 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 84.92, NNZs: 200, Bias: -4.200000, T: 1461240, Avg. loss: 0.922440\n",
      "Total training time: 7.71 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 83.76, NNZs: 196, Bias: -4.400000, T: 1496880, Avg. loss: 0.919053\n",
      "Total training time: 7.91 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 82.35, NNZs: 213, Bias: -4.200000, T: 1532520, Avg. loss: 0.947672\n",
      "Total training time: 8.10 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 83.52, NNZs: 203, Bias: -3.800000, T: 1568160, Avg. loss: 0.919864\n",
      "Total training time: 8.29 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 83.43, NNZs: 204, Bias: -3.600000, T: 1603800, Avg. loss: 0.931673\n",
      "Total training time: 8.47 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 75.18, NNZs: 217, Bias: -3.000000, T: 1639440, Avg. loss: 0.568288\n",
      "Total training time: 8.66 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 68.68, NNZs: 218, Bias: -2.800000, T: 1675080, Avg. loss: 0.553521\n",
      "Total training time: 8.84 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 63.24, NNZs: 225, Bias: -2.640000, T: 1710720, Avg. loss: 0.550764\n",
      "Total training time: 9.02 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 58.55, NNZs: 223, Bias: -2.400000, T: 1746360, Avg. loss: 0.553379\n",
      "Total training time: 9.21 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 54.63, NNZs: 220, Bias: -2.400000, T: 1782000, Avg. loss: 0.553909\n",
      "Total training time: 9.39 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 51.27, NNZs: 222, Bias: -2.560000, T: 1817640, Avg. loss: 0.554563\n",
      "Total training time: 9.58 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 48.42, NNZs: 219, Bias: -2.160000, T: 1853280, Avg. loss: 0.556229\n",
      "Total training time: 9.76 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 46.08, NNZs: 218, Bias: -2.160000, T: 1888920, Avg. loss: 0.555563\n",
      "Total training time: 9.94 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 44.95, NNZs: 229, Bias: -2.232000, T: 1924560, Avg. loss: 0.470997\n",
      "Total training time: 10.12 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 43.97, NNZs: 230, Bias: -2.184000, T: 1960200, Avg. loss: 0.465964\n",
      "Total training time: 10.29 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 43.03, NNZs: 231, Bias: -2.160000, T: 1995840, Avg. loss: 0.463830\n",
      "Total training time: 10.48 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 42.14, NNZs: 228, Bias: -2.048000, T: 2031480, Avg. loss: 0.464038\n",
      "Total training time: 10.67 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 41.28, NNZs: 232, Bias: -2.032000, T: 2067120, Avg. loss: 0.462894\n",
      "Total training time: 10.85 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 40.44, NNZs: 227, Bias: -1.992000, T: 2102760, Avg. loss: 0.463407\n",
      "Total training time: 11.03 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 39.63, NNZs: 231, Bias: -1.968000, T: 2138400, Avg. loss: 0.464034\n",
      "Total training time: 11.23 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 38.84, NNZs: 232, Bias: -2.032000, T: 2174040, Avg. loss: 0.462790\n",
      "Total training time: 11.42 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 38.64, NNZs: 231, Bias: -2.022400, T: 2209680, Avg. loss: 0.444931\n",
      "Total training time: 11.60 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 38.46, NNZs: 231, Bias: -2.014400, T: 2245320, Avg. loss: 0.443745\n",
      "Total training time: 11.78 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 38.28, NNZs: 231, Bias: -2.006400, T: 2280960, Avg. loss: 0.443404\n",
      "Total training time: 11.97 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 38.10, NNZs: 230, Bias: -1.977600, T: 2316600, Avg. loss: 0.443168\n",
      "Total training time: 12.15 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 37.92, NNZs: 230, Bias: -1.974400, T: 2352240, Avg. loss: 0.443020\n",
      "Total training time: 12.33 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 37.74, NNZs: 228, Bias: -1.987200, T: 2387880, Avg. loss: 0.443121\n",
      "Total training time: 12.51 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 37.56, NNZs: 229, Bias: -2.001600, T: 2423520, Avg. loss: 0.443317\n",
      "Total training time: 12.70 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 37.53, NNZs: 229, Bias: -1.995520, T: 2459160, Avg. loss: 0.439154\n",
      "Total training time: 12.88 seconds.\n",
      "-- Epoch 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 37.49, NNZs: 228, Bias: -1.990400, T: 2494800, Avg. loss: 0.438947\n",
      "Total training time: 13.08 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 37.45, NNZs: 229, Bias: -1.987200, T: 2530440, Avg. loss: 0.438873\n",
      "Total training time: 13.26 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 37.42, NNZs: 231, Bias: -1.977600, T: 2566080, Avg. loss: 0.438796\n",
      "Total training time: 13.44 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 37.38, NNZs: 230, Bias: -1.974080, T: 2601720, Avg. loss: 0.438710\n",
      "Total training time: 13.63 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 37.35, NNZs: 230, Bias: -1.975360, T: 2637360, Avg. loss: 0.438817\n",
      "Total training time: 13.82 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 37.34, NNZs: 230, Bias: -1.974080, T: 2673000, Avg. loss: 0.437836\n",
      "Total training time: 14.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 37.33, NNZs: 230, Bias: -1.974656, T: 2708640, Avg. loss: 0.437794\n",
      "Total training time: 14.19 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 37.32, NNZs: 230, Bias: -1.972736, T: 2744280, Avg. loss: 0.437792\n",
      "Total training time: 14.37 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 37.32, NNZs: 230, Bias: -1.972160, T: 2779920, Avg. loss: 0.437799\n",
      "Total training time: 14.57 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 37.31, NNZs: 230, Bias: -1.971328, T: 2815560, Avg. loss: 0.437724\n",
      "Total training time: 14.75 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 37.31, NNZs: 230, Bias: -1.972749, T: 2851200, Avg. loss: 0.437584\n",
      "Total training time: 14.94 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 37.31, NNZs: 230, Bias: -1.972749, T: 2886840, Avg. loss: 0.437559\n",
      "Total training time: 15.13 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 37.30, NNZs: 230, Bias: -1.972506, T: 2922480, Avg. loss: 0.437551\n",
      "Total training time: 15.31 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 37.30, NNZs: 230, Bias: -1.972288, T: 2958120, Avg. loss: 0.437552\n",
      "Total training time: 15.50 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 37.30, NNZs: 231, Bias: -1.972851, T: 2993760, Avg. loss: 0.437541\n",
      "Total training time: 15.69 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 37.30, NNZs: 230, Bias: -1.972506, T: 3029400, Avg. loss: 0.437496\n",
      "Total training time: 15.87 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 37.30, NNZs: 230, Bias: -1.972370, T: 3065040, Avg. loss: 0.437492\n",
      "Total training time: 16.06 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 37.30, NNZs: 230, Bias: -1.972250, T: 3100680, Avg. loss: 0.437490\n",
      "Total training time: 16.24 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 37.30, NNZs: 230, Bias: -1.972260, T: 3136320, Avg. loss: 0.437490\n",
      "Total training time: 16.43 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 37.30, NNZs: 230, Bias: -1.972308, T: 3171960, Avg. loss: 0.437488\n",
      "Total training time: 16.61 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 37.30, NNZs: 230, Bias: -1.972287, T: 3207600, Avg. loss: 0.437478\n",
      "Total training time: 16.79 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 37.30, NNZs: 230, Bias: -1.972270, T: 3243240, Avg. loss: 0.437477\n",
      "Total training time: 16.98 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 37.30, NNZs: 230, Bias: -1.972256, T: 3278880, Avg. loss: 0.437477\n",
      "Total training time: 17.17 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 37.30, NNZs: 230, Bias: -1.972243, T: 3314520, Avg. loss: 0.437477\n",
      "Total training time: 17.34 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 37.30, NNZs: 230, Bias: -1.972228, T: 3350160, Avg. loss: 0.437477\n",
      "Total training time: 17.53 seconds.\n",
      "Convergence after 94 epochs took 17.53 seconds\n",
      "-- Epoch 1\n",
      "Norm: 195.78, NNZs: 257, Bias: -90.000000, T: 35640, Avg. loss: 8.649616\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 222.05, NNZs: 216, Bias: -80.000000, T: 71280, Avg. loss: 7.490345\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 251.44, NNZs: 204, Bias: -85.000000, T: 106920, Avg. loss: 6.553036\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 244.59, NNZs: 184, Bias: -65.000000, T: 142560, Avg. loss: 5.924173\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 266.46, NNZs: 185, Bias: -75.000000, T: 178200, Avg. loss: 5.366360\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 281.03, NNZs: 168, Bias: -70.000000, T: 213840, Avg. loss: 4.994892\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 274.23, NNZs: 157, Bias: -45.000000, T: 249480, Avg. loss: 4.828392\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 307.71, NNZs: 161, Bias: -50.000000, T: 285120, Avg. loss: 4.619200\n",
      "Total training time: 1.48 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 301.65, NNZs: 157, Bias: -40.000000, T: 320760, Avg. loss: 4.386688\n",
      "Total training time: 1.65 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 309.58, NNZs: 154, Bias: -45.000000, T: 356400, Avg. loss: 4.241878\n",
      "Total training time: 1.82 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 288.69, NNZs: 148, Bias: -45.000000, T: 392040, Avg. loss: 4.070633\n",
      "Total training time: 2.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 299.35, NNZs: 128, Bias: -35.000000, T: 427680, Avg. loss: 3.979050\n",
      "Total training time: 2.17 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 276.17, NNZs: 144, Bias: -35.000000, T: 463320, Avg. loss: 3.830890\n",
      "Total training time: 2.34 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 303.27, NNZs: 151, Bias: -30.000000, T: 498960, Avg. loss: 3.821542\n",
      "Total training time: 2.51 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 280.24, NNZs: 155, Bias: -50.000000, T: 534600, Avg. loss: 3.622280\n",
      "Total training time: 2.68 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 286.17, NNZs: 150, Bias: -45.000000, T: 570240, Avg. loss: 3.787541\n",
      "Total training time: 2.85 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 279.01, NNZs: 146, Bias: -45.000000, T: 605880, Avg. loss: 3.631515\n",
      "Total training time: 3.02 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 285.47, NNZs: 138, Bias: -50.000000, T: 641520, Avg. loss: 3.631247\n",
      "Total training time: 3.19 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 304.12, NNZs: 142, Bias: -30.000000, T: 677160, Avg. loss: 3.529196\n",
      "Total training time: 3.37 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 296.18, NNZs: 131, Bias: -25.000000, T: 712800, Avg. loss: 3.484810\n",
      "Total training time: 3.54 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 296.38, NNZs: 121, Bias: -30.000000, T: 748440, Avg. loss: 3.478279\n",
      "Total training time: 3.71 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 276.84, NNZs: 130, Bias: -30.000000, T: 784080, Avg. loss: 3.263852\n",
      "Total training time: 3.89 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 291.90, NNZs: 140, Bias: -45.000000, T: 819720, Avg. loss: 3.389454\n",
      "Total training time: 4.07 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 289.02, NNZs: 152, Bias: -45.000000, T: 855360, Avg. loss: 3.353154\n",
      "Total training time: 4.24 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 293.27, NNZs: 137, Bias: -35.000000, T: 891000, Avg. loss: 3.526531\n",
      "Total training time: 4.40 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 293.12, NNZs: 133, Bias: -35.000000, T: 926640, Avg. loss: 3.449292\n",
      "Total training time: 4.57 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 287.98, NNZs: 136, Bias: -40.000000, T: 962280, Avg. loss: 3.443095\n",
      "Total training time: 4.74 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 141.16, NNZs: 132, Bias: -13.000000, T: 997920, Avg. loss: 0.755730\n",
      "Total training time: 4.90 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 135.70, NNZs: 142, Bias: -14.000000, T: 1033560, Avg. loss: 0.748421\n",
      "Total training time: 5.07 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 128.29, NNZs: 153, Bias: -10.000000, T: 1069200, Avg. loss: 0.827193\n",
      "Total training time: 5.24 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 132.61, NNZs: 160, Bias: -13.000000, T: 1104840, Avg. loss: 0.848626\n",
      "Total training time: 5.41 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 128.74, NNZs: 166, Bias: -11.000000, T: 1140480, Avg. loss: 0.839377\n",
      "Total training time: 5.59 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 128.04, NNZs: 159, Bias: -12.000000, T: 1176120, Avg. loss: 0.855601\n",
      "Total training time: 5.78 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 123.25, NNZs: 173, Bias: -10.000000, T: 1211760, Avg. loss: 0.918866\n",
      "Total training time: 5.97 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 84.52, NNZs: 170, Bias: -4.000000, T: 1247400, Avg. loss: 0.313153\n",
      "Total training time: 6.15 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 69.58, NNZs: 170, Bias: -4.400000, T: 1283040, Avg. loss: 0.292511\n",
      "Total training time: 6.32 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 64.17, NNZs: 182, Bias: -3.600000, T: 1318680, Avg. loss: 0.300064\n",
      "Total training time: 6.50 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 60.81, NNZs: 177, Bias: -3.200000, T: 1354320, Avg. loss: 0.310936\n",
      "Total training time: 6.68 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 58.98, NNZs: 172, Bias: -3.600000, T: 1389960, Avg. loss: 0.325311\n",
      "Total training time: 6.85 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 59.85, NNZs: 172, Bias: -3.600000, T: 1425600, Avg. loss: 0.310516\n",
      "Total training time: 7.03 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 58.89, NNZs: 181, Bias: -4.400000, T: 1461240, Avg. loss: 0.318669\n",
      "Total training time: 7.21 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 53.35, NNZs: 190, Bias: -2.520000, T: 1496880, Avg. loss: 0.198815\n",
      "Total training time: 7.39 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 48.85, NNZs: 181, Bias: -2.200000, T: 1532520, Avg. loss: 0.186132\n",
      "Total training time: 7.57 seconds.\n",
      "-- Epoch 44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 45.06, NNZs: 184, Bias: -2.040000, T: 1568160, Avg. loss: 0.185172\n",
      "Total training time: 7.75 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 41.78, NNZs: 186, Bias: -2.160000, T: 1603800, Avg. loss: 0.186954\n",
      "Total training time: 7.92 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 39.06, NNZs: 186, Bias: -2.080000, T: 1639440, Avg. loss: 0.185945\n",
      "Total training time: 8.10 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 36.78, NNZs: 185, Bias: -2.200000, T: 1675080, Avg. loss: 0.186046\n",
      "Total training time: 8.27 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 34.85, NNZs: 184, Bias: -2.040000, T: 1710720, Avg. loss: 0.186247\n",
      "Total training time: 8.44 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 34.06, NNZs: 182, Bias: -1.720000, T: 1746360, Avg. loss: 0.161965\n",
      "Total training time: 8.63 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 33.32, NNZs: 185, Bias: -1.552000, T: 1782000, Avg. loss: 0.157108\n",
      "Total training time: 8.80 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 32.62, NNZs: 177, Bias: -1.464000, T: 1817640, Avg. loss: 0.155549\n",
      "Total training time: 8.97 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 31.94, NNZs: 175, Bias: -1.360000, T: 1853280, Avg. loss: 0.154492\n",
      "Total training time: 9.15 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 31.28, NNZs: 174, Bias: -1.328000, T: 1888920, Avg. loss: 0.153907\n",
      "Total training time: 9.32 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 30.65, NNZs: 178, Bias: -1.312000, T: 1924560, Avg. loss: 0.153464\n",
      "Total training time: 9.49 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 30.03, NNZs: 176, Bias: -1.304000, T: 1960200, Avg. loss: 0.153545\n",
      "Total training time: 9.67 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 29.43, NNZs: 178, Bias: -1.192000, T: 1995840, Avg. loss: 0.153577\n",
      "Total training time: 9.84 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 28.86, NNZs: 185, Bias: -1.256000, T: 2031480, Avg. loss: 0.153220\n",
      "Total training time: 10.02 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 28.72, NNZs: 186, Bias: -1.190400, T: 2067120, Avg. loss: 0.148592\n",
      "Total training time: 10.20 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 28.58, NNZs: 179, Bias: -1.152000, T: 2102760, Avg. loss: 0.147792\n",
      "Total training time: 10.38 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 28.45, NNZs: 180, Bias: -1.124800, T: 2138400, Avg. loss: 0.147408\n",
      "Total training time: 10.57 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 28.32, NNZs: 176, Bias: -1.108800, T: 2174040, Avg. loss: 0.147193\n",
      "Total training time: 10.74 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 28.19, NNZs: 179, Bias: -1.084800, T: 2209680, Avg. loss: 0.146979\n",
      "Total training time: 10.92 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 28.06, NNZs: 178, Bias: -1.073600, T: 2245320, Avg. loss: 0.146833\n",
      "Total training time: 11.10 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 28.03, NNZs: 178, Bias: -1.058560, T: 2280960, Avg. loss: 0.145794\n",
      "Total training time: 11.29 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 28.00, NNZs: 179, Bias: -1.050880, T: 2316600, Avg. loss: 0.145664\n",
      "Total training time: 11.46 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 27.98, NNZs: 177, Bias: -1.044480, T: 2352240, Avg. loss: 0.145592\n",
      "Total training time: 11.64 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 27.95, NNZs: 170, Bias: -1.039360, T: 2387880, Avg. loss: 0.145517\n",
      "Total training time: 11.82 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 27.92, NNZs: 172, Bias: -1.033280, T: 2423520, Avg. loss: 0.145473\n",
      "Total training time: 12.00 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 27.90, NNZs: 173, Bias: -1.026560, T: 2459160, Avg. loss: 0.145405\n",
      "Total training time: 12.17 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 27.89, NNZs: 177, Bias: -1.024704, T: 2494800, Avg. loss: 0.145194\n",
      "Total training time: 12.34 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 27.88, NNZs: 174, Bias: -1.022848, T: 2530440, Avg. loss: 0.145165\n",
      "Total training time: 12.51 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 27.88, NNZs: 176, Bias: -1.020544, T: 2566080, Avg. loss: 0.145144\n",
      "Total training time: 12.69 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 27.87, NNZs: 174, Bias: -1.018752, T: 2601720, Avg. loss: 0.145129\n",
      "Total training time: 12.85 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 27.87, NNZs: 174, Bias: -1.017152, T: 2637360, Avg. loss: 0.145112\n",
      "Total training time: 13.02 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 27.87, NNZs: 175, Bias: -1.016563, T: 2673000, Avg. loss: 0.145069\n",
      "Total training time: 13.19 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 27.87, NNZs: 174, Bias: -1.016256, T: 2708640, Avg. loss: 0.145060\n",
      "Total training time: 13.36 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 27.87, NNZs: 175, Bias: -1.015834, T: 2744280, Avg. loss: 0.145057\n",
      "Total training time: 13.53 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 27.86, NNZs: 174, Bias: -1.015411, T: 2779920, Avg. loss: 0.145051\n",
      "Total training time: 13.70 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 27.86, NNZs: 173, Bias: -1.014989, T: 2815560, Avg. loss: 0.145048\n",
      "Total training time: 13.90 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 27.86, NNZs: 173, Bias: -1.014761, T: 2851200, Avg. loss: 0.145039\n",
      "Total training time: 14.10 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 27.86, NNZs: 173, Bias: -1.014669, T: 2886840, Avg. loss: 0.145037\n",
      "Total training time: 14.27 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 27.86, NNZs: 173, Bias: -1.014592, T: 2922480, Avg. loss: 0.145036\n",
      "Total training time: 14.44 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 27.86, NNZs: 173, Bias: -1.014487, T: 2958120, Avg. loss: 0.145035\n",
      "Total training time: 14.60 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 27.86, NNZs: 173, Bias: -1.014369, T: 2993760, Avg. loss: 0.145034\n",
      "Total training time: 14.78 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 27.86, NNZs: 173, Bias: -1.014370, T: 3029400, Avg. loss: 0.145032\n",
      "Total training time: 14.95 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 27.86, NNZs: 173, Bias: -1.014342, T: 3065040, Avg. loss: 0.145032\n",
      "Total training time: 15.13 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 27.86, NNZs: 173, Bias: -1.014313, T: 3100680, Avg. loss: 0.145032\n",
      "Total training time: 15.29 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 27.86, NNZs: 173, Bias: -1.014305, T: 3136320, Avg. loss: 0.145032\n",
      "Total training time: 15.46 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 27.86, NNZs: 173, Bias: -1.014285, T: 3171960, Avg. loss: 0.145032\n",
      "Total training time: 15.64 seconds.\n",
      "Convergence after 89 epochs took 15.64 seconds\n",
      "-- Epoch 1\n",
      "Norm: 296.58, NNZs: 295, Bias: 5.000000, T: 35640, Avg. loss: 25.585831\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 332.30, NNZs: 241, Bias: 25.000000, T: 71280, Avg. loss: 22.537978\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 354.88, NNZs: 236, Bias: 10.000000, T: 106920, Avg. loss: 20.356714\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 397.47, NNZs: 216, Bias: -5.000000, T: 142560, Avg. loss: 18.990507\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 387.35, NNZs: 195, Bias: 15.000000, T: 178200, Avg. loss: 17.631857\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 416.45, NNZs: 178, Bias: 0.000000, T: 213840, Avg. loss: 16.639289\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 420.58, NNZs: 182, Bias: 10.000000, T: 249480, Avg. loss: 15.615655\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 416.97, NNZs: 157, Bias: 15.000000, T: 285120, Avg. loss: 14.976625\n",
      "Total training time: 1.53 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 430.41, NNZs: 175, Bias: 0.000000, T: 320760, Avg. loss: 14.563699\n",
      "Total training time: 1.74 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 457.45, NNZs: 147, Bias: 20.000000, T: 356400, Avg. loss: 13.720474\n",
      "Total training time: 1.93 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 467.71, NNZs: 154, Bias: -15.000000, T: 392040, Avg. loss: 13.418603\n",
      "Total training time: 2.11 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 443.47, NNZs: 167, Bias: 5.000000, T: 427680, Avg. loss: 13.062182\n",
      "Total training time: 2.29 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 452.23, NNZs: 158, Bias: 5.000000, T: 463320, Avg. loss: 12.613247\n",
      "Total training time: 2.48 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 470.81, NNZs: 152, Bias: 15.000000, T: 498960, Avg. loss: 12.678874\n",
      "Total training time: 2.65 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 454.37, NNZs: 159, Bias: 5.000000, T: 534600, Avg. loss: 12.525680\n",
      "Total training time: 2.84 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 460.19, NNZs: 155, Bias: 5.000000, T: 570240, Avg. loss: 12.275714\n",
      "Total training time: 3.02 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 460.09, NNZs: 148, Bias: 5.000000, T: 605880, Avg. loss: 12.157794\n",
      "Total training time: 3.20 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 471.92, NNZs: 145, Bias: 0.000000, T: 641520, Avg. loss: 11.514500\n",
      "Total training time: 3.38 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 457.19, NNZs: 145, Bias: -5.000000, T: 677160, Avg. loss: 12.185515\n",
      "Total training time: 3.56 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 483.93, NNZs: 150, Bias: 15.000000, T: 712800, Avg. loss: 11.391892\n",
      "Total training time: 3.74 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 476.11, NNZs: 149, Bias: 10.000000, T: 748440, Avg. loss: 11.358061\n",
      "Total training time: 3.92 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 467.53, NNZs: 144, Bias: 0.000000, T: 784080, Avg. loss: 11.529075\n",
      "Total training time: 4.09 seconds.\n",
      "-- Epoch 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 455.05, NNZs: 155, Bias: -5.000000, T: 819720, Avg. loss: 11.660953\n",
      "Total training time: 4.27 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 473.21, NNZs: 144, Bias: 5.000000, T: 855360, Avg. loss: 11.327157\n",
      "Total training time: 4.45 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 484.53, NNZs: 142, Bias: 15.000000, T: 891000, Avg. loss: 10.902349\n",
      "Total training time: 4.63 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 473.10, NNZs: 143, Bias: 5.000000, T: 926640, Avg. loss: 11.414907\n",
      "Total training time: 4.81 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 493.25, NNZs: 128, Bias: 10.000000, T: 962280, Avg. loss: 10.805804\n",
      "Total training time: 4.99 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 458.24, NNZs: 147, Bias: 10.000000, T: 997920, Avg. loss: 11.065106\n",
      "Total training time: 5.17 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 469.66, NNZs: 155, Bias: -5.000000, T: 1033560, Avg. loss: 11.005775\n",
      "Total training time: 5.35 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 504.55, NNZs: 135, Bias: 5.000000, T: 1069200, Avg. loss: 10.643246\n",
      "Total training time: 5.53 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 488.46, NNZs: 139, Bias: 10.000000, T: 1104840, Avg. loss: 11.070250\n",
      "Total training time: 5.71 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 473.00, NNZs: 143, Bias: 0.000000, T: 1140480, Avg. loss: 11.298971\n",
      "Total training time: 5.89 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 474.59, NNZs: 137, Bias: 0.000000, T: 1176120, Avg. loss: 10.923445\n",
      "Total training time: 6.07 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 481.22, NNZs: 148, Bias: 0.000000, T: 1211760, Avg. loss: 10.858727\n",
      "Total training time: 6.25 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 493.23, NNZs: 133, Bias: 10.000000, T: 1247400, Avg. loss: 11.164143\n",
      "Total training time: 6.43 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 223.46, NNZs: 151, Bias: 2.000000, T: 1283040, Avg. loss: 2.434807\n",
      "Total training time: 6.60 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 209.10, NNZs: 161, Bias: 2.000000, T: 1318680, Avg. loss: 2.530038\n",
      "Total training time: 6.78 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 213.38, NNZs: 157, Bias: 2.000000, T: 1354320, Avg. loss: 2.576831\n",
      "Total training time: 6.96 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 211.09, NNZs: 158, Bias: 2.000000, T: 1389960, Avg. loss: 2.716814\n",
      "Total training time: 7.14 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 215.76, NNZs: 164, Bias: 4.000000, T: 1425600, Avg. loss: 2.582623\n",
      "Total training time: 7.33 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 211.87, NNZs: 168, Bias: 4.000000, T: 1461240, Avg. loss: 2.709069\n",
      "Total training time: 7.52 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 142.97, NNZs: 159, Bias: 1.000000, T: 1496880, Avg. loss: 0.958132\n",
      "Total training time: 7.69 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 114.01, NNZs: 182, Bias: 1.800000, T: 1532520, Avg. loss: 0.959160\n",
      "Total training time: 7.88 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 100.78, NNZs: 185, Bias: 1.000000, T: 1568160, Avg. loss: 1.003893\n",
      "Total training time: 8.07 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 96.64, NNZs: 177, Bias: 2.200000, T: 1603800, Avg. loss: 1.020350\n",
      "Total training time: 8.27 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 95.16, NNZs: 199, Bias: 1.200000, T: 1639440, Avg. loss: 1.003991\n",
      "Total training time: 8.46 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 94.78, NNZs: 202, Bias: 0.800000, T: 1675080, Avg. loss: 1.001025\n",
      "Total training time: 8.65 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 85.51, NNZs: 205, Bias: 0.840000, T: 1710720, Avg. loss: 0.655713\n",
      "Total training time: 8.83 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 78.07, NNZs: 208, Bias: 1.160000, T: 1746360, Avg. loss: 0.639707\n",
      "Total training time: 9.02 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 71.85, NNZs: 214, Bias: 1.160000, T: 1782000, Avg. loss: 0.637773\n",
      "Total training time: 9.21 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 66.40, NNZs: 211, Bias: 1.080000, T: 1817640, Avg. loss: 0.648835\n",
      "Total training time: 9.40 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 61.77, NNZs: 218, Bias: 1.040000, T: 1853280, Avg. loss: 0.645574\n",
      "Total training time: 9.58 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 57.89, NNZs: 209, Bias: 1.040000, T: 1888920, Avg. loss: 0.644199\n",
      "Total training time: 9.78 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 54.62, NNZs: 210, Bias: 1.120000, T: 1924560, Avg. loss: 0.640977\n",
      "Total training time: 10.00 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 52.03, NNZs: 217, Bias: 1.120000, T: 1960200, Avg. loss: 0.645059\n",
      "Total training time: 10.22 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 50.83, NNZs: 224, Bias: 1.016000, T: 1995840, Avg. loss: 0.556913\n",
      "Total training time: 10.45 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 49.73, NNZs: 224, Bias: 0.968000, T: 2031480, Avg. loss: 0.553107\n",
      "Total training time: 10.65 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 48.68, NNZs: 224, Bias: 1.000000, T: 2067120, Avg. loss: 0.552363\n",
      "Total training time: 10.85 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 47.66, NNZs: 228, Bias: 0.928000, T: 2102760, Avg. loss: 0.552437\n",
      "Total training time: 11.04 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 46.67, NNZs: 227, Bias: 0.864000, T: 2138400, Avg. loss: 0.552667\n",
      "Total training time: 11.24 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 45.71, NNZs: 225, Bias: 0.840000, T: 2174040, Avg. loss: 0.553240\n",
      "Total training time: 11.44 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 44.77, NNZs: 228, Bias: 0.912000, T: 2209680, Avg. loss: 0.553268\n",
      "Total training time: 11.62 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 44.55, NNZs: 230, Bias: 0.828800, T: 2245320, Avg. loss: 0.531299\n",
      "Total training time: 11.81 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 44.34, NNZs: 230, Bias: 0.830400, T: 2280960, Avg. loss: 0.530305\n",
      "Total training time: 12.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 44.13, NNZs: 227, Bias: 0.816000, T: 2316600, Avg. loss: 0.529937\n",
      "Total training time: 12.19 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 43.92, NNZs: 226, Bias: 0.806400, T: 2352240, Avg. loss: 0.529943\n",
      "Total training time: 12.39 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 43.72, NNZs: 227, Bias: 0.792000, T: 2387880, Avg. loss: 0.529128\n",
      "Total training time: 12.58 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 43.51, NNZs: 227, Bias: 0.784000, T: 2423520, Avg. loss: 0.529352\n",
      "Total training time: 12.78 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 43.47, NNZs: 227, Bias: 0.803200, T: 2459160, Avg. loss: 0.524941\n",
      "Total training time: 12.99 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 43.43, NNZs: 227, Bias: 0.801600, T: 2494800, Avg. loss: 0.524337\n",
      "Total training time: 13.18 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 43.39, NNZs: 227, Bias: 0.796480, T: 2530440, Avg. loss: 0.524506\n",
      "Total training time: 13.39 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 43.34, NNZs: 227, Bias: 0.802880, T: 2566080, Avg. loss: 0.524396\n",
      "Total training time: 13.58 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 43.30, NNZs: 227, Bias: 0.797760, T: 2601720, Avg. loss: 0.524374\n",
      "Total training time: 13.77 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 43.26, NNZs: 227, Bias: 0.800640, T: 2637360, Avg. loss: 0.524178\n",
      "Total training time: 13.97 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 43.25, NNZs: 227, Bias: 0.789760, T: 2673000, Avg. loss: 0.523480\n",
      "Total training time: 14.16 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 43.24, NNZs: 227, Bias: 0.788032, T: 2708640, Avg. loss: 0.523126\n",
      "Total training time: 14.35 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 43.24, NNZs: 227, Bias: 0.792064, T: 2744280, Avg. loss: 0.523153\n",
      "Total training time: 14.55 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 43.23, NNZs: 227, Bias: 0.789504, T: 2779920, Avg. loss: 0.523114\n",
      "Total training time: 14.75 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 43.22, NNZs: 227, Bias: 0.788224, T: 2815560, Avg. loss: 0.523121\n",
      "Total training time: 14.95 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 43.22, NNZs: 227, Bias: 0.790746, T: 2851200, Avg. loss: 0.522872\n",
      "Total training time: 15.14 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 43.22, NNZs: 227, Bias: 0.790144, T: 2886840, Avg. loss: 0.522831\n",
      "Total training time: 15.33 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 43.21, NNZs: 227, Bias: 0.790874, T: 2922480, Avg. loss: 0.522831\n",
      "Total training time: 15.53 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 43.21, NNZs: 227, Bias: 0.790272, T: 2958120, Avg. loss: 0.522824\n",
      "Total training time: 15.72 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 43.21, NNZs: 227, Bias: 0.790093, T: 2993760, Avg. loss: 0.522817\n",
      "Total training time: 15.92 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 43.21, NNZs: 227, Bias: 0.790257, T: 3029400, Avg. loss: 0.522764\n",
      "Total training time: 16.11 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 43.21, NNZs: 227, Bias: 0.790426, T: 3065040, Avg. loss: 0.522760\n",
      "Total training time: 16.30 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 43.21, NNZs: 227, Bias: 0.790495, T: 3100680, Avg. loss: 0.522758\n",
      "Total training time: 16.50 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 43.21, NNZs: 227, Bias: 0.790490, T: 3136320, Avg. loss: 0.522757\n",
      "Total training time: 16.69 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 43.21, NNZs: 227, Bias: 0.790566, T: 3171960, Avg. loss: 0.522757\n",
      "Total training time: 16.89 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 43.21, NNZs: 227, Bias: 0.790569, T: 3207600, Avg. loss: 0.522743\n",
      "Total training time: 17.08 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 43.21, NNZs: 227, Bias: 0.790569, T: 3243240, Avg. loss: 0.522742\n",
      "Total training time: 17.28 seconds.\n",
      "-- Epoch 92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 43.21, NNZs: 227, Bias: 0.790563, T: 3278880, Avg. loss: 0.522742\n",
      "Total training time: 17.49 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 43.21, NNZs: 227, Bias: 0.790561, T: 3314520, Avg. loss: 0.522742\n",
      "Total training time: 17.67 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 43.21, NNZs: 227, Bias: 0.790561, T: 3350160, Avg. loss: 0.522742\n",
      "Total training time: 17.87 seconds.\n",
      "Convergence after 94 epochs took 17.87 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   51.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 280.06, NNZs: 308, Bias: -50.000000, T: 35640, Avg. loss: 22.039345\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 302.77, NNZs: 258, Bias: -40.000000, T: 71280, Avg. loss: 19.918299\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 339.85, NNZs: 227, Bias: -30.000000, T: 106920, Avg. loss: 18.278891\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 364.92, NNZs: 228, Bias: -25.000000, T: 142560, Avg. loss: 17.110609\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 377.93, NNZs: 187, Bias: -35.000000, T: 178200, Avg. loss: 15.525460\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 384.65, NNZs: 179, Bias: -30.000000, T: 213840, Avg. loss: 14.967670\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 389.75, NNZs: 183, Bias: -40.000000, T: 249480, Avg. loss: 14.135530\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 397.58, NNZs: 188, Bias: -40.000000, T: 285120, Avg. loss: 13.612761\n",
      "Total training time: 1.58 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 393.90, NNZs: 173, Bias: -30.000000, T: 320760, Avg. loss: 12.806743\n",
      "Total training time: 1.77 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 401.40, NNZs: 167, Bias: -15.000000, T: 356400, Avg. loss: 12.679028\n",
      "Total training time: 1.95 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 412.45, NNZs: 165, Bias: -25.000000, T: 392040, Avg. loss: 12.485178\n",
      "Total training time: 2.13 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 417.57, NNZs: 156, Bias: -25.000000, T: 427680, Avg. loss: 11.954061\n",
      "Total training time: 2.32 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 414.20, NNZs: 171, Bias: -30.000000, T: 463320, Avg. loss: 11.479647\n",
      "Total training time: 2.49 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 417.47, NNZs: 167, Bias: -20.000000, T: 498960, Avg. loss: 11.757877\n",
      "Total training time: 2.69 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 432.93, NNZs: 153, Bias: -25.000000, T: 534600, Avg. loss: 11.784697\n",
      "Total training time: 2.87 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 434.57, NNZs: 138, Bias: -15.000000, T: 570240, Avg. loss: 11.347874\n",
      "Total training time: 3.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 439.19, NNZs: 171, Bias: -10.000000, T: 605880, Avg. loss: 11.282423\n",
      "Total training time: 3.23 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 441.93, NNZs: 164, Bias: -25.000000, T: 641520, Avg. loss: 11.080528\n",
      "Total training time: 3.41 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 436.61, NNZs: 148, Bias: -20.000000, T: 677160, Avg. loss: 10.694257\n",
      "Total training time: 3.59 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 446.68, NNZs: 148, Bias: -20.000000, T: 712800, Avg. loss: 11.096359\n",
      "Total training time: 3.77 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 441.67, NNZs: 148, Bias: -25.000000, T: 748440, Avg. loss: 10.823163\n",
      "Total training time: 3.94 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 426.59, NNZs: 149, Bias: -30.000000, T: 784080, Avg. loss: 10.418302\n",
      "Total training time: 4.13 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 420.94, NNZs: 143, Bias: -25.000000, T: 819720, Avg. loss: 11.136162\n",
      "Total training time: 4.31 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 435.09, NNZs: 147, Bias: -20.000000, T: 855360, Avg. loss: 10.938114\n",
      "Total training time: 4.49 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 418.14, NNZs: 158, Bias: -25.000000, T: 891000, Avg. loss: 10.658187\n",
      "Total training time: 4.67 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 430.25, NNZs: 139, Bias: -5.000000, T: 926640, Avg. loss: 10.875741\n",
      "Total training time: 4.85 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 423.68, NNZs: 158, Bias: -20.000000, T: 962280, Avg. loss: 10.574061\n",
      "Total training time: 5.03 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 196.53, NNZs: 160, Bias: -13.000000, T: 997920, Avg. loss: 2.530030\n",
      "Total training time: 5.20 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 190.48, NNZs: 173, Bias: -13.000000, T: 1033560, Avg. loss: 2.538754\n",
      "Total training time: 5.39 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 193.01, NNZs: 166, Bias: -8.000000, T: 1069200, Avg. loss: 2.480200\n",
      "Total training time: 5.57 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 187.18, NNZs: 176, Bias: -10.000000, T: 1104840, Avg. loss: 2.667341\n",
      "Total training time: 5.76 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 185.25, NNZs: 190, Bias: -11.000000, T: 1140480, Avg. loss: 2.659341\n",
      "Total training time: 5.94 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 183.33, NNZs: 164, Bias: -10.000000, T: 1176120, Avg. loss: 2.661157\n",
      "Total training time: 6.15 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 188.68, NNZs: 183, Bias: -10.000000, T: 1211760, Avg. loss: 2.670222\n",
      "Total training time: 6.34 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 190.00, NNZs: 191, Bias: -8.000000, T: 1247400, Avg. loss: 2.672065\n",
      "Total training time: 6.53 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 125.92, NNZs: 185, Bias: -4.600000, T: 1283040, Avg. loss: 0.917370\n",
      "Total training time: 6.71 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 100.25, NNZs: 188, Bias: -4.400000, T: 1318680, Avg. loss: 0.882348\n",
      "Total training time: 6.90 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 89.93, NNZs: 196, Bias: -4.400000, T: 1354320, Avg. loss: 0.902772\n",
      "Total training time: 7.08 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 86.36, NNZs: 199, Bias: -4.400000, T: 1389960, Avg. loss: 0.911871\n",
      "Total training time: 7.26 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 85.67, NNZs: 194, Bias: -4.000000, T: 1425600, Avg. loss: 0.913230\n",
      "Total training time: 7.45 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 84.90, NNZs: 200, Bias: -4.000000, T: 1461240, Avg. loss: 0.909135\n",
      "Total training time: 7.63 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 84.83, NNZs: 199, Bias: -3.200000, T: 1496880, Avg. loss: 0.902196\n",
      "Total training time: 7.82 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 76.67, NNZs: 216, Bias: -2.720000, T: 1532520, Avg. loss: 0.556927\n",
      "Total training time: 7.99 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 70.18, NNZs: 225, Bias: -2.280000, T: 1568160, Avg. loss: 0.542254\n",
      "Total training time: 8.17 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 64.51, NNZs: 229, Bias: -2.160000, T: 1603800, Avg. loss: 0.551295\n",
      "Total training time: 8.36 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 59.79, NNZs: 230, Bias: -2.040000, T: 1639440, Avg. loss: 0.547823\n",
      "Total training time: 8.54 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 55.77, NNZs: 219, Bias: -1.920000, T: 1675080, Avg. loss: 0.547294\n",
      "Total training time: 8.73 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 52.32, NNZs: 221, Bias: -2.600000, T: 1710720, Avg. loss: 0.550614\n",
      "Total training time: 8.93 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 49.54, NNZs: 223, Bias: -1.960000, T: 1746360, Avg. loss: 0.548923\n",
      "Total training time: 9.14 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 48.38, NNZs: 231, Bias: -2.032000, T: 1782000, Avg. loss: 0.467075\n",
      "Total training time: 9.33 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 47.34, NNZs: 233, Bias: -1.920000, T: 1817640, Avg. loss: 0.461319\n",
      "Total training time: 9.50 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 46.33, NNZs: 231, Bias: -1.920000, T: 1853280, Avg. loss: 0.461800\n",
      "Total training time: 9.68 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 45.37, NNZs: 230, Bias: -1.832000, T: 1888920, Avg. loss: 0.460943\n",
      "Total training time: 9.86 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 44.43, NNZs: 231, Bias: -1.864000, T: 1924560, Avg. loss: 0.461560\n",
      "Total training time: 10.03 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 43.53, NNZs: 232, Bias: -1.784000, T: 1960200, Avg. loss: 0.461025\n",
      "Total training time: 10.21 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 42.65, NNZs: 231, Bias: -1.768000, T: 1995840, Avg. loss: 0.460289\n",
      "Total training time: 10.40 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 42.44, NNZs: 234, Bias: -1.731200, T: 2031480, Avg. loss: 0.444459\n",
      "Total training time: 10.58 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 42.24, NNZs: 232, Bias: -1.728000, T: 2067120, Avg. loss: 0.442665\n",
      "Total training time: 10.80 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 42.04, NNZs: 230, Bias: -1.712000, T: 2102760, Avg. loss: 0.442496\n",
      "Total training time: 10.98 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 41.84, NNZs: 233, Bias: -1.696000, T: 2138400, Avg. loss: 0.442879\n",
      "Total training time: 11.16 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 41.65, NNZs: 232, Bias: -1.710400, T: 2174040, Avg. loss: 0.442137\n",
      "Total training time: 11.34 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 41.46, NNZs: 231, Bias: -1.678400, T: 2209680, Avg. loss: 0.442484\n",
      "Total training time: 11.51 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 41.26, NNZs: 230, Bias: -1.659200, T: 2245320, Avg. loss: 0.442406\n",
      "Total training time: 11.69 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 41.22, NNZs: 231, Bias: -1.658880, T: 2280960, Avg. loss: 0.438562\n",
      "Total training time: 11.87 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 41.18, NNZs: 231, Bias: -1.651840, T: 2316600, Avg. loss: 0.438348\n",
      "Total training time: 12.04 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 41.14, NNZs: 230, Bias: -1.651520, T: 2352240, Avg. loss: 0.438310\n",
      "Total training time: 12.22 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 41.10, NNZs: 231, Bias: -1.653760, T: 2387880, Avg. loss: 0.438253\n",
      "Total training time: 12.40 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 41.06, NNZs: 231, Bias: -1.646400, T: 2423520, Avg. loss: 0.438222\n",
      "Total training time: 12.58 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 41.02, NNZs: 231, Bias: -1.649600, T: 2459160, Avg. loss: 0.438197\n",
      "Total training time: 12.76 seconds.\n",
      "-- Epoch 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 41.02, NNZs: 231, Bias: -1.650112, T: 2494800, Avg. loss: 0.437414\n",
      "Total training time: 12.94 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 41.01, NNZs: 231, Bias: -1.650176, T: 2530440, Avg. loss: 0.437371\n",
      "Total training time: 13.13 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 41.00, NNZs: 231, Bias: -1.651840, T: 2566080, Avg. loss: 0.437346\n",
      "Total training time: 13.32 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 40.99, NNZs: 231, Bias: -1.649728, T: 2601720, Avg. loss: 0.437308\n",
      "Total training time: 13.50 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 40.98, NNZs: 231, Bias: -1.648064, T: 2637360, Avg. loss: 0.437322\n",
      "Total training time: 13.68 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 40.98, NNZs: 231, Bias: -1.648550, T: 2673000, Avg. loss: 0.437144\n",
      "Total training time: 13.86 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 40.98, NNZs: 231, Bias: -1.647949, T: 2708640, Avg. loss: 0.437136\n",
      "Total training time: 14.03 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 40.98, NNZs: 231, Bias: -1.648038, T: 2744280, Avg. loss: 0.437125\n",
      "Total training time: 14.21 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 40.98, NNZs: 231, Bias: -1.647066, T: 2779920, Avg. loss: 0.437115\n",
      "Total training time: 14.39 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 40.98, NNZs: 231, Bias: -1.647654, T: 2815560, Avg. loss: 0.437122\n",
      "Total training time: 14.56 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 40.98, NNZs: 231, Bias: -1.647690, T: 2851200, Avg. loss: 0.437069\n",
      "Total training time: 14.74 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 40.98, NNZs: 231, Bias: -1.647690, T: 2886840, Avg. loss: 0.437069\n",
      "Total training time: 14.92 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 40.98, NNZs: 231, Bias: -1.647736, T: 2922480, Avg. loss: 0.437068\n",
      "Total training time: 15.09 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 40.97, NNZs: 231, Bias: -1.647747, T: 2958120, Avg. loss: 0.437068\n",
      "Total training time: 15.27 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 40.97, NNZs: 231, Bias: -1.647693, T: 2993760, Avg. loss: 0.437068\n",
      "Total training time: 15.45 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 40.97, NNZs: 231, Bias: -1.647686, T: 3029400, Avg. loss: 0.437056\n",
      "Total training time: 15.62 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 40.97, NNZs: 231, Bias: -1.647678, T: 3065040, Avg. loss: 0.437056\n",
      "Total training time: 15.81 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 40.97, NNZs: 231, Bias: -1.647678, T: 3100680, Avg. loss: 0.437056\n",
      "Total training time: 15.98 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 40.97, NNZs: 231, Bias: -1.647678, T: 3136320, Avg. loss: 0.437056\n",
      "Total training time: 16.16 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 40.97, NNZs: 231, Bias: -1.647668, T: 3171960, Avg. loss: 0.437056\n",
      "Total training time: 16.34 seconds.\n",
      "Convergence after 89 epochs took 16.34 seconds\n",
      "-- Epoch 1\n",
      "Norm: 188.48, NNZs: 258, Bias: -95.000000, T: 35640, Avg. loss: 8.613480\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 214.05, NNZs: 222, Bias: -80.000000, T: 71280, Avg. loss: 7.514688\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 249.22, NNZs: 208, Bias: -70.000000, T: 106920, Avg. loss: 6.856935\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 243.25, NNZs: 205, Bias: -60.000000, T: 142560, Avg. loss: 6.069747\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 252.69, NNZs: 179, Bias: -65.000000, T: 178200, Avg. loss: 5.513221\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 263.77, NNZs: 164, Bias: -60.000000, T: 213840, Avg. loss: 5.029417\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 286.07, NNZs: 151, Bias: -60.000000, T: 249480, Avg. loss: 4.743245\n",
      "Total training time: 1.31 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 263.89, NNZs: 159, Bias: -50.000000, T: 285120, Avg. loss: 4.483757\n",
      "Total training time: 1.49 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 299.31, NNZs: 150, Bias: -40.000000, T: 320760, Avg. loss: 4.130112\n",
      "Total training time: 1.66 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 313.34, NNZs: 153, Bias: -45.000000, T: 356400, Avg. loss: 4.263482\n",
      "Total training time: 1.84 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 270.45, NNZs: 147, Bias: -50.000000, T: 392040, Avg. loss: 4.308773\n",
      "Total training time: 2.02 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 275.75, NNZs: 153, Bias: -35.000000, T: 427680, Avg. loss: 4.187656\n",
      "Total training time: 2.18 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 283.42, NNZs: 166, Bias: -50.000000, T: 463320, Avg. loss: 4.016822\n",
      "Total training time: 2.36 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 305.95, NNZs: 150, Bias: -50.000000, T: 498960, Avg. loss: 4.054445\n",
      "Total training time: 2.53 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 298.86, NNZs: 127, Bias: -35.000000, T: 534600, Avg. loss: 3.972655\n",
      "Total training time: 2.69 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 277.35, NNZs: 137, Bias: -30.000000, T: 570240, Avg. loss: 3.797986\n",
      "Total training time: 2.86 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 310.34, NNZs: 135, Bias: -45.000000, T: 605880, Avg. loss: 3.806190\n",
      "Total training time: 3.03 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 271.24, NNZs: 142, Bias: -45.000000, T: 641520, Avg. loss: 3.913458\n",
      "Total training time: 3.20 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 294.29, NNZs: 138, Bias: -45.000000, T: 677160, Avg. loss: 3.693244\n",
      "Total training time: 3.36 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 295.57, NNZs: 149, Bias: -45.000000, T: 712800, Avg. loss: 3.909680\n",
      "Total training time: 3.53 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 295.56, NNZs: 137, Bias: -45.000000, T: 748440, Avg. loss: 3.994921\n",
      "Total training time: 3.70 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 302.85, NNZs: 125, Bias: -45.000000, T: 784080, Avg. loss: 3.740006\n",
      "Total training time: 3.87 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 271.58, NNZs: 138, Bias: -40.000000, T: 819720, Avg. loss: 3.637568\n",
      "Total training time: 4.06 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 303.69, NNZs: 138, Bias: -35.000000, T: 855360, Avg. loss: 3.715100\n",
      "Total training time: 4.24 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 294.41, NNZs: 144, Bias: -40.000000, T: 891000, Avg. loss: 3.573611\n",
      "Total training time: 4.41 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 276.55, NNZs: 144, Bias: -40.000000, T: 926640, Avg. loss: 3.744992\n",
      "Total training time: 4.58 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 277.45, NNZs: 135, Bias: -40.000000, T: 962280, Avg. loss: 3.704552\n",
      "Total training time: 4.76 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 287.96, NNZs: 156, Bias: -40.000000, T: 997920, Avg. loss: 3.431881\n",
      "Total training time: 4.96 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 308.40, NNZs: 127, Bias: -35.000000, T: 1033560, Avg. loss: 3.704454\n",
      "Total training time: 5.12 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 296.39, NNZs: 143, Bias: -50.000000, T: 1069200, Avg. loss: 3.685683\n",
      "Total training time: 5.29 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 297.85, NNZs: 130, Bias: -35.000000, T: 1104840, Avg. loss: 3.786832\n",
      "Total training time: 5.46 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 306.23, NNZs: 132, Bias: -30.000000, T: 1140480, Avg. loss: 3.603640\n",
      "Total training time: 5.62 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 309.15, NNZs: 145, Bias: -45.000000, T: 1176120, Avg. loss: 3.687335\n",
      "Total training time: 5.78 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 137.92, NNZs: 135, Bias: -13.000000, T: 1211760, Avg. loss: 0.816331\n",
      "Total training time: 5.95 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 132.39, NNZs: 142, Bias: -11.000000, T: 1247400, Avg. loss: 0.788087\n",
      "Total training time: 6.11 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 129.38, NNZs: 167, Bias: -10.000000, T: 1283040, Avg. loss: 0.840821\n",
      "Total training time: 6.29 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 134.18, NNZs: 166, Bias: -10.000000, T: 1318680, Avg. loss: 0.855069\n",
      "Total training time: 6.50 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 125.04, NNZs: 170, Bias: -12.000000, T: 1354320, Avg. loss: 0.921455\n",
      "Total training time: 6.69 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 126.33, NNZs: 178, Bias: -7.000000, T: 1389960, Avg. loss: 0.997649\n",
      "Total training time: 6.89 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 123.49, NNZs: 167, Bias: -12.000000, T: 1425600, Avg. loss: 0.982382\n",
      "Total training time: 7.09 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 84.31, NNZs: 169, Bias: -4.400000, T: 1461240, Avg. loss: 0.324161\n",
      "Total training time: 7.28 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 68.91, NNZs: 167, Bias: -4.800000, T: 1496880, Avg. loss: 0.295100\n",
      "Total training time: 7.48 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 63.14, NNZs: 167, Bias: -5.400000, T: 1532520, Avg. loss: 0.305301\n",
      "Total training time: 7.65 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 61.54, NNZs: 173, Bias: -4.000000, T: 1568160, Avg. loss: 0.299632\n",
      "Total training time: 7.85 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 59.98, NNZs: 185, Bias: -3.600000, T: 1603800, Avg. loss: 0.312348\n",
      "Total training time: 8.05 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 60.39, NNZs: 182, Bias: -4.000000, T: 1639440, Avg. loss: 0.310786\n",
      "Total training time: 8.24 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 59.61, NNZs: 183, Bias: -4.000000, T: 1675080, Avg. loss: 0.308986\n",
      "Total training time: 8.44 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 53.86, NNZs: 183, Bias: -2.680000, T: 1710720, Avg. loss: 0.200362\n",
      "Total training time: 8.61 seconds.\n",
      "-- Epoch 49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 49.26, NNZs: 184, Bias: -2.600000, T: 1746360, Avg. loss: 0.186777\n",
      "Total training time: 8.79 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 45.44, NNZs: 182, Bias: -2.320000, T: 1782000, Avg. loss: 0.183487\n",
      "Total training time: 8.99 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 42.14, NNZs: 184, Bias: -2.040000, T: 1817640, Avg. loss: 0.185125\n",
      "Total training time: 9.17 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 39.43, NNZs: 188, Bias: -1.880000, T: 1853280, Avg. loss: 0.183462\n",
      "Total training time: 9.37 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 37.08, NNZs: 199, Bias: -1.920000, T: 1888920, Avg. loss: 0.184909\n",
      "Total training time: 9.55 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 35.13, NNZs: 195, Bias: -1.800000, T: 1924560, Avg. loss: 0.185819\n",
      "Total training time: 9.71 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 33.53, NNZs: 192, Bias: -2.000000, T: 1960200, Avg. loss: 0.186988\n",
      "Total training time: 9.89 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 32.78, NNZs: 195, Bias: -1.680000, T: 1995840, Avg. loss: 0.160741\n",
      "Total training time: 10.07 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 32.09, NNZs: 184, Bias: -1.520000, T: 2031480, Avg. loss: 0.156281\n",
      "Total training time: 10.25 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 31.42, NNZs: 191, Bias: -1.392000, T: 2067120, Avg. loss: 0.154703\n",
      "Total training time: 10.43 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 30.78, NNZs: 187, Bias: -1.320000, T: 2102760, Avg. loss: 0.153890\n",
      "Total training time: 10.61 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 30.17, NNZs: 181, Bias: -1.264000, T: 2138400, Avg. loss: 0.153558\n",
      "Total training time: 10.81 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 29.57, NNZs: 176, Bias: -1.216000, T: 2174040, Avg. loss: 0.153289\n",
      "Total training time: 11.00 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 28.98, NNZs: 182, Bias: -1.240000, T: 2209680, Avg. loss: 0.152814\n",
      "Total training time: 11.18 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 28.42, NNZs: 180, Bias: -1.248000, T: 2245320, Avg. loss: 0.153060\n",
      "Total training time: 11.38 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 28.28, NNZs: 186, Bias: -1.180800, T: 2280960, Avg. loss: 0.148434\n",
      "Total training time: 11.58 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 28.15, NNZs: 183, Bias: -1.147200, T: 2316600, Avg. loss: 0.147666\n",
      "Total training time: 11.78 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 28.02, NNZs: 181, Bias: -1.121600, T: 2352240, Avg. loss: 0.147362\n",
      "Total training time: 11.97 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 27.89, NNZs: 180, Bias: -1.096000, T: 2387880, Avg. loss: 0.147161\n",
      "Total training time: 12.14 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 27.76, NNZs: 179, Bias: -1.072000, T: 2423520, Avg. loss: 0.146894\n",
      "Total training time: 12.31 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 27.63, NNZs: 172, Bias: -1.067200, T: 2459160, Avg. loss: 0.146732\n",
      "Total training time: 12.51 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 27.61, NNZs: 181, Bias: -1.055040, T: 2494800, Avg. loss: 0.145851\n",
      "Total training time: 12.67 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 27.58, NNZs: 180, Bias: -1.048000, T: 2530440, Avg. loss: 0.145726\n",
      "Total training time: 12.85 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 27.55, NNZs: 180, Bias: -1.041920, T: 2566080, Avg. loss: 0.145660\n",
      "Total training time: 13.05 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 27.53, NNZs: 182, Bias: -1.032960, T: 2601720, Avg. loss: 0.145580\n",
      "Total training time: 13.21 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 27.50, NNZs: 177, Bias: -1.029440, T: 2637360, Avg. loss: 0.145532\n",
      "Total training time: 13.41 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 27.50, NNZs: 180, Bias: -1.026304, T: 2673000, Avg. loss: 0.145339\n",
      "Total training time: 13.60 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 27.49, NNZs: 181, Bias: -1.024320, T: 2708640, Avg. loss: 0.145301\n",
      "Total training time: 13.79 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 27.49, NNZs: 179, Bias: -1.022528, T: 2744280, Avg. loss: 0.145285\n",
      "Total training time: 13.98 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 27.48, NNZs: 179, Bias: -1.020672, T: 2779920, Avg. loss: 0.145269\n",
      "Total training time: 14.16 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 27.48, NNZs: 179, Bias: -1.019008, T: 2815560, Avg. loss: 0.145252\n",
      "Total training time: 14.36 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 27.47, NNZs: 179, Bias: -1.018291, T: 2851200, Avg. loss: 0.145209\n",
      "Total training time: 14.54 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 27.47, NNZs: 180, Bias: -1.017677, T: 2886840, Avg. loss: 0.145201\n",
      "Total training time: 14.70 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 27.47, NNZs: 180, Bias: -1.017344, T: 2922480, Avg. loss: 0.145198\n",
      "Total training time: 14.87 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 27.47, NNZs: 179, Bias: -1.016922, T: 2958120, Avg. loss: 0.145194\n",
      "Total training time: 15.04 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 27.47, NNZs: 179, Bias: -1.016371, T: 2993760, Avg. loss: 0.145191\n",
      "Total training time: 15.21 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 27.47, NNZs: 180, Bias: -1.016320, T: 3029400, Avg. loss: 0.145180\n",
      "Total training time: 15.38 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 27.47, NNZs: 180, Bias: -1.016236, T: 3065040, Avg. loss: 0.145179\n",
      "Total training time: 15.56 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 27.47, NNZs: 180, Bias: -1.016125, T: 3100680, Avg. loss: 0.145178\n",
      "Total training time: 15.72 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 27.47, NNZs: 179, Bias: -1.016061, T: 3136320, Avg. loss: 0.145177\n",
      "Total training time: 15.89 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 27.47, NNZs: 178, Bias: -1.015967, T: 3171960, Avg. loss: 0.145177\n",
      "Total training time: 16.06 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 27.47, NNZs: 178, Bias: -1.015953, T: 3207600, Avg. loss: 0.145174\n",
      "Total training time: 16.24 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 27.47, NNZs: 178, Bias: -1.015914, T: 3243240, Avg. loss: 0.145174\n",
      "Total training time: 16.43 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 27.47, NNZs: 178, Bias: -1.015889, T: 3278880, Avg. loss: 0.145174\n",
      "Total training time: 16.60 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 27.47, NNZs: 178, Bias: -1.015885, T: 3314520, Avg. loss: 0.145174\n",
      "Total training time: 16.77 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 27.47, NNZs: 178, Bias: -1.015845, T: 3350160, Avg. loss: 0.145174\n",
      "Total training time: 16.95 seconds.\n",
      "Convergence after 94 epochs took 16.95 seconds\n",
      "-- Epoch 1\n",
      "Norm: 289.55, NNZs: 292, Bias: 0.000000, T: 35640, Avg. loss: 25.337766\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 326.68, NNZs: 244, Bias: -5.000000, T: 71280, Avg. loss: 22.971710\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 357.98, NNZs: 209, Bias: 25.000000, T: 106920, Avg. loss: 20.427253\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 385.18, NNZs: 231, Bias: 15.000000, T: 142560, Avg. loss: 18.995335\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 396.58, NNZs: 192, Bias: -5.000000, T: 178200, Avg. loss: 17.414286\n",
      "Total training time: 1.07 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 411.69, NNZs: 175, Bias: 0.000000, T: 213840, Avg. loss: 16.591173\n",
      "Total training time: 1.27 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 415.08, NNZs: 186, Bias: 5.000000, T: 249480, Avg. loss: 15.502222\n",
      "Total training time: 1.49 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 445.88, NNZs: 172, Bias: -10.000000, T: 285120, Avg. loss: 14.735589\n",
      "Total training time: 1.70 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 454.43, NNZs: 165, Bias: 10.000000, T: 320760, Avg. loss: 14.387838\n",
      "Total training time: 1.90 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 442.11, NNZs: 144, Bias: 10.000000, T: 356400, Avg. loss: 13.788555\n",
      "Total training time: 2.11 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 441.97, NNZs: 160, Bias: 10.000000, T: 392040, Avg. loss: 13.368969\n",
      "Total training time: 2.30 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 430.87, NNZs: 153, Bias: -5.000000, T: 427680, Avg. loss: 13.069079\n",
      "Total training time: 2.50 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 438.46, NNZs: 153, Bias: 5.000000, T: 463320, Avg. loss: 12.743612\n",
      "Total training time: 2.68 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 469.89, NNZs: 140, Bias: 5.000000, T: 498960, Avg. loss: 12.633943\n",
      "Total training time: 2.87 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 433.87, NNZs: 147, Bias: -5.000000, T: 534600, Avg. loss: 12.053123\n",
      "Total training time: 3.06 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 470.67, NNZs: 134, Bias: 5.000000, T: 570240, Avg. loss: 11.644350\n",
      "Total training time: 3.23 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 441.55, NNZs: 134, Bias: -5.000000, T: 605880, Avg. loss: 12.018594\n",
      "Total training time: 3.42 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 477.06, NNZs: 140, Bias: 5.000000, T: 641520, Avg. loss: 11.609624\n",
      "Total training time: 3.60 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 462.58, NNZs: 148, Bias: 20.000000, T: 677160, Avg. loss: 12.009804\n",
      "Total training time: 3.78 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 478.14, NNZs: 145, Bias: 5.000000, T: 712800, Avg. loss: 11.354683\n",
      "Total training time: 3.96 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 463.89, NNZs: 130, Bias: -5.000000, T: 748440, Avg. loss: 12.212637\n",
      "Total training time: 4.15 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 473.40, NNZs: 148, Bias: 5.000000, T: 784080, Avg. loss: 11.188650\n",
      "Total training time: 4.36 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 480.45, NNZs: 146, Bias: -5.000000, T: 819720, Avg. loss: 10.674403\n",
      "Total training time: 4.55 seconds.\n",
      "-- Epoch 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 450.32, NNZs: 151, Bias: 10.000000, T: 855360, Avg. loss: 10.848763\n",
      "Total training time: 4.73 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 468.33, NNZs: 160, Bias: 10.000000, T: 891000, Avg. loss: 11.474296\n",
      "Total training time: 4.92 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 489.10, NNZs: 140, Bias: 0.000000, T: 926640, Avg. loss: 10.609034\n",
      "Total training time: 5.10 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 447.61, NNZs: 154, Bias: 10.000000, T: 962280, Avg. loss: 11.030984\n",
      "Total training time: 5.28 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 468.43, NNZs: 150, Bias: 10.000000, T: 997920, Avg. loss: 10.954818\n",
      "Total training time: 5.47 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 491.64, NNZs: 145, Bias: 10.000000, T: 1033560, Avg. loss: 10.709813\n",
      "Total training time: 5.66 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 462.60, NNZs: 148, Bias: 10.000000, T: 1069200, Avg. loss: 11.068085\n",
      "Total training time: 5.85 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 478.61, NNZs: 137, Bias: 0.000000, T: 1104840, Avg. loss: 10.753038\n",
      "Total training time: 6.05 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 227.41, NNZs: 140, Bias: 8.000000, T: 1140480, Avg. loss: 2.374520\n",
      "Total training time: 6.23 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 206.52, NNZs: 163, Bias: 5.000000, T: 1176120, Avg. loss: 2.628406\n",
      "Total training time: 6.42 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 211.98, NNZs: 156, Bias: 2.000000, T: 1211760, Avg. loss: 2.666820\n",
      "Total training time: 6.63 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 210.73, NNZs: 153, Bias: 4.000000, T: 1247400, Avg. loss: 2.640492\n",
      "Total training time: 6.84 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 212.55, NNZs: 161, Bias: 3.000000, T: 1283040, Avg. loss: 2.696200\n",
      "Total training time: 7.04 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 207.01, NNZs: 163, Bias: 2.000000, T: 1318680, Avg. loss: 2.709326\n",
      "Total training time: 7.25 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 139.04, NNZs: 166, Bias: 0.400000, T: 1354320, Avg. loss: 0.993672\n",
      "Total training time: 7.46 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 112.48, NNZs: 177, Bias: 0.600000, T: 1389960, Avg. loss: 0.945050\n",
      "Total training time: 7.66 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 101.80, NNZs: 181, Bias: 1.600000, T: 1425600, Avg. loss: 0.973236\n",
      "Total training time: 7.84 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 98.07, NNZs: 187, Bias: 1.600000, T: 1461240, Avg. loss: 0.999125\n",
      "Total training time: 8.04 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 96.26, NNZs: 192, Bias: 1.400000, T: 1496880, Avg. loss: 0.999983\n",
      "Total training time: 8.22 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 94.63, NNZs: 197, Bias: 1.400000, T: 1532520, Avg. loss: 1.024835\n",
      "Total training time: 8.42 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 93.84, NNZs: 188, Bias: 1.600000, T: 1568160, Avg. loss: 1.009623\n",
      "Total training time: 8.62 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 84.86, NNZs: 198, Bias: 1.080000, T: 1603800, Avg. loss: 0.646842\n",
      "Total training time: 8.83 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 77.58, NNZs: 211, Bias: 0.920000, T: 1639440, Avg. loss: 0.639471\n",
      "Total training time: 9.03 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 71.28, NNZs: 208, Bias: 0.840000, T: 1675080, Avg. loss: 0.639452\n",
      "Total training time: 9.23 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 65.86, NNZs: 211, Bias: 0.560000, T: 1710720, Avg. loss: 0.646809\n",
      "Total training time: 9.44 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 61.23, NNZs: 212, Bias: 0.560000, T: 1746360, Avg. loss: 0.643453\n",
      "Total training time: 9.67 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 57.39, NNZs: 215, Bias: 1.040000, T: 1782000, Avg. loss: 0.640560\n",
      "Total training time: 9.88 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 54.25, NNZs: 216, Bias: 0.800000, T: 1817640, Avg. loss: 0.642233\n",
      "Total training time: 10.09 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 52.98, NNZs: 226, Bias: 0.744000, T: 1853280, Avg. loss: 0.553449\n",
      "Total training time: 10.28 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 51.83, NNZs: 225, Bias: 0.712000, T: 1888920, Avg. loss: 0.549507\n",
      "Total training time: 10.49 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 50.70, NNZs: 225, Bias: 0.648000, T: 1924560, Avg. loss: 0.550776\n",
      "Total training time: 10.70 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 49.62, NNZs: 224, Bias: 0.680000, T: 1960200, Avg. loss: 0.548703\n",
      "Total training time: 10.90 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 48.59, NNZs: 229, Bias: 0.576000, T: 1995840, Avg. loss: 0.549094\n",
      "Total training time: 11.10 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 47.57, NNZs: 224, Bias: 0.560000, T: 2031480, Avg. loss: 0.549204\n",
      "Total training time: 11.29 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 46.58, NNZs: 228, Bias: 0.528000, T: 2067120, Avg. loss: 0.549739\n",
      "Total training time: 11.49 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 46.35, NNZs: 230, Bias: 0.539200, T: 2102760, Avg. loss: 0.528106\n",
      "Total training time: 11.69 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 46.13, NNZs: 231, Bias: 0.528000, T: 2138400, Avg. loss: 0.526178\n",
      "Total training time: 11.90 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 45.91, NNZs: 231, Bias: 0.521600, T: 2174040, Avg. loss: 0.527014\n",
      "Total training time: 12.10 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 45.69, NNZs: 231, Bias: 0.502400, T: 2209680, Avg. loss: 0.526589\n",
      "Total training time: 12.30 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 45.48, NNZs: 231, Bias: 0.491200, T: 2245320, Avg. loss: 0.526215\n",
      "Total training time: 12.51 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 45.27, NNZs: 232, Bias: 0.483200, T: 2280960, Avg. loss: 0.526400\n",
      "Total training time: 12.70 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 45.05, NNZs: 230, Bias: 0.467200, T: 2316600, Avg. loss: 0.526356\n",
      "Total training time: 12.90 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 45.01, NNZs: 231, Bias: 0.478720, T: 2352240, Avg. loss: 0.521078\n",
      "Total training time: 13.11 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 44.97, NNZs: 231, Bias: 0.468480, T: 2387880, Avg. loss: 0.520854\n",
      "Total training time: 13.34 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 44.92, NNZs: 232, Bias: 0.476160, T: 2423520, Avg. loss: 0.520592\n",
      "Total training time: 13.56 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 44.88, NNZs: 231, Bias: 0.473280, T: 2459160, Avg. loss: 0.520614\n",
      "Total training time: 13.77 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 44.84, NNZs: 231, Bias: 0.468160, T: 2494800, Avg. loss: 0.520622\n",
      "Total training time: 13.98 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 44.80, NNZs: 231, Bias: 0.463040, T: 2530440, Avg. loss: 0.520676\n",
      "Total training time: 14.18 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 44.79, NNZs: 231, Bias: 0.467968, T: 2566080, Avg. loss: 0.519519\n",
      "Total training time: 14.38 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 44.78, NNZs: 231, Bias: 0.469504, T: 2601720, Avg. loss: 0.519450\n",
      "Total training time: 14.59 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 44.77, NNZs: 231, Bias: 0.470272, T: 2637360, Avg. loss: 0.519429\n",
      "Total training time: 14.79 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 44.76, NNZs: 231, Bias: 0.466624, T: 2673000, Avg. loss: 0.519404\n",
      "Total training time: 15.00 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 44.75, NNZs: 231, Bias: 0.468416, T: 2708640, Avg. loss: 0.519418\n",
      "Total training time: 15.19 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 44.74, NNZs: 231, Bias: 0.468288, T: 2744280, Avg. loss: 0.519405\n",
      "Total training time: 15.38 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 44.74, NNZs: 231, Bias: 0.467930, T: 2779920, Avg. loss: 0.519124\n",
      "Total training time: 15.58 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 44.74, NNZs: 231, Bias: 0.468403, T: 2815560, Avg. loss: 0.519112\n",
      "Total training time: 15.76 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 44.74, NNZs: 231, Bias: 0.468442, T: 2851200, Avg. loss: 0.519111\n",
      "Total training time: 15.95 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 44.74, NNZs: 231, Bias: 0.467366, T: 2886840, Avg. loss: 0.519105\n",
      "Total training time: 16.14 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 44.73, NNZs: 231, Bias: 0.467494, T: 2922480, Avg. loss: 0.519107\n",
      "Total training time: 16.33 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 44.73, NNZs: 231, Bias: 0.467484, T: 2958120, Avg. loss: 0.519040\n",
      "Total training time: 16.52 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 44.73, NNZs: 231, Bias: 0.467553, T: 2993760, Avg. loss: 0.519040\n",
      "Total training time: 16.70 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 44.73, NNZs: 231, Bias: 0.467530, T: 3029400, Avg. loss: 0.519039\n",
      "Total training time: 16.88 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 44.73, NNZs: 231, Bias: 0.467551, T: 3065040, Avg. loss: 0.519040\n",
      "Total training time: 17.08 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 44.73, NNZs: 231, Bias: 0.467510, T: 3100680, Avg. loss: 0.519038\n",
      "Total training time: 17.25 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 44.73, NNZs: 231, Bias: 0.467526, T: 3136320, Avg. loss: 0.519024\n",
      "Total training time: 17.44 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 44.73, NNZs: 231, Bias: 0.467535, T: 3171960, Avg. loss: 0.519024\n",
      "Total training time: 17.63 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 44.73, NNZs: 231, Bias: 0.467542, T: 3207600, Avg. loss: 0.519024\n",
      "Total training time: 17.83 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 44.73, NNZs: 231, Bias: 0.467550, T: 3243240, Avg. loss: 0.519024\n",
      "Total training time: 18.01 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 44.73, NNZs: 231, Bias: 0.467553, T: 3278880, Avg. loss: 0.519024\n",
      "Total training time: 18.20 seconds.\n",
      "Convergence after 92 epochs took 18.20 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   51.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 264.61, NNZs: 299, Bias: -40.000000, T: 35640, Avg. loss: 21.894772\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 319.27, NNZs: 254, Bias: -45.000000, T: 71280, Avg. loss: 19.851979\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 340.29, NNZs: 223, Bias: -35.000000, T: 106920, Avg. loss: 18.066857\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 364.23, NNZs: 204, Bias: -25.000000, T: 142560, Avg. loss: 16.612725\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 366.58, NNZs: 213, Bias: -25.000000, T: 178200, Avg. loss: 16.029170\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 370.84, NNZs: 187, Bias: -10.000000, T: 213840, Avg. loss: 14.601799\n",
      "Total training time: 1.16 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 413.41, NNZs: 171, Bias: -15.000000, T: 249480, Avg. loss: 13.536896\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 409.90, NNZs: 173, Bias: -20.000000, T: 285120, Avg. loss: 13.285549\n",
      "Total training time: 1.54 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 412.09, NNZs: 171, Bias: -30.000000, T: 320760, Avg. loss: 13.118032\n",
      "Total training time: 1.71 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 413.50, NNZs: 180, Bias: -20.000000, T: 356400, Avg. loss: 12.669998\n",
      "Total training time: 1.92 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 427.71, NNZs: 172, Bias: -20.000000, T: 392040, Avg. loss: 12.251580\n",
      "Total training time: 2.11 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 432.67, NNZs: 149, Bias: -15.000000, T: 427680, Avg. loss: 11.701037\n",
      "Total training time: 2.31 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 421.13, NNZs: 157, Bias: -20.000000, T: 463320, Avg. loss: 12.116814\n",
      "Total training time: 2.50 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 413.56, NNZs: 168, Bias: -35.000000, T: 498960, Avg. loss: 11.414277\n",
      "Total training time: 2.68 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 420.88, NNZs: 153, Bias: -25.000000, T: 534600, Avg. loss: 11.741103\n",
      "Total training time: 2.86 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 409.87, NNZs: 167, Bias: -25.000000, T: 570240, Avg. loss: 11.178965\n",
      "Total training time: 3.04 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 422.94, NNZs: 162, Bias: -30.000000, T: 605880, Avg. loss: 11.086807\n",
      "Total training time: 3.22 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 436.28, NNZs: 151, Bias: -20.000000, T: 641520, Avg. loss: 10.918730\n",
      "Total training time: 3.40 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 439.62, NNZs: 166, Bias: -30.000000, T: 677160, Avg. loss: 10.855594\n",
      "Total training time: 3.59 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 434.02, NNZs: 157, Bias: -15.000000, T: 712800, Avg. loss: 10.887204\n",
      "Total training time: 3.76 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 447.05, NNZs: 161, Bias: -20.000000, T: 748440, Avg. loss: 10.914299\n",
      "Total training time: 3.96 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 439.33, NNZs: 163, Bias: -15.000000, T: 784080, Avg. loss: 10.901171\n",
      "Total training time: 4.15 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 439.64, NNZs: 155, Bias: -25.000000, T: 819720, Avg. loss: 10.854909\n",
      "Total training time: 4.34 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 432.00, NNZs: 150, Bias: -30.000000, T: 855360, Avg. loss: 10.834376\n",
      "Total training time: 4.52 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 432.06, NNZs: 157, Bias: -20.000000, T: 891000, Avg. loss: 10.874677\n",
      "Total training time: 4.70 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 451.93, NNZs: 148, Bias: -15.000000, T: 926640, Avg. loss: 10.658330\n",
      "Total training time: 4.87 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 423.19, NNZs: 151, Bias: -20.000000, T: 962280, Avg. loss: 10.833726\n",
      "Total training time: 5.06 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 437.64, NNZs: 141, Bias: -20.000000, T: 997920, Avg. loss: 10.610836\n",
      "Total training time: 5.23 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 440.81, NNZs: 135, Bias: -20.000000, T: 1033560, Avg. loss: 10.739812\n",
      "Total training time: 5.42 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 437.51, NNZs: 146, Bias: -25.000000, T: 1069200, Avg. loss: 10.692258\n",
      "Total training time: 5.61 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 435.07, NNZs: 141, Bias: -20.000000, T: 1104840, Avg. loss: 10.446687\n",
      "Total training time: 5.81 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 420.88, NNZs: 163, Bias: -25.000000, T: 1140480, Avg. loss: 11.288720\n",
      "Total training time: 6.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 422.81, NNZs: 167, Bias: -15.000000, T: 1176120, Avg. loss: 10.741591\n",
      "Total training time: 6.21 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 447.75, NNZs: 133, Bias: -15.000000, T: 1211760, Avg. loss: 10.565564\n",
      "Total training time: 6.41 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 426.74, NNZs: 141, Bias: -10.000000, T: 1247400, Avg. loss: 10.419121\n",
      "Total training time: 6.59 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 431.71, NNZs: 156, Bias: -15.000000, T: 1283040, Avg. loss: 10.816061\n",
      "Total training time: 6.77 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 429.24, NNZs: 139, Bias: -15.000000, T: 1318680, Avg. loss: 10.310060\n",
      "Total training time: 6.96 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 410.33, NNZs: 168, Bias: -25.000000, T: 1354320, Avg. loss: 10.318781\n",
      "Total training time: 7.15 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 426.26, NNZs: 154, Bias: -30.000000, T: 1389960, Avg. loss: 10.731906\n",
      "Total training time: 7.35 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 447.72, NNZs: 145, Bias: -25.000000, T: 1425600, Avg. loss: 10.211662\n",
      "Total training time: 7.53 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 448.92, NNZs: 163, Bias: -10.000000, T: 1461240, Avg. loss: 11.033397\n",
      "Total training time: 7.71 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 438.41, NNZs: 148, Bias: -20.000000, T: 1496880, Avg. loss: 10.308674\n",
      "Total training time: 7.91 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 446.91, NNZs: 142, Bias: -10.000000, T: 1532520, Avg. loss: 10.447254\n",
      "Total training time: 8.09 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 431.31, NNZs: 146, Bias: -25.000000, T: 1568160, Avg. loss: 10.112806\n",
      "Total training time: 8.26 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 426.84, NNZs: 147, Bias: -10.000000, T: 1603800, Avg. loss: 10.479560\n",
      "Total training time: 8.44 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 434.04, NNZs: 157, Bias: -20.000000, T: 1639440, Avg. loss: 10.611596\n",
      "Total training time: 8.62 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 427.13, NNZs: 142, Bias: -20.000000, T: 1675080, Avg. loss: 10.282952\n",
      "Total training time: 8.80 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 436.04, NNZs: 144, Bias: -15.000000, T: 1710720, Avg. loss: 10.628342\n",
      "Total training time: 8.99 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 412.65, NNZs: 150, Bias: -25.000000, T: 1746360, Avg. loss: 10.497189\n",
      "Total training time: 9.16 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 196.43, NNZs: 150, Bias: -9.000000, T: 1782000, Avg. loss: 2.546312\n",
      "Total training time: 9.35 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 191.15, NNZs: 152, Bias: -10.000000, T: 1817640, Avg. loss: 2.557896\n",
      "Total training time: 9.54 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 187.85, NNZs: 171, Bias: -9.000000, T: 1853280, Avg. loss: 2.567868\n",
      "Total training time: 9.72 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 189.56, NNZs: 168, Bias: -9.000000, T: 1888920, Avg. loss: 2.562971\n",
      "Total training time: 9.90 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 187.53, NNZs: 190, Bias: -6.000000, T: 1924560, Avg. loss: 2.598769\n",
      "Total training time: 10.09 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 182.25, NNZs: 178, Bias: -7.000000, T: 1960200, Avg. loss: 2.709105\n",
      "Total training time: 10.26 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 120.63, NNZs: 184, Bias: -4.000000, T: 1995840, Avg. loss: 0.944861\n",
      "Total training time: 10.45 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 96.16, NNZs: 196, Bias: -5.000000, T: 2031480, Avg. loss: 0.906570\n",
      "Total training time: 10.64 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 88.19, NNZs: 192, Bias: -4.200000, T: 2067120, Avg. loss: 0.902564\n",
      "Total training time: 10.84 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 85.84, NNZs: 199, Bias: -4.400000, T: 2102760, Avg. loss: 0.903745\n",
      "Total training time: 11.03 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 84.50, NNZs: 203, Bias: -4.000000, T: 2138400, Avg. loss: 0.902398\n",
      "Total training time: 11.22 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 84.24, NNZs: 198, Bias: -4.200000, T: 2174040, Avg. loss: 0.908678\n",
      "Total training time: 11.43 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 83.86, NNZs: 210, Bias: -4.000000, T: 2209680, Avg. loss: 0.914116\n",
      "Total training time: 11.64 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 84.19, NNZs: 206, Bias: -4.200000, T: 2245320, Avg. loss: 0.910583\n",
      "Total training time: 11.85 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 76.01, NNZs: 217, Bias: -3.000000, T: 2280960, Avg. loss: 0.555535\n",
      "Total training time: 12.06 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 69.48, NNZs: 221, Bias: -2.920000, T: 2316600, Avg. loss: 0.545222\n",
      "Total training time: 12.25 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 63.96, NNZs: 219, Bias: -2.720000, T: 2352240, Avg. loss: 0.543725\n",
      "Total training time: 12.46 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 59.29, NNZs: 222, Bias: -2.480000, T: 2387880, Avg. loss: 0.543941\n",
      "Total training time: 12.66 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 55.33, NNZs: 213, Bias: -2.520000, T: 2423520, Avg. loss: 0.543167\n",
      "Total training time: 12.86 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 52.01, NNZs: 213, Bias: -2.240000, T: 2459160, Avg. loss: 0.545764\n",
      "Total training time: 13.05 seconds.\n",
      "-- Epoch 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 49.27, NNZs: 224, Bias: -2.280000, T: 2494800, Avg. loss: 0.545477\n",
      "Total training time: 13.23 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 46.84, NNZs: 214, Bias: -2.360000, T: 2530440, Avg. loss: 0.545810\n",
      "Total training time: 13.42 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 45.73, NNZs: 223, Bias: -2.200000, T: 2566080, Avg. loss: 0.464537\n",
      "Total training time: 13.61 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 44.75, NNZs: 225, Bias: -2.048000, T: 2601720, Avg. loss: 0.460705\n",
      "Total training time: 13.80 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 43.81, NNZs: 228, Bias: -2.088000, T: 2637360, Avg. loss: 0.460012\n",
      "Total training time: 13.99 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 42.89, NNZs: 227, Bias: -1.952000, T: 2673000, Avg. loss: 0.460972\n",
      "Total training time: 14.18 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 42.00, NNZs: 223, Bias: -1.944000, T: 2708640, Avg. loss: 0.459826\n",
      "Total training time: 14.36 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 41.15, NNZs: 224, Bias: -1.984000, T: 2744280, Avg. loss: 0.459716\n",
      "Total training time: 14.55 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 40.32, NNZs: 226, Bias: -1.976000, T: 2779920, Avg. loss: 0.459769\n",
      "Total training time: 14.73 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 40.12, NNZs: 228, Bias: -1.936000, T: 2815560, Avg. loss: 0.441865\n",
      "Total training time: 14.91 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 39.93, NNZs: 229, Bias: -1.945600, T: 2851200, Avg. loss: 0.440377\n",
      "Total training time: 15.09 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 39.74, NNZs: 228, Bias: -1.936000, T: 2886840, Avg. loss: 0.440084\n",
      "Total training time: 15.27 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 39.55, NNZs: 227, Bias: -1.921600, T: 2922480, Avg. loss: 0.439981\n",
      "Total training time: 15.46 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 39.37, NNZs: 226, Bias: -1.886400, T: 2958120, Avg. loss: 0.440131\n",
      "Total training time: 15.65 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 39.18, NNZs: 229, Bias: -1.900800, T: 2993760, Avg. loss: 0.440067\n",
      "Total training time: 15.84 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 39.00, NNZs: 228, Bias: -1.908800, T: 3029400, Avg. loss: 0.439788\n",
      "Total training time: 16.04 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 38.96, NNZs: 229, Bias: -1.900160, T: 3065040, Avg. loss: 0.436032\n",
      "Total training time: 16.21 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 38.92, NNZs: 229, Bias: -1.901760, T: 3100680, Avg. loss: 0.435751\n",
      "Total training time: 16.41 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 38.89, NNZs: 229, Bias: -1.897600, T: 3136320, Avg. loss: 0.435696\n",
      "Total training time: 16.59 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 38.85, NNZs: 229, Bias: -1.897920, T: 3171960, Avg. loss: 0.435680\n",
      "Total training time: 16.76 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 38.81, NNZs: 228, Bias: -1.900480, T: 3207600, Avg. loss: 0.435576\n",
      "Total training time: 16.95 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 38.77, NNZs: 228, Bias: -1.893120, T: 3243240, Avg. loss: 0.435607\n",
      "Total training time: 17.14 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 38.77, NNZs: 228, Bias: -1.892288, T: 3278880, Avg. loss: 0.434701\n",
      "Total training time: 17.34 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 38.76, NNZs: 228, Bias: -1.889792, T: 3314520, Avg. loss: 0.434632\n",
      "Total training time: 17.54 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 38.75, NNZs: 228, Bias: -1.889600, T: 3350160, Avg. loss: 0.434621\n",
      "Total training time: 17.72 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 38.74, NNZs: 228, Bias: -1.889408, T: 3385800, Avg. loss: 0.434551\n",
      "Total training time: 17.91 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 38.74, NNZs: 228, Bias: -1.886080, T: 3421440, Avg. loss: 0.434543\n",
      "Total training time: 18.12 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 38.73, NNZs: 228, Bias: -1.889638, T: 3457080, Avg. loss: 0.434356\n",
      "Total training time: 18.30 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 38.73, NNZs: 228, Bias: -1.889190, T: 3492720, Avg. loss: 0.434364\n",
      "Total training time: 18.49 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 38.73, NNZs: 228, Bias: -1.888077, T: 3528360, Avg. loss: 0.434335\n",
      "Total training time: 18.67 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 38.73, NNZs: 228, Bias: -1.888371, T: 3564000, Avg. loss: 0.434354\n",
      "Total training time: 18.86 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 38.73, NNZs: 228, Bias: -1.888666, T: 3599640, Avg. loss: 0.434349\n",
      "Total training time: 19.07 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 38.73, NNZs: 228, Bias: -1.888712, T: 3635280, Avg. loss: 0.434295\n",
      "Total training time: 19.26 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 38.73, NNZs: 228, Bias: -1.888717, T: 3670920, Avg. loss: 0.434295\n",
      "Total training time: 19.44 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 38.73, NNZs: 228, Bias: -1.888701, T: 3706560, Avg. loss: 0.434294\n",
      "Total training time: 19.64 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 38.73, NNZs: 228, Bias: -1.888701, T: 3742200, Avg. loss: 0.434293\n",
      "Total training time: 19.82 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 38.73, NNZs: 228, Bias: -1.888684, T: 3777840, Avg. loss: 0.434293\n",
      "Total training time: 20.02 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 38.73, NNZs: 228, Bias: -1.888686, T: 3813480, Avg. loss: 0.434281\n",
      "Total training time: 20.19 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 38.73, NNZs: 228, Bias: -1.888688, T: 3849120, Avg. loss: 0.434281\n",
      "Total training time: 20.38 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 38.73, NNZs: 228, Bias: -1.888692, T: 3884760, Avg. loss: 0.434281\n",
      "Total training time: 20.57 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 38.73, NNZs: 228, Bias: -1.888692, T: 3920400, Avg. loss: 0.434281\n",
      "Total training time: 20.74 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 38.73, NNZs: 228, Bias: -1.888693, T: 3956040, Avg. loss: 0.434281\n",
      "Total training time: 20.93 seconds.\n",
      "Convergence after 111 epochs took 20.93 seconds\n",
      "-- Epoch 1\n",
      "Norm: 182.26, NNZs: 267, Bias: -80.000000, T: 35640, Avg. loss: 8.631000\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 223.07, NNZs: 213, Bias: -90.000000, T: 71280, Avg. loss: 7.365679\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 242.12, NNZs: 211, Bias: -70.000000, T: 106920, Avg. loss: 6.536553\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 253.29, NNZs: 188, Bias: -65.000000, T: 142560, Avg. loss: 5.919179\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 236.12, NNZs: 183, Bias: -60.000000, T: 178200, Avg. loss: 5.284960\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 261.80, NNZs: 174, Bias: -75.000000, T: 213840, Avg. loss: 5.131466\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 275.36, NNZs: 150, Bias: -45.000000, T: 249480, Avg. loss: 4.658041\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 296.10, NNZs: 146, Bias: -45.000000, T: 285120, Avg. loss: 4.500450\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 277.34, NNZs: 145, Bias: -30.000000, T: 320760, Avg. loss: 4.043963\n",
      "Total training time: 1.59 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 274.62, NNZs: 142, Bias: -40.000000, T: 356400, Avg. loss: 4.194482\n",
      "Total training time: 1.76 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 282.77, NNZs: 153, Bias: -40.000000, T: 392040, Avg. loss: 4.090625\n",
      "Total training time: 1.92 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 275.66, NNZs: 131, Bias: -40.000000, T: 427680, Avg. loss: 3.872639\n",
      "Total training time: 2.09 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 266.99, NNZs: 150, Bias: -45.000000, T: 463320, Avg. loss: 3.826068\n",
      "Total training time: 2.26 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 290.03, NNZs: 135, Bias: -40.000000, T: 498960, Avg. loss: 3.777892\n",
      "Total training time: 2.42 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 299.89, NNZs: 145, Bias: -40.000000, T: 534600, Avg. loss: 3.706402\n",
      "Total training time: 2.59 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 271.29, NNZs: 145, Bias: -45.000000, T: 570240, Avg. loss: 3.647906\n",
      "Total training time: 2.76 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 310.43, NNZs: 125, Bias: -45.000000, T: 605880, Avg. loss: 3.402173\n",
      "Total training time: 2.93 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 300.64, NNZs: 135, Bias: -45.000000, T: 641520, Avg. loss: 3.380395\n",
      "Total training time: 3.10 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 289.75, NNZs: 125, Bias: -35.000000, T: 677160, Avg. loss: 3.638429\n",
      "Total training time: 3.25 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 291.69, NNZs: 140, Bias: -30.000000, T: 712800, Avg. loss: 3.300878\n",
      "Total training time: 3.42 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 301.67, NNZs: 141, Bias: -45.000000, T: 748440, Avg. loss: 3.551940\n",
      "Total training time: 3.59 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 283.57, NNZs: 139, Bias: -35.000000, T: 784080, Avg. loss: 3.539868\n",
      "Total training time: 3.75 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 278.40, NNZs: 151, Bias: -40.000000, T: 819720, Avg. loss: 3.577829\n",
      "Total training time: 3.92 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 300.87, NNZs: 140, Bias: -45.000000, T: 855360, Avg. loss: 3.487287\n",
      "Total training time: 4.09 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 274.14, NNZs: 131, Bias: -35.000000, T: 891000, Avg. loss: 3.326990\n",
      "Total training time: 4.25 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 142.80, NNZs: 122, Bias: -9.000000, T: 926640, Avg. loss: 0.684610\n",
      "Total training time: 4.41 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 138.88, NNZs: 146, Bias: -11.000000, T: 962280, Avg. loss: 0.689832\n",
      "Total training time: 4.57 seconds.\n",
      "-- Epoch 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 137.50, NNZs: 138, Bias: -9.000000, T: 997920, Avg. loss: 0.737143\n",
      "Total training time: 4.74 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 137.42, NNZs: 137, Bias: -9.000000, T: 1033560, Avg. loss: 0.726937\n",
      "Total training time: 4.90 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 138.03, NNZs: 179, Bias: -8.000000, T: 1069200, Avg. loss: 0.782045\n",
      "Total training time: 5.08 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 132.93, NNZs: 165, Bias: -9.000000, T: 1104840, Avg. loss: 0.837833\n",
      "Total training time: 5.25 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 88.88, NNZs: 164, Bias: -4.200000, T: 1140480, Avg. loss: 0.309994\n",
      "Total training time: 5.42 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 70.98, NNZs: 167, Bias: -3.800000, T: 1176120, Avg. loss: 0.285958\n",
      "Total training time: 5.60 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 63.81, NNZs: 178, Bias: -3.800000, T: 1211760, Avg. loss: 0.304009\n",
      "Total training time: 5.76 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 60.88, NNZs: 180, Bias: -4.000000, T: 1247400, Avg. loss: 0.304326\n",
      "Total training time: 5.93 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 59.76, NNZs: 178, Bias: -3.400000, T: 1283040, Avg. loss: 0.307989\n",
      "Total training time: 6.12 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 60.03, NNZs: 182, Bias: -4.200000, T: 1318680, Avg. loss: 0.304684\n",
      "Total training time: 6.29 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 59.98, NNZs: 188, Bias: -4.000000, T: 1354320, Avg. loss: 0.306717\n",
      "Total training time: 6.46 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 54.23, NNZs: 198, Bias: -2.640000, T: 1389960, Avg. loss: 0.199169\n",
      "Total training time: 6.64 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 49.52, NNZs: 198, Bias: -2.560000, T: 1425600, Avg. loss: 0.187760\n",
      "Total training time: 6.81 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 45.55, NNZs: 193, Bias: -2.200000, T: 1461240, Avg. loss: 0.187109\n",
      "Total training time: 7.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 42.15, NNZs: 196, Bias: -2.200000, T: 1496880, Avg. loss: 0.187076\n",
      "Total training time: 7.18 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 39.25, NNZs: 193, Bias: -2.080000, T: 1532520, Avg. loss: 0.187847\n",
      "Total training time: 7.35 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 36.95, NNZs: 201, Bias: -2.000000, T: 1568160, Avg. loss: 0.184750\n",
      "Total training time: 7.52 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 35.05, NNZs: 199, Bias: -2.040000, T: 1603800, Avg. loss: 0.186456\n",
      "Total training time: 7.70 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 33.39, NNZs: 187, Bias: -1.880000, T: 1639440, Avg. loss: 0.186379\n",
      "Total training time: 7.87 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 32.01, NNZs: 188, Bias: -1.880000, T: 1675080, Avg. loss: 0.187119\n",
      "Total training time: 8.05 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 30.94, NNZs: 188, Bias: -1.920000, T: 1710720, Avg. loss: 0.185727\n",
      "Total training time: 8.22 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 30.08, NNZs: 192, Bias: -1.920000, T: 1746360, Avg. loss: 0.185454\n",
      "Total training time: 8.39 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 29.40, NNZs: 193, Bias: -1.688000, T: 1782000, Avg. loss: 0.161869\n",
      "Total training time: 8.57 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 28.78, NNZs: 192, Bias: -1.528000, T: 1817640, Avg. loss: 0.157402\n",
      "Total training time: 8.75 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 28.20, NNZs: 187, Bias: -1.488000, T: 1853280, Avg. loss: 0.155615\n",
      "Total training time: 8.93 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 27.64, NNZs: 187, Bias: -1.416000, T: 1888920, Avg. loss: 0.154793\n",
      "Total training time: 9.11 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 27.10, NNZs: 183, Bias: -1.360000, T: 1924560, Avg. loss: 0.154563\n",
      "Total training time: 9.28 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 26.57, NNZs: 189, Bias: -1.352000, T: 1960200, Avg. loss: 0.154165\n",
      "Total training time: 9.45 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 26.06, NNZs: 179, Bias: -1.296000, T: 1995840, Avg. loss: 0.154181\n",
      "Total training time: 9.62 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 25.57, NNZs: 177, Bias: -1.304000, T: 2031480, Avg. loss: 0.154376\n",
      "Total training time: 9.79 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 25.45, NNZs: 189, Bias: -1.241600, T: 2067120, Avg. loss: 0.148672\n",
      "Total training time: 9.97 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 25.33, NNZs: 187, Bias: -1.212800, T: 2102760, Avg. loss: 0.147997\n",
      "Total training time: 10.15 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 25.21, NNZs: 187, Bias: -1.182400, T: 2138400, Avg. loss: 0.147619\n",
      "Total training time: 10.32 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 25.09, NNZs: 180, Bias: -1.142400, T: 2174040, Avg. loss: 0.147438\n",
      "Total training time: 10.50 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 24.98, NNZs: 182, Bias: -1.113600, T: 2209680, Avg. loss: 0.147168\n",
      "Total training time: 10.68 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 24.86, NNZs: 177, Bias: -1.104000, T: 2245320, Avg. loss: 0.147052\n",
      "Total training time: 10.85 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 24.84, NNZs: 182, Bias: -1.086080, T: 2280960, Avg. loss: 0.146006\n",
      "Total training time: 11.02 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 24.82, NNZs: 183, Bias: -1.078080, T: 2316600, Avg. loss: 0.145858\n",
      "Total training time: 11.20 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 24.79, NNZs: 180, Bias: -1.069760, T: 2352240, Avg. loss: 0.145803\n",
      "Total training time: 11.37 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 24.77, NNZs: 182, Bias: -1.064640, T: 2387880, Avg. loss: 0.145750\n",
      "Total training time: 11.54 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 24.74, NNZs: 179, Bias: -1.058560, T: 2423520, Avg. loss: 0.145689\n",
      "Total training time: 11.72 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 24.72, NNZs: 183, Bias: -1.050240, T: 2459160, Avg. loss: 0.145619\n",
      "Total training time: 11.88 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 24.72, NNZs: 182, Bias: -1.048448, T: 2494800, Avg. loss: 0.145412\n",
      "Total training time: 12.06 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 24.71, NNZs: 181, Bias: -1.045952, T: 2530440, Avg. loss: 0.145383\n",
      "Total training time: 12.23 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 24.71, NNZs: 182, Bias: -1.044160, T: 2566080, Avg. loss: 0.145362\n",
      "Total training time: 12.41 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 24.70, NNZs: 182, Bias: -1.042112, T: 2601720, Avg. loss: 0.145346\n",
      "Total training time: 12.58 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 24.70, NNZs: 181, Bias: -1.041216, T: 2637360, Avg. loss: 0.145326\n",
      "Total training time: 12.75 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 24.70, NNZs: 182, Bias: -1.040269, T: 2673000, Avg. loss: 0.145290\n",
      "Total training time: 12.92 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 24.70, NNZs: 182, Bias: -1.039808, T: 2708640, Avg. loss: 0.145280\n",
      "Total training time: 13.09 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 24.69, NNZs: 182, Bias: -1.039270, T: 2744280, Avg. loss: 0.145276\n",
      "Total training time: 13.25 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 24.69, NNZs: 182, Bias: -1.038950, T: 2779920, Avg. loss: 0.145273\n",
      "Total training time: 13.42 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 24.69, NNZs: 182, Bias: -1.038323, T: 2815560, Avg. loss: 0.145270\n",
      "Total training time: 13.59 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 24.69, NNZs: 182, Bias: -1.038331, T: 2851200, Avg. loss: 0.145260\n",
      "Total training time: 13.76 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 24.69, NNZs: 182, Bias: -1.038282, T: 2886840, Avg. loss: 0.145258\n",
      "Total training time: 13.93 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 24.69, NNZs: 182, Bias: -1.038190, T: 2922480, Avg. loss: 0.145257\n",
      "Total training time: 14.10 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 24.69, NNZs: 182, Bias: -1.038118, T: 2958120, Avg. loss: 0.145257\n",
      "Total training time: 14.26 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 24.69, NNZs: 182, Bias: -1.038006, T: 2993760, Avg. loss: 0.145256\n",
      "Total training time: 14.43 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 24.69, NNZs: 182, Bias: -1.037965, T: 3029400, Avg. loss: 0.145254\n",
      "Total training time: 14.61 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 24.69, NNZs: 182, Bias: -1.037949, T: 3065040, Avg. loss: 0.145254\n",
      "Total training time: 14.77 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 24.69, NNZs: 182, Bias: -1.037933, T: 3100680, Avg. loss: 0.145253\n",
      "Total training time: 14.94 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 24.69, NNZs: 182, Bias: -1.037917, T: 3136320, Avg. loss: 0.145253\n",
      "Total training time: 15.12 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 24.69, NNZs: 182, Bias: -1.037901, T: 3171960, Avg. loss: 0.145253\n",
      "Total training time: 15.28 seconds.\n",
      "Convergence after 89 epochs took 15.28 seconds\n",
      "-- Epoch 1\n",
      "Norm: 280.64, NNZs: 297, Bias: -5.000000, T: 35640, Avg. loss: 25.258043\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 338.51, NNZs: 255, Bias: 10.000000, T: 71280, Avg. loss: 22.603203\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 363.84, NNZs: 217, Bias: 20.000000, T: 106920, Avg. loss: 20.378556\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 373.34, NNZs: 208, Bias: -5.000000, T: 142560, Avg. loss: 18.888812\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 394.12, NNZs: 201, Bias: 15.000000, T: 178200, Avg. loss: 17.660603\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 415.53, NNZs: 181, Bias: 15.000000, T: 213840, Avg. loss: 16.694919\n",
      "Total training time: 1.16 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 421.10, NNZs: 189, Bias: 5.000000, T: 249480, Avg. loss: 15.539193\n",
      "Total training time: 1.36 seconds.\n",
      "-- Epoch 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 434.51, NNZs: 170, Bias: 10.000000, T: 285120, Avg. loss: 14.561562\n",
      "Total training time: 1.54 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 436.53, NNZs: 164, Bias: 0.000000, T: 320760, Avg. loss: 14.572823\n",
      "Total training time: 1.72 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 457.85, NNZs: 161, Bias: 5.000000, T: 356400, Avg. loss: 13.523565\n",
      "Total training time: 1.91 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 437.82, NNZs: 161, Bias: 15.000000, T: 392040, Avg. loss: 13.092891\n",
      "Total training time: 2.09 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 444.23, NNZs: 168, Bias: 5.000000, T: 427680, Avg. loss: 13.143417\n",
      "Total training time: 2.28 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 468.16, NNZs: 163, Bias: 5.000000, T: 463320, Avg. loss: 13.058170\n",
      "Total training time: 2.45 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 452.01, NNZs: 155, Bias: -5.000000, T: 498960, Avg. loss: 12.035370\n",
      "Total training time: 2.64 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 451.81, NNZs: 137, Bias: 5.000000, T: 534600, Avg. loss: 12.079927\n",
      "Total training time: 2.82 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 481.02, NNZs: 150, Bias: 20.000000, T: 570240, Avg. loss: 12.106155\n",
      "Total training time: 2.99 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 445.31, NNZs: 164, Bias: 5.000000, T: 605880, Avg. loss: 11.883993\n",
      "Total training time: 3.16 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 462.24, NNZs: 144, Bias: 5.000000, T: 641520, Avg. loss: 11.939291\n",
      "Total training time: 3.35 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 478.29, NNZs: 156, Bias: -5.000000, T: 677160, Avg. loss: 11.848315\n",
      "Total training time: 3.52 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 455.82, NNZs: 156, Bias: 15.000000, T: 712800, Avg. loss: 11.309434\n",
      "Total training time: 3.72 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 470.84, NNZs: 148, Bias: 10.000000, T: 748440, Avg. loss: 11.482953\n",
      "Total training time: 3.90 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 527.77, NNZs: 135, Bias: 5.000000, T: 784080, Avg. loss: 11.972235\n",
      "Total training time: 4.06 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 460.54, NNZs: 137, Bias: 5.000000, T: 819720, Avg. loss: 11.307947\n",
      "Total training time: 4.24 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 488.94, NNZs: 158, Bias: 20.000000, T: 855360, Avg. loss: 11.581974\n",
      "Total training time: 4.42 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 492.21, NNZs: 142, Bias: -5.000000, T: 891000, Avg. loss: 11.191838\n",
      "Total training time: 4.59 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 484.87, NNZs: 142, Bias: -5.000000, T: 926640, Avg. loss: 10.799539\n",
      "Total training time: 4.77 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 473.05, NNZs: 146, Bias: 0.000000, T: 962280, Avg. loss: 10.761954\n",
      "Total training time: 4.94 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 455.35, NNZs: 138, Bias: 10.000000, T: 997920, Avg. loss: 10.822159\n",
      "Total training time: 5.15 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 441.64, NNZs: 160, Bias: 5.000000, T: 1033560, Avg. loss: 11.280737\n",
      "Total training time: 5.33 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 474.98, NNZs: 149, Bias: 0.000000, T: 1069200, Avg. loss: 11.556589\n",
      "Total training time: 5.51 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 464.78, NNZs: 123, Bias: 5.000000, T: 1104840, Avg. loss: 11.135334\n",
      "Total training time: 5.69 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 482.28, NNZs: 153, Bias: 5.000000, T: 1140480, Avg. loss: 11.002357\n",
      "Total training time: 5.87 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 213.74, NNZs: 149, Bias: 2.000000, T: 1176120, Avg. loss: 2.611586\n",
      "Total training time: 6.04 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 210.07, NNZs: 156, Bias: 4.000000, T: 1211760, Avg. loss: 2.635701\n",
      "Total training time: 6.21 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 210.79, NNZs: 158, Bias: 2.000000, T: 1247400, Avg. loss: 2.618962\n",
      "Total training time: 6.40 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 206.33, NNZs: 152, Bias: 1.000000, T: 1283040, Avg. loss: 2.672252\n",
      "Total training time: 6.57 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 203.23, NNZs: 171, Bias: 4.000000, T: 1318680, Avg. loss: 2.760650\n",
      "Total training time: 6.74 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 213.99, NNZs: 164, Bias: 3.000000, T: 1354320, Avg. loss: 2.677166\n",
      "Total training time: 6.93 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 143.08, NNZs: 170, Bias: 0.600000, T: 1389960, Avg. loss: 0.970837\n",
      "Total training time: 7.14 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 113.43, NNZs: 171, Bias: 0.800000, T: 1425600, Avg. loss: 0.946922\n",
      "Total training time: 7.33 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 103.50, NNZs: 188, Bias: 1.400000, T: 1461240, Avg. loss: 0.947506\n",
      "Total training time: 7.50 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 99.32, NNZs: 185, Bias: 1.400000, T: 1496880, Avg. loss: 0.953355\n",
      "Total training time: 7.68 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 97.67, NNZs: 186, Bias: 1.400000, T: 1532520, Avg. loss: 0.980189\n",
      "Total training time: 7.86 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 96.42, NNZs: 195, Bias: 1.200000, T: 1568160, Avg. loss: 0.987503\n",
      "Total training time: 8.04 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 96.36, NNZs: 196, Bias: 0.600000, T: 1603800, Avg. loss: 0.990257\n",
      "Total training time: 8.24 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 87.25, NNZs: 199, Bias: 0.320000, T: 1639440, Avg. loss: 0.637444\n",
      "Total training time: 8.43 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 79.92, NNZs: 203, Bias: 0.560000, T: 1675080, Avg. loss: 0.624412\n",
      "Total training time: 8.61 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 73.74, NNZs: 207, Bias: 0.800000, T: 1710720, Avg. loss: 0.626597\n",
      "Total training time: 8.79 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 68.36, NNZs: 212, Bias: 0.800000, T: 1746360, Avg. loss: 0.628370\n",
      "Total training time: 8.97 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 64.00, NNZs: 211, Bias: 0.760000, T: 1782000, Avg. loss: 0.623568\n",
      "Total training time: 9.17 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 60.20, NNZs: 216, Bias: 0.640000, T: 1817640, Avg. loss: 0.624628\n",
      "Total training time: 9.36 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 57.07, NNZs: 215, Bias: 0.720000, T: 1853280, Avg. loss: 0.629795\n",
      "Total training time: 9.53 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 55.77, NNZs: 222, Bias: 0.584000, T: 1888920, Avg. loss: 0.548668\n",
      "Total training time: 9.72 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 54.59, NNZs: 224, Bias: 0.544000, T: 1924560, Avg. loss: 0.544696\n",
      "Total training time: 9.90 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 53.43, NNZs: 225, Bias: 0.592000, T: 1960200, Avg. loss: 0.543590\n",
      "Total training time: 10.07 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 52.31, NNZs: 224, Bias: 0.632000, T: 1995840, Avg. loss: 0.546116\n",
      "Total training time: 10.25 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 51.23, NNZs: 225, Bias: 0.560000, T: 2031480, Avg. loss: 0.544560\n",
      "Total training time: 10.43 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 50.18, NNZs: 222, Bias: 0.584000, T: 2067120, Avg. loss: 0.545893\n",
      "Total training time: 10.61 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 49.15, NNZs: 226, Bias: 0.504000, T: 2102760, Avg. loss: 0.546139\n",
      "Total training time: 10.79 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 48.15, NNZs: 223, Bias: 0.480000, T: 2138400, Avg. loss: 0.544320\n",
      "Total training time: 10.97 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 47.92, NNZs: 224, Bias: 0.536000, T: 2174040, Avg. loss: 0.526005\n",
      "Total training time: 11.15 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 47.69, NNZs: 226, Bias: 0.556800, T: 2209680, Avg. loss: 0.524174\n",
      "Total training time: 11.33 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 47.47, NNZs: 225, Bias: 0.545600, T: 2245320, Avg. loss: 0.524538\n",
      "Total training time: 11.50 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 47.25, NNZs: 225, Bias: 0.526400, T: 2280960, Avg. loss: 0.524868\n",
      "Total training time: 11.69 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 47.03, NNZs: 223, Bias: 0.537600, T: 2316600, Avg. loss: 0.524571\n",
      "Total training time: 11.87 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 46.81, NNZs: 224, Bias: 0.521600, T: 2352240, Avg. loss: 0.524291\n",
      "Total training time: 12.04 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 46.59, NNZs: 224, Bias: 0.515200, T: 2387880, Avg. loss: 0.524531\n",
      "Total training time: 12.22 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 46.55, NNZs: 224, Bias: 0.517760, T: 2423520, Avg. loss: 0.520197\n",
      "Total training time: 12.40 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 46.50, NNZs: 224, Bias: 0.524480, T: 2459160, Avg. loss: 0.519615\n",
      "Total training time: 12.57 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 46.46, NNZs: 224, Bias: 0.516160, T: 2494800, Avg. loss: 0.519608\n",
      "Total training time: 12.75 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 46.41, NNZs: 224, Bias: 0.528320, T: 2530440, Avg. loss: 0.519586\n",
      "Total training time: 12.93 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 46.37, NNZs: 224, Bias: 0.515840, T: 2566080, Avg. loss: 0.519500\n",
      "Total training time: 13.11 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 46.33, NNZs: 224, Bias: 0.516800, T: 2601720, Avg. loss: 0.519529\n",
      "Total training time: 13.30 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 46.32, NNZs: 224, Bias: 0.518656, T: 2637360, Avg. loss: 0.518443\n",
      "Total training time: 13.47 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 46.31, NNZs: 224, Bias: 0.518912, T: 2673000, Avg. loss: 0.518437\n",
      "Total training time: 13.65 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 46.30, NNZs: 224, Bias: 0.518208, T: 2708640, Avg. loss: 0.518461\n",
      "Total training time: 13.83 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 46.29, NNZs: 225, Bias: 0.519104, T: 2744280, Avg. loss: 0.518416\n",
      "Total training time: 14.00 seconds.\n",
      "-- Epoch 78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 46.28, NNZs: 224, Bias: 0.515392, T: 2779920, Avg. loss: 0.518401\n",
      "Total training time: 14.18 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 46.27, NNZs: 225, Bias: 0.517440, T: 2815560, Avg. loss: 0.518442\n",
      "Total training time: 14.36 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 46.27, NNZs: 225, Bias: 0.516621, T: 2851200, Avg. loss: 0.518171\n",
      "Total training time: 14.54 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 46.27, NNZs: 225, Bias: 0.515955, T: 2886840, Avg. loss: 0.518157\n",
      "Total training time: 14.73 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 46.27, NNZs: 225, Bias: 0.516096, T: 2922480, Avg. loss: 0.518145\n",
      "Total training time: 14.91 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 46.27, NNZs: 225, Bias: 0.516531, T: 2958120, Avg. loss: 0.518148\n",
      "Total training time: 15.08 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 46.26, NNZs: 225, Bias: 0.515750, T: 2993760, Avg. loss: 0.518150\n",
      "Total training time: 15.26 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 46.26, NNZs: 225, Bias: 0.515850, T: 3029400, Avg. loss: 0.518090\n",
      "Total training time: 15.44 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 46.26, NNZs: 225, Bias: 0.515858, T: 3065040, Avg. loss: 0.518089\n",
      "Total training time: 15.63 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 46.26, NNZs: 225, Bias: 0.515917, T: 3100680, Avg. loss: 0.518088\n",
      "Total training time: 15.81 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 46.26, NNZs: 225, Bias: 0.515955, T: 3136320, Avg. loss: 0.518087\n",
      "Total training time: 15.98 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 46.26, NNZs: 225, Bias: 0.515896, T: 3171960, Avg. loss: 0.518088\n",
      "Total training time: 16.16 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 46.26, NNZs: 225, Bias: 0.515890, T: 3207600, Avg. loss: 0.518074\n",
      "Total training time: 16.34 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 46.26, NNZs: 225, Bias: 0.515888, T: 3243240, Avg. loss: 0.518074\n",
      "Total training time: 16.51 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 46.26, NNZs: 225, Bias: 0.515879, T: 3278880, Avg. loss: 0.518074\n",
      "Total training time: 16.70 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 46.26, NNZs: 225, Bias: 0.515875, T: 3314520, Avg. loss: 0.518074\n",
      "Total training time: 16.87 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 46.26, NNZs: 225, Bias: 0.515872, T: 3350160, Avg. loss: 0.518074\n",
      "Total training time: 17.05 seconds.\n",
      "Convergence after 94 epochs took 17.05 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   53.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 274.29, NNZs: 295, Bias: -30.000000, T: 35640, Avg. loss: 21.768073\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 310.16, NNZs: 264, Bias: -35.000000, T: 71280, Avg. loss: 19.871913\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 332.61, NNZs: 228, Bias: -35.000000, T: 106920, Avg. loss: 17.831057\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 352.25, NNZs: 221, Bias: -40.000000, T: 142560, Avg. loss: 16.670506\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 359.44, NNZs: 190, Bias: -30.000000, T: 178200, Avg. loss: 15.882713\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 385.93, NNZs: 187, Bias: -20.000000, T: 213840, Avg. loss: 14.736021\n",
      "Total training time: 1.16 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 401.81, NNZs: 189, Bias: -30.000000, T: 249480, Avg. loss: 13.985249\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 402.74, NNZs: 183, Bias: -20.000000, T: 285120, Avg. loss: 13.393308\n",
      "Total training time: 1.54 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 402.57, NNZs: 172, Bias: -15.000000, T: 320760, Avg. loss: 13.072598\n",
      "Total training time: 1.73 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 426.22, NNZs: 167, Bias: -25.000000, T: 356400, Avg. loss: 12.691069\n",
      "Total training time: 1.92 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 401.34, NNZs: 166, Bias: -15.000000, T: 392040, Avg. loss: 12.356113\n",
      "Total training time: 2.11 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 443.70, NNZs: 166, Bias: -20.000000, T: 427680, Avg. loss: 12.039654\n",
      "Total training time: 2.28 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 430.16, NNZs: 151, Bias: -5.000000, T: 463320, Avg. loss: 11.851790\n",
      "Total training time: 2.47 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 431.67, NNZs: 163, Bias: -20.000000, T: 498960, Avg. loss: 12.233638\n",
      "Total training time: 2.66 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 442.37, NNZs: 160, Bias: -20.000000, T: 534600, Avg. loss: 11.610960\n",
      "Total training time: 2.84 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 429.43, NNZs: 151, Bias: -15.000000, T: 570240, Avg. loss: 11.506462\n",
      "Total training time: 3.02 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 431.78, NNZs: 167, Bias: -20.000000, T: 605880, Avg. loss: 11.139315\n",
      "Total training time: 3.20 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 429.81, NNZs: 151, Bias: -5.000000, T: 641520, Avg. loss: 11.310210\n",
      "Total training time: 3.38 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 432.20, NNZs: 160, Bias: -15.000000, T: 677160, Avg. loss: 10.787705\n",
      "Total training time: 3.57 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 436.62, NNZs: 133, Bias: -25.000000, T: 712800, Avg. loss: 11.014481\n",
      "Total training time: 3.74 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 431.92, NNZs: 164, Bias: -20.000000, T: 748440, Avg. loss: 10.559213\n",
      "Total training time: 3.93 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 410.78, NNZs: 157, Bias: -15.000000, T: 784080, Avg. loss: 10.991803\n",
      "Total training time: 4.11 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 426.88, NNZs: 146, Bias: -15.000000, T: 819720, Avg. loss: 10.979138\n",
      "Total training time: 4.28 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 419.59, NNZs: 156, Bias: -15.000000, T: 855360, Avg. loss: 11.028853\n",
      "Total training time: 4.46 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 431.90, NNZs: 163, Bias: -15.000000, T: 891000, Avg. loss: 11.432093\n",
      "Total training time: 4.64 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 442.81, NNZs: 148, Bias: -15.000000, T: 926640, Avg. loss: 10.894671\n",
      "Total training time: 4.84 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 196.31, NNZs: 157, Bias: -7.000000, T: 962280, Avg. loss: 2.401766\n",
      "Total training time: 5.02 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 186.29, NNZs: 159, Bias: -7.000000, T: 997920, Avg. loss: 2.563428\n",
      "Total training time: 5.20 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 182.78, NNZs: 173, Bias: -9.000000, T: 1033560, Avg. loss: 2.616702\n",
      "Total training time: 5.38 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 178.70, NNZs: 185, Bias: -6.000000, T: 1069200, Avg. loss: 2.687923\n",
      "Total training time: 5.58 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 185.27, NNZs: 184, Bias: -8.000000, T: 1104840, Avg. loss: 2.750622\n",
      "Total training time: 5.75 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 183.47, NNZs: 180, Bias: -8.000000, T: 1140480, Avg. loss: 2.729787\n",
      "Total training time: 5.94 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 120.77, NNZs: 185, Bias: -5.000000, T: 1176120, Avg. loss: 0.948736\n",
      "Total training time: 6.13 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 96.97, NNZs: 199, Bias: -5.000000, T: 1211760, Avg. loss: 0.903501\n",
      "Total training time: 6.33 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 88.35, NNZs: 197, Bias: -4.400000, T: 1247400, Avg. loss: 0.918749\n",
      "Total training time: 6.53 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 85.67, NNZs: 195, Bias: -5.000000, T: 1283040, Avg. loss: 0.904208\n",
      "Total training time: 6.71 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 83.88, NNZs: 206, Bias: -4.800000, T: 1318680, Avg. loss: 0.933729\n",
      "Total training time: 6.90 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 83.64, NNZs: 199, Bias: -4.200000, T: 1354320, Avg. loss: 0.916518\n",
      "Total training time: 7.09 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 83.17, NNZs: 198, Bias: -4.400000, T: 1389960, Avg. loss: 0.916601\n",
      "Total training time: 7.27 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 74.95, NNZs: 208, Bias: -3.240000, T: 1425600, Avg. loss: 0.563994\n",
      "Total training time: 7.46 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 68.67, NNZs: 225, Bias: -2.960000, T: 1461240, Avg. loss: 0.546086\n",
      "Total training time: 7.64 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 63.17, NNZs: 213, Bias: -2.800000, T: 1496880, Avg. loss: 0.546541\n",
      "Total training time: 7.84 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 58.52, NNZs: 222, Bias: -2.760000, T: 1532520, Avg. loss: 0.550449\n",
      "Total training time: 8.04 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 54.71, NNZs: 216, Bias: -2.720000, T: 1568160, Avg. loss: 0.541747\n",
      "Total training time: 8.22 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 51.47, NNZs: 227, Bias: -2.720000, T: 1603800, Avg. loss: 0.546936\n",
      "Total training time: 8.41 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 48.69, NNZs: 227, Bias: -2.640000, T: 1639440, Avg. loss: 0.550387\n",
      "Total training time: 8.59 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 46.50, NNZs: 224, Bias: -2.640000, T: 1675080, Avg. loss: 0.544177\n",
      "Total training time: 8.77 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 44.67, NNZs: 220, Bias: -2.400000, T: 1710720, Avg. loss: 0.546764\n",
      "Total training time: 8.95 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 43.09, NNZs: 222, Bias: -2.440000, T: 1746360, Avg. loss: 0.550511\n",
      "Total training time: 9.14 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 42.05, NNZs: 231, Bias: -2.368000, T: 1782000, Avg. loss: 0.469102\n",
      "Total training time: 9.35 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 41.14, NNZs: 230, Bias: -2.272000, T: 1817640, Avg. loss: 0.463633\n",
      "Total training time: 9.55 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 40.29, NNZs: 232, Bias: -2.232000, T: 1853280, Avg. loss: 0.461952\n",
      "Total training time: 9.74 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 39.47, NNZs: 232, Bias: -2.144000, T: 1888920, Avg. loss: 0.462147\n",
      "Total training time: 9.92 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 38.70, NNZs: 232, Bias: -2.032000, T: 1924560, Avg. loss: 0.461829\n",
      "Total training time: 10.11 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 37.94, NNZs: 235, Bias: -2.072000, T: 1960200, Avg. loss: 0.462684\n",
      "Total training time: 10.30 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 37.20, NNZs: 234, Bias: -2.104000, T: 1995840, Avg. loss: 0.463043\n",
      "Total training time: 10.49 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 36.47, NNZs: 233, Bias: -2.096000, T: 2031480, Avg. loss: 0.462457\n",
      "Total training time: 10.67 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 36.29, NNZs: 233, Bias: -2.073600, T: 2067120, Avg. loss: 0.443917\n",
      "Total training time: 10.86 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 36.12, NNZs: 232, Bias: -2.059200, T: 2102760, Avg. loss: 0.442926\n",
      "Total training time: 11.05 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 35.95, NNZs: 232, Bias: -2.022400, T: 2138400, Avg. loss: 0.442044\n",
      "Total training time: 11.22 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 35.78, NNZs: 232, Bias: -2.033600, T: 2174040, Avg. loss: 0.442789\n",
      "Total training time: 11.40 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 35.62, NNZs: 232, Bias: -2.025600, T: 2209680, Avg. loss: 0.442239\n",
      "Total training time: 11.59 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 35.45, NNZs: 232, Bias: -2.025600, T: 2245320, Avg. loss: 0.442301\n",
      "Total training time: 11.76 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 35.42, NNZs: 233, Bias: -2.013760, T: 2280960, Avg. loss: 0.438472\n",
      "Total training time: 11.95 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 35.38, NNZs: 233, Bias: -2.018880, T: 2316600, Avg. loss: 0.438166\n",
      "Total training time: 12.14 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 35.35, NNZs: 233, Bias: -2.012480, T: 2352240, Avg. loss: 0.438036\n",
      "Total training time: 12.34 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 35.32, NNZs: 232, Bias: -2.019520, T: 2387880, Avg. loss: 0.437979\n",
      "Total training time: 12.52 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 35.28, NNZs: 232, Bias: -2.001920, T: 2423520, Avg. loss: 0.437925\n",
      "Total training time: 12.70 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 35.25, NNZs: 232, Bias: -2.006080, T: 2459160, Avg. loss: 0.438074\n",
      "Total training time: 12.90 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 70\n",
      "Norm: 35.24, NNZs: 233, Bias: -2.012096, T: 2494800, Avg. loss: 0.437180\n",
      "Total training time: 13.08 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 35.24, NNZs: 233, Bias: -2.010688, T: 2530440, Avg. loss: 0.437067\n",
      "Total training time: 13.26 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 35.23, NNZs: 233, Bias: -2.009728, T: 2566080, Avg. loss: 0.437037\n",
      "Total training time: 13.44 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 35.22, NNZs: 233, Bias: -2.011584, T: 2601720, Avg. loss: 0.436995\n",
      "Total training time: 13.63 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 35.21, NNZs: 233, Bias: -2.010304, T: 2637360, Avg. loss: 0.437023\n",
      "Total training time: 13.80 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 35.21, NNZs: 233, Bias: -2.009997, T: 2673000, Avg. loss: 0.436808\n",
      "Total training time: 13.99 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 35.21, NNZs: 233, Bias: -2.009779, T: 2708640, Avg. loss: 0.436803\n",
      "Total training time: 14.17 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 35.21, NNZs: 233, Bias: -2.010266, T: 2744280, Avg. loss: 0.436802\n",
      "Total training time: 14.35 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 35.21, NNZs: 233, Bias: -2.010419, T: 2779920, Avg. loss: 0.436797\n",
      "Total training time: 14.53 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 35.21, NNZs: 233, Bias: -2.009933, T: 2815560, Avg. loss: 0.436789\n",
      "Total training time: 14.71 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 35.21, NNZs: 233, Bias: -2.009999, T: 2851200, Avg. loss: 0.436739\n",
      "Total training time: 14.89 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 35.21, NNZs: 233, Bias: -2.010068, T: 2886840, Avg. loss: 0.436737\n",
      "Total training time: 15.08 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 35.21, NNZs: 233, Bias: -2.010112, T: 2922480, Avg. loss: 0.436737\n",
      "Total training time: 15.25 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 35.21, NNZs: 233, Bias: -2.010053, T: 2958120, Avg. loss: 0.436736\n",
      "Total training time: 15.43 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 35.21, NNZs: 233, Bias: -2.010022, T: 2993760, Avg. loss: 0.436736\n",
      "Total training time: 15.61 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 35.21, NNZs: 233, Bias: -2.010026, T: 3029400, Avg. loss: 0.436725\n",
      "Total training time: 15.79 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 35.21, NNZs: 233, Bias: -2.010034, T: 3065040, Avg. loss: 0.436724\n",
      "Total training time: 15.97 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 35.21, NNZs: 233, Bias: -2.010043, T: 3100680, Avg. loss: 0.436724\n",
      "Total training time: 16.16 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 35.21, NNZs: 233, Bias: -2.010050, T: 3136320, Avg. loss: 0.436724\n",
      "Total training time: 16.35 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 35.21, NNZs: 233, Bias: -2.010056, T: 3171960, Avg. loss: 0.436724\n",
      "Total training time: 16.54 seconds.\n",
      "Convergence after 89 epochs took 16.54 seconds\n",
      "-- Epoch 1\n",
      "Norm: 185.59, NNZs: 277, Bias: -75.000000, T: 35640, Avg. loss: 8.518153\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 215.03, NNZs: 220, Bias: -80.000000, T: 71280, Avg. loss: 7.278545\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 247.34, NNZs: 212, Bias: -80.000000, T: 106920, Avg. loss: 6.622600\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 240.52, NNZs: 190, Bias: -80.000000, T: 142560, Avg. loss: 5.949530\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 262.68, NNZs: 180, Bias: -65.000000, T: 178200, Avg. loss: 5.605820\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 257.86, NNZs: 149, Bias: -60.000000, T: 213840, Avg. loss: 5.101947\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 275.47, NNZs: 169, Bias: -60.000000, T: 249480, Avg. loss: 4.773286\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 289.96, NNZs: 131, Bias: -55.000000, T: 285120, Avg. loss: 4.481461\n",
      "Total training time: 1.44 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 301.50, NNZs: 140, Bias: -40.000000, T: 320760, Avg. loss: 4.268051\n",
      "Total training time: 1.62 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 270.23, NNZs: 147, Bias: -55.000000, T: 356400, Avg. loss: 4.131252\n",
      "Total training time: 1.80 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 267.65, NNZs: 154, Bias: -30.000000, T: 392040, Avg. loss: 4.047637\n",
      "Total training time: 1.98 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 287.85, NNZs: 160, Bias: -55.000000, T: 427680, Avg. loss: 4.214297\n",
      "Total training time: 2.15 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 272.45, NNZs: 148, Bias: -40.000000, T: 463320, Avg. loss: 4.053972\n",
      "Total training time: 2.33 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 269.00, NNZs: 171, Bias: -50.000000, T: 498960, Avg. loss: 3.820492\n",
      "Total training time: 2.50 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 298.82, NNZs: 174, Bias: -45.000000, T: 534600, Avg. loss: 3.711427\n",
      "Total training time: 2.67 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 295.51, NNZs: 157, Bias: -40.000000, T: 570240, Avg. loss: 3.712167\n",
      "Total training time: 2.84 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 283.07, NNZs: 151, Bias: -30.000000, T: 605880, Avg. loss: 3.667238\n",
      "Total training time: 3.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 300.62, NNZs: 147, Bias: -40.000000, T: 641520, Avg. loss: 3.458546\n",
      "Total training time: 3.17 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 295.93, NNZs: 144, Bias: -40.000000, T: 677160, Avg. loss: 3.536863\n",
      "Total training time: 3.36 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 305.04, NNZs: 145, Bias: -45.000000, T: 712800, Avg. loss: 3.546484\n",
      "Total training time: 3.53 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 296.97, NNZs: 143, Bias: -30.000000, T: 748440, Avg. loss: 3.470513\n",
      "Total training time: 3.70 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 279.15, NNZs: 137, Bias: -30.000000, T: 784080, Avg. loss: 3.560331\n",
      "Total training time: 3.87 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 309.97, NNZs: 137, Bias: -45.000000, T: 819720, Avg. loss: 3.643308\n",
      "Total training time: 4.04 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 136.47, NNZs: 131, Bias: -12.000000, T: 855360, Avg. loss: 0.775908\n",
      "Total training time: 4.20 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 134.19, NNZs: 150, Bias: -13.000000, T: 891000, Avg. loss: 0.751458\n",
      "Total training time: 4.36 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 132.60, NNZs: 160, Bias: -11.000000, T: 926640, Avg. loss: 0.787706\n",
      "Total training time: 4.54 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 129.28, NNZs: 162, Bias: -10.000000, T: 962280, Avg. loss: 0.838826\n",
      "Total training time: 4.70 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 130.02, NNZs: 169, Bias: -10.000000, T: 997920, Avg. loss: 0.838798\n",
      "Total training time: 4.88 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 128.82, NNZs: 149, Bias: -12.000000, T: 1033560, Avg. loss: 0.875014\n",
      "Total training time: 5.06 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 129.71, NNZs: 171, Bias: -11.000000, T: 1069200, Avg. loss: 0.922633\n",
      "Total training time: 5.23 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 86.76, NNZs: 170, Bias: -5.200000, T: 1104840, Avg. loss: 0.315861\n",
      "Total training time: 5.41 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 69.90, NNZs: 168, Bias: -4.400000, T: 1140480, Avg. loss: 0.298953\n",
      "Total training time: 5.59 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 63.10, NNZs: 187, Bias: -4.800000, T: 1176120, Avg. loss: 0.301784\n",
      "Total training time: 5.76 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 59.84, NNZs: 187, Bias: -4.600000, T: 1211760, Avg. loss: 0.308969\n",
      "Total training time: 5.94 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 59.02, NNZs: 178, Bias: -4.200000, T: 1247400, Avg. loss: 0.315122\n",
      "Total training time: 6.12 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 59.25, NNZs: 180, Bias: -4.200000, T: 1283040, Avg. loss: 0.308755\n",
      "Total training time: 6.30 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 59.07, NNZs: 192, Bias: -3.600000, T: 1318680, Avg. loss: 0.311964\n",
      "Total training time: 6.48 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 53.47, NNZs: 186, Bias: -2.720000, T: 1354320, Avg. loss: 0.196448\n",
      "Total training time: 6.65 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 49.04, NNZs: 184, Bias: -2.320000, T: 1389960, Avg. loss: 0.182272\n",
      "Total training time: 6.82 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 45.32, NNZs: 186, Bias: -2.120000, T: 1425600, Avg. loss: 0.182412\n",
      "Total training time: 7.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 42.19, NNZs: 188, Bias: -2.080000, T: 1461240, Avg. loss: 0.181963\n",
      "Total training time: 7.17 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 39.42, NNZs: 192, Bias: -1.920000, T: 1496880, Avg. loss: 0.183859\n",
      "Total training time: 7.35 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 37.10, NNZs: 193, Bias: -2.040000, T: 1532520, Avg. loss: 0.184136\n",
      "Total training time: 7.53 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 35.26, NNZs: 192, Bias: -2.040000, T: 1568160, Avg. loss: 0.183460\n",
      "Total training time: 7.69 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 34.47, NNZs: 192, Bias: -1.696000, T: 1603800, Avg. loss: 0.159915\n",
      "Total training time: 7.87 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 33.72, NNZs: 193, Bias: -1.552000, T: 1639440, Avg. loss: 0.156515\n",
      "Total training time: 8.05 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 33.01, NNZs: 194, Bias: -1.456000, T: 1675080, Avg. loss: 0.155178\n",
      "Total training time: 8.22 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 32.33, NNZs: 190, Bias: -1.352000, T: 1710720, Avg. loss: 0.154399\n",
      "Total training time: 8.40 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 31.66, NNZs: 181, Bias: -1.384000, T: 1746360, Avg. loss: 0.153536\n",
      "Total training time: 8.58 seconds.\n",
      "-- Epoch 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 31.03, NNZs: 189, Bias: -1.264000, T: 1782000, Avg. loss: 0.153066\n",
      "Total training time: 8.76 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 30.41, NNZs: 186, Bias: -1.280000, T: 1817640, Avg. loss: 0.152590\n",
      "Total training time: 8.93 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 29.81, NNZs: 188, Bias: -1.240000, T: 1853280, Avg. loss: 0.152236\n",
      "Total training time: 9.11 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 29.67, NNZs: 189, Bias: -1.168000, T: 1888920, Avg. loss: 0.148185\n",
      "Total training time: 9.30 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 29.53, NNZs: 190, Bias: -1.142400, T: 1924560, Avg. loss: 0.147524\n",
      "Total training time: 9.49 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 29.39, NNZs: 187, Bias: -1.118400, T: 1960200, Avg. loss: 0.147320\n",
      "Total training time: 9.66 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 29.26, NNZs: 182, Bias: -1.092800, T: 1995840, Avg. loss: 0.146994\n",
      "Total training time: 9.83 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 29.12, NNZs: 184, Bias: -1.078400, T: 2031480, Avg. loss: 0.146762\n",
      "Total training time: 10.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 28.99, NNZs: 185, Bias: -1.067200, T: 2067120, Avg. loss: 0.146644\n",
      "Total training time: 10.19 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 28.96, NNZs: 187, Bias: -1.052480, T: 2102760, Avg. loss: 0.145705\n",
      "Total training time: 10.36 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 28.93, NNZs: 187, Bias: -1.046080, T: 2138400, Avg. loss: 0.145581\n",
      "Total training time: 10.54 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 28.90, NNZs: 187, Bias: -1.039040, T: 2174040, Avg. loss: 0.145515\n",
      "Total training time: 10.71 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 28.88, NNZs: 184, Bias: -1.032000, T: 2209680, Avg. loss: 0.145439\n",
      "Total training time: 10.89 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 28.85, NNZs: 184, Bias: -1.026560, T: 2245320, Avg. loss: 0.145387\n",
      "Total training time: 11.06 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 28.84, NNZs: 184, Bias: -1.024960, T: 2280960, Avg. loss: 0.145191\n",
      "Total training time: 11.23 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 28.84, NNZs: 185, Bias: -1.023232, T: 2316600, Avg. loss: 0.145173\n",
      "Total training time: 11.41 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 28.83, NNZs: 182, Bias: -1.021568, T: 2352240, Avg. loss: 0.145150\n",
      "Total training time: 11.59 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 28.83, NNZs: 183, Bias: -1.019776, T: 2387880, Avg. loss: 0.145129\n",
      "Total training time: 11.76 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 28.82, NNZs: 183, Bias: -1.018752, T: 2423520, Avg. loss: 0.145118\n",
      "Total training time: 11.94 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 28.82, NNZs: 184, Bias: -1.018035, T: 2459160, Avg. loss: 0.145079\n",
      "Total training time: 12.11 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 28.82, NNZs: 185, Bias: -1.017715, T: 2494800, Avg. loss: 0.145072\n",
      "Total training time: 12.30 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 28.82, NNZs: 183, Bias: -1.017318, T: 2530440, Avg. loss: 0.145069\n",
      "Total training time: 12.48 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 28.82, NNZs: 184, Bias: -1.017062, T: 2566080, Avg. loss: 0.145063\n",
      "Total training time: 12.66 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 28.81, NNZs: 185, Bias: -1.016563, T: 2601720, Avg. loss: 0.145060\n",
      "Total training time: 12.84 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 28.81, NNZs: 185, Bias: -1.016494, T: 2637360, Avg. loss: 0.145052\n",
      "Total training time: 13.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 28.81, NNZs: 185, Bias: -1.016394, T: 2673000, Avg. loss: 0.145050\n",
      "Total training time: 13.20 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 28.81, NNZs: 185, Bias: -1.016323, T: 2708640, Avg. loss: 0.145049\n",
      "Total training time: 13.37 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 28.81, NNZs: 185, Bias: -1.016189, T: 2744280, Avg. loss: 0.145049\n",
      "Total training time: 13.56 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 28.81, NNZs: 185, Bias: -1.016159, T: 2779920, Avg. loss: 0.145048\n",
      "Total training time: 13.73 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 28.81, NNZs: 185, Bias: -1.016129, T: 2815560, Avg. loss: 0.145045\n",
      "Total training time: 13.91 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 28.81, NNZs: 185, Bias: -1.016132, T: 2851200, Avg. loss: 0.145045\n",
      "Total training time: 14.09 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 28.81, NNZs: 185, Bias: -1.016103, T: 2886840, Avg. loss: 0.145045\n",
      "Total training time: 14.26 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 28.81, NNZs: 185, Bias: -1.016083, T: 2922480, Avg. loss: 0.145045\n",
      "Total training time: 14.44 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 28.81, NNZs: 185, Bias: -1.016065, T: 2958120, Avg. loss: 0.145045\n",
      "Total training time: 14.62 seconds.\n",
      "Convergence after 83 epochs took 14.62 seconds\n",
      "-- Epoch 1\n",
      "Norm: 281.33, NNZs: 308, Bias: 15.000000, T: 35640, Avg. loss: 24.763314\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 325.22, NNZs: 263, Bias: 5.000000, T: 71280, Avg. loss: 22.889694\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 346.94, NNZs: 223, Bias: 25.000000, T: 106920, Avg. loss: 20.207038\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 375.12, NNZs: 214, Bias: -5.000000, T: 142560, Avg. loss: 18.812956\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 376.17, NNZs: 195, Bias: 15.000000, T: 178200, Avg. loss: 17.768410\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 394.02, NNZs: 193, Bias: 15.000000, T: 213840, Avg. loss: 16.747397\n",
      "Total training time: 1.16 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 419.10, NNZs: 195, Bias: 10.000000, T: 249480, Avg. loss: 15.312003\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 435.75, NNZs: 161, Bias: 10.000000, T: 285120, Avg. loss: 14.565744\n",
      "Total training time: 1.53 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 421.99, NNZs: 174, Bias: 10.000000, T: 320760, Avg. loss: 14.303439\n",
      "Total training time: 1.72 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 443.20, NNZs: 173, Bias: 0.000000, T: 356400, Avg. loss: 13.871962\n",
      "Total training time: 1.91 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 426.84, NNZs: 175, Bias: 0.000000, T: 392040, Avg. loss: 13.444468\n",
      "Total training time: 2.08 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 433.86, NNZs: 149, Bias: -10.000000, T: 427680, Avg. loss: 13.305324\n",
      "Total training time: 2.27 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 462.27, NNZs: 145, Bias: 0.000000, T: 463320, Avg. loss: 13.029337\n",
      "Total training time: 2.45 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 479.32, NNZs: 163, Bias: 5.000000, T: 498960, Avg. loss: 12.549338\n",
      "Total training time: 2.62 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 474.15, NNZs: 147, Bias: 0.000000, T: 534600, Avg. loss: 12.119177\n",
      "Total training time: 2.81 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 465.94, NNZs: 137, Bias: 5.000000, T: 570240, Avg. loss: 12.483860\n",
      "Total training time: 2.99 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 456.24, NNZs: 151, Bias: 20.000000, T: 605880, Avg. loss: 11.861337\n",
      "Total training time: 3.18 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 463.72, NNZs: 150, Bias: 0.000000, T: 641520, Avg. loss: 11.809430\n",
      "Total training time: 3.36 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 466.38, NNZs: 167, Bias: 10.000000, T: 677160, Avg. loss: 11.925298\n",
      "Total training time: 3.54 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 468.57, NNZs: 152, Bias: 0.000000, T: 712800, Avg. loss: 12.165540\n",
      "Total training time: 3.72 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 449.91, NNZs: 132, Bias: 5.000000, T: 748440, Avg. loss: 11.280724\n",
      "Total training time: 3.92 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 452.09, NNZs: 156, Bias: 10.000000, T: 784080, Avg. loss: 11.599235\n",
      "Total training time: 4.09 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 518.67, NNZs: 150, Bias: 0.000000, T: 819720, Avg. loss: 11.465410\n",
      "Total training time: 4.27 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 462.95, NNZs: 156, Bias: 25.000000, T: 855360, Avg. loss: 10.683638\n",
      "Total training time: 4.45 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 459.78, NNZs: 133, Bias: -5.000000, T: 891000, Avg. loss: 11.428537\n",
      "Total training time: 4.62 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 499.52, NNZs: 134, Bias: 5.000000, T: 926640, Avg. loss: 11.134248\n",
      "Total training time: 4.80 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 454.14, NNZs: 142, Bias: -5.000000, T: 962280, Avg. loss: 10.905362\n",
      "Total training time: 4.98 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 479.00, NNZs: 129, Bias: 10.000000, T: 997920, Avg. loss: 11.378297\n",
      "Total training time: 5.16 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 461.66, NNZs: 148, Bias: 20.000000, T: 1033560, Avg. loss: 11.243244\n",
      "Total training time: 5.34 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 223.09, NNZs: 130, Bias: 2.000000, T: 1069200, Avg. loss: 2.442361\n",
      "Total training time: 5.51 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 215.70, NNZs: 144, Bias: 5.000000, T: 1104840, Avg. loss: 2.421055\n",
      "Total training time: 5.69 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 212.65, NNZs: 147, Bias: 0.000000, T: 1140480, Avg. loss: 2.588898\n",
      "Total training time: 5.87 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 209.33, NNZs: 156, Bias: 2.000000, T: 1176120, Avg. loss: 2.532046\n",
      "Total training time: 6.04 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 213.42, NNZs: 164, Bias: 2.000000, T: 1211760, Avg. loss: 2.668671\n",
      "Total training time: 6.23 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 203.28, NNZs: 163, Bias: 5.000000, T: 1247400, Avg. loss: 2.699402\n",
      "Total training time: 6.41 seconds.\n",
      "-- Epoch 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 209.10, NNZs: 171, Bias: 5.000000, T: 1283040, Avg. loss: 2.806845\n",
      "Total training time: 6.59 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 139.66, NNZs: 172, Bias: 1.600000, T: 1318680, Avg. loss: 1.006406\n",
      "Total training time: 6.77 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 111.75, NNZs: 175, Bias: 2.600000, T: 1354320, Avg. loss: 0.961126\n",
      "Total training time: 6.95 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 101.67, NNZs: 193, Bias: 1.800000, T: 1389960, Avg. loss: 0.993881\n",
      "Total training time: 7.13 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 98.25, NNZs: 187, Bias: 1.800000, T: 1425600, Avg. loss: 0.985294\n",
      "Total training time: 7.31 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 96.29, NNZs: 197, Bias: 1.800000, T: 1461240, Avg. loss: 0.984454\n",
      "Total training time: 7.50 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 95.96, NNZs: 186, Bias: 1.600000, T: 1496880, Avg. loss: 0.989516\n",
      "Total training time: 7.68 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 94.70, NNZs: 196, Bias: 1.200000, T: 1532520, Avg. loss: 1.020163\n",
      "Total training time: 7.87 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 85.64, NNZs: 196, Bias: 1.320000, T: 1568160, Avg. loss: 0.646641\n",
      "Total training time: 8.05 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 78.43, NNZs: 205, Bias: 0.920000, T: 1603800, Avg. loss: 0.635329\n",
      "Total training time: 8.23 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 72.33, NNZs: 204, Bias: 1.040000, T: 1639440, Avg. loss: 0.635292\n",
      "Total training time: 8.42 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 67.16, NNZs: 204, Bias: 0.960000, T: 1675080, Avg. loss: 0.630562\n",
      "Total training time: 8.59 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 62.81, NNZs: 210, Bias: 1.000000, T: 1710720, Avg. loss: 0.634101\n",
      "Total training time: 8.78 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 59.10, NNZs: 212, Bias: 1.200000, T: 1746360, Avg. loss: 0.631830\n",
      "Total training time: 8.97 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 56.00, NNZs: 211, Bias: 1.000000, T: 1782000, Avg. loss: 0.635088\n",
      "Total training time: 9.17 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 53.49, NNZs: 212, Bias: 1.080000, T: 1817640, Avg. loss: 0.635147\n",
      "Total training time: 9.36 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 51.30, NNZs: 216, Bias: 1.000000, T: 1853280, Avg. loss: 0.635743\n",
      "Total training time: 9.55 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 50.15, NNZs: 220, Bias: 0.864000, T: 1888920, Avg. loss: 0.552793\n",
      "Total training time: 9.74 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 49.10, NNZs: 216, Bias: 0.808000, T: 1924560, Avg. loss: 0.549985\n",
      "Total training time: 9.93 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 48.08, NNZs: 220, Bias: 0.704000, T: 1960200, Avg. loss: 0.547276\n",
      "Total training time: 10.12 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 47.09, NNZs: 222, Bias: 0.688000, T: 1995840, Avg. loss: 0.548691\n",
      "Total training time: 10.32 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 46.14, NNZs: 224, Bias: 0.672000, T: 2031480, Avg. loss: 0.549283\n",
      "Total training time: 10.51 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 45.22, NNZs: 223, Bias: 0.752000, T: 2067120, Avg. loss: 0.548111\n",
      "Total training time: 10.70 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 44.34, NNZs: 224, Bias: 0.728000, T: 2102760, Avg. loss: 0.548153\n",
      "Total training time: 10.89 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 43.46, NNZs: 223, Bias: 0.680000, T: 2138400, Avg. loss: 0.549411\n",
      "Total training time: 11.08 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 43.24, NNZs: 225, Bias: 0.737600, T: 2174040, Avg. loss: 0.528842\n",
      "Total training time: 11.27 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 43.04, NNZs: 226, Bias: 0.718400, T: 2209680, Avg. loss: 0.527378\n",
      "Total training time: 11.47 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 42.84, NNZs: 227, Bias: 0.729600, T: 2245320, Avg. loss: 0.526810\n",
      "Total training time: 11.66 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 42.64, NNZs: 225, Bias: 0.705600, T: 2280960, Avg. loss: 0.526484\n",
      "Total training time: 11.85 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 42.44, NNZs: 226, Bias: 0.713600, T: 2316600, Avg. loss: 0.526703\n",
      "Total training time: 12.04 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 42.25, NNZs: 227, Bias: 0.683200, T: 2352240, Avg. loss: 0.526734\n",
      "Total training time: 12.23 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 42.05, NNZs: 227, Bias: 0.681600, T: 2387880, Avg. loss: 0.526683\n",
      "Total training time: 12.42 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 42.01, NNZs: 226, Bias: 0.690880, T: 2423520, Avg. loss: 0.522493\n",
      "Total training time: 12.61 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 41.97, NNZs: 226, Bias: 0.687680, T: 2459160, Avg. loss: 0.522201\n",
      "Total training time: 12.80 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 41.93, NNZs: 226, Bias: 0.680000, T: 2494800, Avg. loss: 0.522052\n",
      "Total training time: 12.99 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 41.89, NNZs: 226, Bias: 0.680640, T: 2530440, Avg. loss: 0.521892\n",
      "Total training time: 13.18 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 41.85, NNZs: 226, Bias: 0.675840, T: 2566080, Avg. loss: 0.521876\n",
      "Total training time: 13.37 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 41.81, NNZs: 226, Bias: 0.666560, T: 2601720, Avg. loss: 0.521770\n",
      "Total training time: 13.55 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 41.81, NNZs: 226, Bias: 0.676032, T: 2637360, Avg. loss: 0.520966\n",
      "Total training time: 13.75 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 41.80, NNZs: 226, Bias: 0.674368, T: 2673000, Avg. loss: 0.520861\n",
      "Total training time: 13.94 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 41.79, NNZs: 226, Bias: 0.675584, T: 2708640, Avg. loss: 0.520807\n",
      "Total training time: 14.13 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 41.78, NNZs: 226, Bias: 0.673984, T: 2744280, Avg. loss: 0.520810\n",
      "Total training time: 14.32 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 41.77, NNZs: 226, Bias: 0.674944, T: 2779920, Avg. loss: 0.520810\n",
      "Total training time: 14.51 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 41.77, NNZs: 226, Bias: 0.673907, T: 2815560, Avg. loss: 0.520537\n",
      "Total training time: 14.70 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 41.77, NNZs: 226, Bias: 0.673203, T: 2851200, Avg. loss: 0.520525\n",
      "Total training time: 14.90 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 41.77, NNZs: 226, Bias: 0.673651, T: 2886840, Avg. loss: 0.520528\n",
      "Total training time: 15.09 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 41.77, NNZs: 226, Bias: 0.673677, T: 2922480, Avg. loss: 0.520527\n",
      "Total training time: 15.28 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 41.77, NNZs: 226, Bias: 0.673702, T: 2958120, Avg. loss: 0.520525\n",
      "Total training time: 15.47 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 41.77, NNZs: 226, Bias: 0.673546, T: 2993760, Avg. loss: 0.520465\n",
      "Total training time: 15.69 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 41.77, NNZs: 226, Bias: 0.673513, T: 3029400, Avg. loss: 0.520465\n",
      "Total training time: 15.88 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 41.76, NNZs: 226, Bias: 0.673505, T: 3065040, Avg. loss: 0.520464\n",
      "Total training time: 16.07 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 41.76, NNZs: 226, Bias: 0.673449, T: 3100680, Avg. loss: 0.520464\n",
      "Total training time: 16.26 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 41.76, NNZs: 226, Bias: 0.673454, T: 3136320, Avg. loss: 0.520463\n",
      "Total training time: 16.45 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 41.76, NNZs: 226, Bias: 0.673437, T: 3171960, Avg. loss: 0.520450\n",
      "Total training time: 16.63 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 41.76, NNZs: 226, Bias: 0.673420, T: 3207600, Avg. loss: 0.520450\n",
      "Total training time: 16.83 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 41.76, NNZs: 226, Bias: 0.673406, T: 3243240, Avg. loss: 0.520450\n",
      "Total training time: 17.01 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 41.76, NNZs: 226, Bias: 0.673390, T: 3278880, Avg. loss: 0.520450\n",
      "Total training time: 17.22 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 41.76, NNZs: 226, Bias: 0.673382, T: 3314520, Avg. loss: 0.520450\n",
      "Total training time: 17.42 seconds.\n",
      "Convergence after 93 epochs took 17.42 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   48.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 279.08, NNZs: 285, Bias: -30.000000, T: 35640, Avg. loss: 21.941759\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 316.56, NNZs: 257, Bias: -30.000000, T: 71280, Avg. loss: 19.763837\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 332.16, NNZs: 222, Bias: -20.000000, T: 106920, Avg. loss: 17.854760\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 341.39, NNZs: 203, Bias: -30.000000, T: 142560, Avg. loss: 16.998311\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 375.74, NNZs: 208, Bias: -20.000000, T: 178200, Avg. loss: 15.104413\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 378.17, NNZs: 190, Bias: -35.000000, T: 213840, Avg. loss: 14.877089\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 390.50, NNZs: 179, Bias: -10.000000, T: 249480, Avg. loss: 14.077258\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 416.47, NNZs: 166, Bias: -20.000000, T: 285120, Avg. loss: 13.349843\n",
      "Total training time: 1.53 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 403.86, NNZs: 156, Bias: -20.000000, T: 320760, Avg. loss: 12.891834\n",
      "Total training time: 1.72 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 409.61, NNZs: 170, Bias: -15.000000, T: 356400, Avg. loss: 12.525896\n",
      "Total training time: 1.90 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 434.42, NNZs: 162, Bias: -20.000000, T: 392040, Avg. loss: 12.673711\n",
      "Total training time: 2.09 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 417.61, NNZs: 162, Bias: -25.000000, T: 427680, Avg. loss: 12.394622\n",
      "Total training time: 2.28 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 417.39, NNZs: 157, Bias: -10.000000, T: 463320, Avg. loss: 12.015472\n",
      "Total training time: 2.46 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 428.75, NNZs: 154, Bias: -20.000000, T: 498960, Avg. loss: 11.413983\n",
      "Total training time: 2.64 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 431.93, NNZs: 167, Bias: -20.000000, T: 534600, Avg. loss: 11.417388\n",
      "Total training time: 2.83 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 451.68, NNZs: 151, Bias: 0.000000, T: 570240, Avg. loss: 11.517313\n",
      "Total training time: 3.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 427.04, NNZs: 143, Bias: -25.000000, T: 605880, Avg. loss: 10.978942\n",
      "Total training time: 3.19 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 420.90, NNZs: 147, Bias: -25.000000, T: 641520, Avg. loss: 11.053020\n",
      "Total training time: 3.37 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 416.72, NNZs: 157, Bias: -30.000000, T: 677160, Avg. loss: 11.054712\n",
      "Total training time: 3.56 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 427.72, NNZs: 148, Bias: -30.000000, T: 712800, Avg. loss: 11.261328\n",
      "Total training time: 3.75 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 432.90, NNZs: 153, Bias: -20.000000, T: 748440, Avg. loss: 10.806438\n",
      "Total training time: 3.92 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 408.62, NNZs: 152, Bias: -25.000000, T: 784080, Avg. loss: 10.260028\n",
      "Total training time: 4.11 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 429.30, NNZs: 145, Bias: -10.000000, T: 819720, Avg. loss: 10.801936\n",
      "Total training time: 4.30 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 423.65, NNZs: 154, Bias: -20.000000, T: 855360, Avg. loss: 10.703834\n",
      "Total training time: 4.47 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 435.30, NNZs: 157, Bias: -15.000000, T: 891000, Avg. loss: 10.855674\n",
      "Total training time: 4.65 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 439.45, NNZs: 130, Bias: -20.000000, T: 926640, Avg. loss: 10.878281\n",
      "Total training time: 4.83 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 456.86, NNZs: 144, Bias: -10.000000, T: 962280, Avg. loss: 10.777262\n",
      "Total training time: 5.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 190.08, NNZs: 151, Bias: -6.000000, T: 997920, Avg. loss: 2.513971\n",
      "Total training time: 5.18 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 188.28, NNZs: 170, Bias: -9.000000, T: 1033560, Avg. loss: 2.498973\n",
      "Total training time: 5.37 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 189.94, NNZs: 176, Bias: -10.000000, T: 1069200, Avg. loss: 2.569440\n",
      "Total training time: 5.55 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 187.21, NNZs: 182, Bias: -9.000000, T: 1104840, Avg. loss: 2.657867\n",
      "Total training time: 5.74 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 186.00, NNZs: 168, Bias: -7.000000, T: 1140480, Avg. loss: 2.664833\n",
      "Total training time: 5.92 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 187.15, NNZs: 170, Bias: -9.000000, T: 1176120, Avg. loss: 2.656847\n",
      "Total training time: 6.11 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 180.56, NNZs: 185, Bias: -10.000000, T: 1211760, Avg. loss: 2.775802\n",
      "Total training time: 6.30 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 119.56, NNZs: 190, Bias: -4.200000, T: 1247400, Avg. loss: 0.952299\n",
      "Total training time: 6.49 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 96.24, NNZs: 195, Bias: -4.200000, T: 1283040, Avg. loss: 0.891874\n",
      "Total training time: 6.69 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 86.88, NNZs: 204, Bias: -3.800000, T: 1318680, Avg. loss: 0.912194\n",
      "Total training time: 6.88 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 83.21, NNZs: 192, Bias: -3.800000, T: 1354320, Avg. loss: 0.926910\n",
      "Total training time: 7.07 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 82.21, NNZs: 212, Bias: -3.800000, T: 1389960, Avg. loss: 0.930115\n",
      "Total training time: 7.27 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 82.01, NNZs: 196, Bias: -3.200000, T: 1425600, Avg. loss: 0.927203\n",
      "Total training time: 7.47 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 81.79, NNZs: 193, Bias: -3.800000, T: 1461240, Avg. loss: 0.931797\n",
      "Total training time: 7.67 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 74.06, NNZs: 218, Bias: -2.800000, T: 1496880, Avg. loss: 0.555619\n",
      "Total training time: 7.86 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 67.64, NNZs: 220, Bias: -2.440000, T: 1532520, Avg. loss: 0.546574\n",
      "Total training time: 8.07 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 62.20, NNZs: 223, Bias: -2.200000, T: 1568160, Avg. loss: 0.550283\n",
      "Total training time: 8.26 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 57.54, NNZs: 225, Bias: -2.120000, T: 1603800, Avg. loss: 0.549353\n",
      "Total training time: 8.45 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 53.72, NNZs: 226, Bias: -2.080000, T: 1639440, Avg. loss: 0.547141\n",
      "Total training time: 8.65 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 50.27, NNZs: 223, Bias: -2.240000, T: 1675080, Avg. loss: 0.548697\n",
      "Total training time: 8.86 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 47.52, NNZs: 223, Bias: -2.280000, T: 1710720, Avg. loss: 0.549491\n",
      "Total training time: 9.06 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 46.35, NNZs: 228, Bias: -2.160000, T: 1746360, Avg. loss: 0.468091\n",
      "Total training time: 9.27 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 45.32, NNZs: 229, Bias: -2.064000, T: 1782000, Avg. loss: 0.461276\n",
      "Total training time: 9.46 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 44.36, NNZs: 230, Bias: -1.992000, T: 1817640, Avg. loss: 0.460155\n",
      "Total training time: 9.66 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 43.40, NNZs: 230, Bias: -1.944000, T: 1853280, Avg. loss: 0.460513\n",
      "Total training time: 9.85 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 42.49, NNZs: 235, Bias: -1.880000, T: 1888920, Avg. loss: 0.459686\n",
      "Total training time: 10.07 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 41.60, NNZs: 236, Bias: -1.808000, T: 1924560, Avg. loss: 0.459108\n",
      "Total training time: 10.27 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 40.76, NNZs: 233, Bias: -1.864000, T: 1960200, Avg. loss: 0.459161\n",
      "Total training time: 10.46 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 39.91, NNZs: 232, Bias: -1.832000, T: 1995840, Avg. loss: 0.459366\n",
      "Total training time: 10.65 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 39.72, NNZs: 234, Bias: -1.803200, T: 2031480, Avg. loss: 0.439965\n",
      "Total training time: 10.84 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 39.53, NNZs: 233, Bias: -1.800000, T: 2067120, Avg. loss: 0.438544\n",
      "Total training time: 11.04 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 39.34, NNZs: 234, Bias: -1.771200, T: 2102760, Avg. loss: 0.438592\n",
      "Total training time: 11.23 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 39.15, NNZs: 232, Bias: -1.760000, T: 2138400, Avg. loss: 0.438367\n",
      "Total training time: 11.43 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 38.97, NNZs: 232, Bias: -1.771200, T: 2174040, Avg. loss: 0.438466\n",
      "Total training time: 11.63 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 38.79, NNZs: 229, Bias: -1.764800, T: 2209680, Avg. loss: 0.438002\n",
      "Total training time: 11.82 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 38.61, NNZs: 230, Bias: -1.745600, T: 2245320, Avg. loss: 0.437989\n",
      "Total training time: 12.02 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 38.57, NNZs: 229, Bias: -1.748480, T: 2280960, Avg. loss: 0.434151\n",
      "Total training time: 12.21 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 38.53, NNZs: 229, Bias: -1.749120, T: 2316600, Avg. loss: 0.433828\n",
      "Total training time: 12.41 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 38.49, NNZs: 229, Bias: -1.742400, T: 2352240, Avg. loss: 0.433834\n",
      "Total training time: 12.60 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 38.46, NNZs: 230, Bias: -1.734720, T: 2387880, Avg. loss: 0.433670\n",
      "Total training time: 12.80 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 38.42, NNZs: 228, Bias: -1.744000, T: 2423520, Avg. loss: 0.433647\n",
      "Total training time: 12.99 seconds.\n",
      "-- Epoch 69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 38.38, NNZs: 229, Bias: -1.732160, T: 2459160, Avg. loss: 0.433577\n",
      "Total training time: 13.19 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 38.38, NNZs: 229, Bias: -1.738112, T: 2494800, Avg. loss: 0.432863\n",
      "Total training time: 13.38 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 38.37, NNZs: 229, Bias: -1.735552, T: 2530440, Avg. loss: 0.432717\n",
      "Total training time: 13.57 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 38.36, NNZs: 229, Bias: -1.735552, T: 2566080, Avg. loss: 0.432718\n",
      "Total training time: 13.77 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 38.35, NNZs: 229, Bias: -1.736896, T: 2601720, Avg. loss: 0.432678\n",
      "Total training time: 13.95 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 38.35, NNZs: 229, Bias: -1.737152, T: 2637360, Avg. loss: 0.432666\n",
      "Total training time: 14.15 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 38.35, NNZs: 229, Bias: -1.736269, T: 2673000, Avg. loss: 0.432456\n",
      "Total training time: 14.34 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 38.34, NNZs: 229, Bias: -1.735462, T: 2708640, Avg. loss: 0.432441\n",
      "Total training time: 14.52 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 38.34, NNZs: 229, Bias: -1.736128, T: 2744280, Avg. loss: 0.432441\n",
      "Total training time: 14.70 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 38.34, NNZs: 229, Bias: -1.735808, T: 2779920, Avg. loss: 0.432441\n",
      "Total training time: 14.88 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 38.34, NNZs: 229, Bias: -1.735206, T: 2815560, Avg. loss: 0.432430\n",
      "Total training time: 15.07 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 38.34, NNZs: 229, Bias: -1.735434, T: 2851200, Avg. loss: 0.432390\n",
      "Total training time: 15.25 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 38.34, NNZs: 229, Bias: -1.735642, T: 2886840, Avg. loss: 0.432384\n",
      "Total training time: 15.43 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 38.34, NNZs: 229, Bias: -1.735757, T: 2922480, Avg. loss: 0.432381\n",
      "Total training time: 15.61 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 38.34, NNZs: 229, Bias: -1.735795, T: 2958120, Avg. loss: 0.432380\n",
      "Total training time: 15.80 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 38.34, NNZs: 229, Bias: -1.735795, T: 2993760, Avg. loss: 0.432380\n",
      "Total training time: 15.97 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 38.34, NNZs: 229, Bias: -1.735799, T: 3029400, Avg. loss: 0.432368\n",
      "Total training time: 16.15 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 38.34, NNZs: 229, Bias: -1.735801, T: 3065040, Avg. loss: 0.432368\n",
      "Total training time: 16.33 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 38.34, NNZs: 229, Bias: -1.735804, T: 3100680, Avg. loss: 0.432368\n",
      "Total training time: 16.51 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 38.34, NNZs: 229, Bias: -1.735806, T: 3136320, Avg. loss: 0.432368\n",
      "Total training time: 16.69 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 38.34, NNZs: 229, Bias: -1.735812, T: 3171960, Avg. loss: 0.432368\n",
      "Total training time: 16.88 seconds.\n",
      "Convergence after 89 epochs took 16.88 seconds\n",
      "-- Epoch 1\n",
      "Norm: 196.68, NNZs: 268, Bias: -75.000000, T: 35640, Avg. loss: 8.522826\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 208.26, NNZs: 224, Bias: -85.000000, T: 71280, Avg. loss: 7.452120\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 234.98, NNZs: 202, Bias: -80.000000, T: 106920, Avg. loss: 6.621170\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 249.39, NNZs: 170, Bias: -65.000000, T: 142560, Avg. loss: 5.925966\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 266.86, NNZs: 167, Bias: -70.000000, T: 178200, Avg. loss: 5.355225\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 269.22, NNZs: 173, Bias: -60.000000, T: 213840, Avg. loss: 4.994941\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 248.38, NNZs: 158, Bias: -65.000000, T: 249480, Avg. loss: 4.834618\n",
      "Total training time: 1.31 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 267.74, NNZs: 150, Bias: -45.000000, T: 285120, Avg. loss: 4.493810\n",
      "Total training time: 1.49 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 277.34, NNZs: 154, Bias: -50.000000, T: 320760, Avg. loss: 4.040548\n",
      "Total training time: 1.66 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 288.10, NNZs: 143, Bias: -50.000000, T: 356400, Avg. loss: 3.933326\n",
      "Total training time: 1.83 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 314.00, NNZs: 137, Bias: -45.000000, T: 392040, Avg. loss: 3.905039\n",
      "Total training time: 1.99 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 262.54, NNZs: 134, Bias: -45.000000, T: 427680, Avg. loss: 3.773111\n",
      "Total training time: 2.18 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 288.48, NNZs: 151, Bias: -40.000000, T: 463320, Avg. loss: 3.626749\n",
      "Total training time: 2.36 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 277.89, NNZs: 147, Bias: -45.000000, T: 498960, Avg. loss: 3.848296\n",
      "Total training time: 2.52 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 292.13, NNZs: 143, Bias: -35.000000, T: 534600, Avg. loss: 3.902522\n",
      "Total training time: 2.69 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 301.70, NNZs: 133, Bias: -35.000000, T: 570240, Avg. loss: 3.617873\n",
      "Total training time: 2.87 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 304.49, NNZs: 147, Bias: -45.000000, T: 605880, Avg. loss: 3.677812\n",
      "Total training time: 3.03 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 284.58, NNZs: 116, Bias: -30.000000, T: 641520, Avg. loss: 3.491960\n",
      "Total training time: 3.20 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 298.45, NNZs: 130, Bias: -45.000000, T: 677160, Avg. loss: 3.545519\n",
      "Total training time: 3.37 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 318.98, NNZs: 144, Bias: -40.000000, T: 712800, Avg. loss: 3.386296\n",
      "Total training time: 3.53 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 320.41, NNZs: 128, Bias: -30.000000, T: 748440, Avg. loss: 3.283412\n",
      "Total training time: 3.69 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 266.44, NNZs: 132, Bias: -35.000000, T: 784080, Avg. loss: 3.273947\n",
      "Total training time: 3.86 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 310.23, NNZs: 125, Bias: -35.000000, T: 819720, Avg. loss: 3.473866\n",
      "Total training time: 4.03 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 307.00, NNZs: 133, Bias: -40.000000, T: 855360, Avg. loss: 3.290740\n",
      "Total training time: 4.19 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 300.36, NNZs: 130, Bias: -40.000000, T: 891000, Avg. loss: 3.203204\n",
      "Total training time: 4.35 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 315.26, NNZs: 129, Bias: -50.000000, T: 926640, Avg. loss: 3.272340\n",
      "Total training time: 4.51 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 309.27, NNZs: 126, Bias: -40.000000, T: 962280, Avg. loss: 3.170615\n",
      "Total training time: 4.68 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 267.62, NNZs: 135, Bias: -55.000000, T: 997920, Avg. loss: 3.480394\n",
      "Total training time: 4.84 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 294.61, NNZs: 126, Bias: -40.000000, T: 1033560, Avg. loss: 3.380373\n",
      "Total training time: 5.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 289.26, NNZs: 127, Bias: -45.000000, T: 1069200, Avg. loss: 3.511292\n",
      "Total training time: 5.18 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 294.80, NNZs: 136, Bias: -40.000000, T: 1104840, Avg. loss: 3.487012\n",
      "Total training time: 5.35 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 292.08, NNZs: 120, Bias: -35.000000, T: 1140480, Avg. loss: 3.329404\n",
      "Total training time: 5.51 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 142.87, NNZs: 113, Bias: -10.000000, T: 1176120, Avg. loss: 0.729599\n",
      "Total training time: 5.67 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 134.71, NNZs: 137, Bias: -13.000000, T: 1211760, Avg. loss: 0.724636\n",
      "Total training time: 5.84 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 134.98, NNZs: 141, Bias: -10.000000, T: 1247400, Avg. loss: 0.728364\n",
      "Total training time: 6.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 135.89, NNZs: 153, Bias: -11.000000, T: 1283040, Avg. loss: 0.783429\n",
      "Total training time: 6.16 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 133.10, NNZs: 145, Bias: -8.000000, T: 1318680, Avg. loss: 0.833688\n",
      "Total training time: 6.33 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 133.15, NNZs: 153, Bias: -8.000000, T: 1354320, Avg. loss: 0.831357\n",
      "Total training time: 6.50 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 132.75, NNZs: 165, Bias: -10.000000, T: 1389960, Avg. loss: 0.887177\n",
      "Total training time: 6.68 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 87.93, NNZs: 163, Bias: -3.800000, T: 1425600, Avg. loss: 0.325715\n",
      "Total training time: 6.86 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 70.08, NNZs: 176, Bias: -4.200000, T: 1461240, Avg. loss: 0.292197\n",
      "Total training time: 7.03 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 64.16, NNZs: 169, Bias: -3.600000, T: 1496880, Avg. loss: 0.295580\n",
      "Total training time: 7.20 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 61.46, NNZs: 170, Bias: -3.800000, T: 1532520, Avg. loss: 0.305124\n",
      "Total training time: 7.38 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 59.49, NNZs: 172, Bias: -4.000000, T: 1568160, Avg. loss: 0.319439\n",
      "Total training time: 7.55 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 59.14, NNZs: 173, Bias: -3.600000, T: 1603800, Avg. loss: 0.309280\n",
      "Total training time: 7.73 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 59.45, NNZs: 179, Bias: -3.800000, T: 1639440, Avg. loss: 0.306614\n",
      "Total training time: 7.91 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 53.76, NNZs: 181, Bias: -2.280000, T: 1675080, Avg. loss: 0.198830\n",
      "Total training time: 8.08 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 49.15, NNZs: 178, Bias: -2.280000, T: 1710720, Avg. loss: 0.187055\n",
      "Total training time: 8.26 seconds.\n",
      "-- Epoch 49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 45.25, NNZs: 189, Bias: -2.160000, T: 1746360, Avg. loss: 0.185622\n",
      "Total training time: 8.44 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 41.95, NNZs: 180, Bias: -1.920000, T: 1782000, Avg. loss: 0.185302\n",
      "Total training time: 8.60 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 39.15, NNZs: 189, Bias: -1.920000, T: 1817640, Avg. loss: 0.185801\n",
      "Total training time: 8.79 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 36.78, NNZs: 186, Bias: -2.000000, T: 1853280, Avg. loss: 0.186584\n",
      "Total training time: 8.96 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 34.86, NNZs: 187, Bias: -1.960000, T: 1888920, Avg. loss: 0.184928\n",
      "Total training time: 9.13 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 33.26, NNZs: 194, Bias: -1.880000, T: 1924560, Avg. loss: 0.186053\n",
      "Total training time: 9.31 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 32.50, NNZs: 186, Bias: -1.648000, T: 1960200, Avg. loss: 0.160898\n",
      "Total training time: 9.48 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 31.80, NNZs: 190, Bias: -1.496000, T: 1995840, Avg. loss: 0.156664\n",
      "Total training time: 9.68 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 31.14, NNZs: 193, Bias: -1.400000, T: 2031480, Avg. loss: 0.155178\n",
      "Total training time: 9.86 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 30.50, NNZs: 180, Bias: -1.376000, T: 2067120, Avg. loss: 0.154179\n",
      "Total training time: 10.03 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 29.89, NNZs: 182, Bias: -1.296000, T: 2102760, Avg. loss: 0.153535\n",
      "Total training time: 10.21 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 29.29, NNZs: 185, Bias: -1.264000, T: 2138400, Avg. loss: 0.153543\n",
      "Total training time: 10.38 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 28.71, NNZs: 176, Bias: -1.288000, T: 2174040, Avg. loss: 0.153021\n",
      "Total training time: 10.56 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 28.15, NNZs: 178, Bias: -1.232000, T: 2209680, Avg. loss: 0.153039\n",
      "Total training time: 10.74 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 28.01, NNZs: 183, Bias: -1.184000, T: 2245320, Avg. loss: 0.148205\n",
      "Total training time: 10.92 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 27.88, NNZs: 182, Bias: -1.158400, T: 2280960, Avg. loss: 0.147414\n",
      "Total training time: 11.09 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 27.75, NNZs: 183, Bias: -1.131200, T: 2316600, Avg. loss: 0.147107\n",
      "Total training time: 11.26 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 27.63, NNZs: 180, Bias: -1.116800, T: 2352240, Avg. loss: 0.146797\n",
      "Total training time: 11.44 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 27.50, NNZs: 181, Bias: -1.089600, T: 2387880, Avg. loss: 0.146712\n",
      "Total training time: 11.61 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 27.37, NNZs: 178, Bias: -1.076800, T: 2423520, Avg. loss: 0.146531\n",
      "Total training time: 11.78 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 27.35, NNZs: 187, Bias: -1.067840, T: 2459160, Avg. loss: 0.145657\n",
      "Total training time: 11.96 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 27.32, NNZs: 186, Bias: -1.061120, T: 2494800, Avg. loss: 0.145537\n",
      "Total training time: 12.12 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 27.29, NNZs: 181, Bias: -1.054400, T: 2530440, Avg. loss: 0.145456\n",
      "Total training time: 12.30 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 27.27, NNZs: 178, Bias: -1.048320, T: 2566080, Avg. loss: 0.145399\n",
      "Total training time: 12.48 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 27.24, NNZs: 178, Bias: -1.043200, T: 2601720, Avg. loss: 0.145348\n",
      "Total training time: 12.65 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 27.24, NNZs: 181, Bias: -1.041024, T: 2637360, Avg. loss: 0.145163\n",
      "Total training time: 12.82 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 27.23, NNZs: 182, Bias: -1.039488, T: 2673000, Avg. loss: 0.145140\n",
      "Total training time: 12.99 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 27.23, NNZs: 183, Bias: -1.038912, T: 2708640, Avg. loss: 0.145124\n",
      "Total training time: 13.18 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 27.22, NNZs: 180, Bias: -1.036544, T: 2744280, Avg. loss: 0.145112\n",
      "Total training time: 13.36 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 27.22, NNZs: 181, Bias: -1.035008, T: 2779920, Avg. loss: 0.145099\n",
      "Total training time: 13.53 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 27.22, NNZs: 183, Bias: -1.034560, T: 2815560, Avg. loss: 0.145061\n",
      "Total training time: 13.70 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 27.21, NNZs: 182, Bias: -1.034266, T: 2851200, Avg. loss: 0.145053\n",
      "Total training time: 13.87 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 27.21, NNZs: 184, Bias: -1.033933, T: 2886840, Avg. loss: 0.145051\n",
      "Total training time: 14.04 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 27.21, NNZs: 184, Bias: -1.033382, T: 2922480, Avg. loss: 0.145048\n",
      "Total training time: 14.20 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 27.21, NNZs: 183, Bias: -1.033280, T: 2958120, Avg. loss: 0.145045\n",
      "Total training time: 14.38 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 27.21, NNZs: 184, Bias: -1.033172, T: 2993760, Avg. loss: 0.145036\n",
      "Total training time: 14.54 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 27.21, NNZs: 184, Bias: -1.033078, T: 3029400, Avg. loss: 0.145035\n",
      "Total training time: 14.72 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 27.21, NNZs: 184, Bias: -1.032996, T: 3065040, Avg. loss: 0.145034\n",
      "Total training time: 14.89 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 27.21, NNZs: 184, Bias: -1.032957, T: 3100680, Avg. loss: 0.145033\n",
      "Total training time: 15.06 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 27.21, NNZs: 184, Bias: -1.032837, T: 3136320, Avg. loss: 0.145033\n",
      "Total training time: 15.22 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 27.21, NNZs: 184, Bias: -1.032849, T: 3171960, Avg. loss: 0.145031\n",
      "Total training time: 15.40 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 27.21, NNZs: 184, Bias: -1.032852, T: 3207600, Avg. loss: 0.145031\n",
      "Total training time: 15.57 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 27.21, NNZs: 184, Bias: -1.032847, T: 3243240, Avg. loss: 0.145031\n",
      "Total training time: 15.75 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 27.21, NNZs: 184, Bias: -1.032823, T: 3278880, Avg. loss: 0.145031\n",
      "Total training time: 15.92 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 27.21, NNZs: 184, Bias: -1.032813, T: 3314520, Avg. loss: 0.145031\n",
      "Total training time: 16.09 seconds.\n",
      "Convergence after 93 epochs took 16.09 seconds\n",
      "-- Epoch 1\n",
      "Norm: 301.79, NNZs: 299, Bias: 5.000000, T: 35640, Avg. loss: 24.985709\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 329.05, NNZs: 265, Bias: 10.000000, T: 71280, Avg. loss: 22.595261\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 355.04, NNZs: 227, Bias: -10.000000, T: 106920, Avg. loss: 20.357287\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 369.21, NNZs: 225, Bias: 5.000000, T: 142560, Avg. loss: 18.847005\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 386.93, NNZs: 210, Bias: 5.000000, T: 178200, Avg. loss: 17.485288\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 402.98, NNZs: 198, Bias: -10.000000, T: 213840, Avg. loss: 16.169626\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 436.82, NNZs: 173, Bias: -5.000000, T: 249480, Avg. loss: 15.552186\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 434.72, NNZs: 172, Bias: -5.000000, T: 285120, Avg. loss: 14.921064\n",
      "Total training time: 1.52 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 416.04, NNZs: 174, Bias: -10.000000, T: 320760, Avg. loss: 14.157677\n",
      "Total training time: 1.71 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 453.12, NNZs: 157, Bias: -5.000000, T: 356400, Avg. loss: 13.781250\n",
      "Total training time: 1.90 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 458.03, NNZs: 159, Bias: -5.000000, T: 392040, Avg. loss: 13.768626\n",
      "Total training time: 2.09 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 455.38, NNZs: 152, Bias: 0.000000, T: 427680, Avg. loss: 12.935090\n",
      "Total training time: 2.28 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 465.86, NNZs: 148, Bias: 20.000000, T: 463320, Avg. loss: 12.592625\n",
      "Total training time: 2.46 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 451.17, NNZs: 153, Bias: 5.000000, T: 498960, Avg. loss: 12.442427\n",
      "Total training time: 2.64 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 452.04, NNZs: 159, Bias: 15.000000, T: 534600, Avg. loss: 12.237598\n",
      "Total training time: 2.82 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 459.02, NNZs: 137, Bias: 5.000000, T: 570240, Avg. loss: 12.121293\n",
      "Total training time: 3.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 443.16, NNZs: 172, Bias: -15.000000, T: 605880, Avg. loss: 12.182572\n",
      "Total training time: 3.18 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 447.43, NNZs: 152, Bias: 5.000000, T: 641520, Avg. loss: 11.911162\n",
      "Total training time: 3.37 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 474.44, NNZs: 145, Bias: -5.000000, T: 677160, Avg. loss: 12.070913\n",
      "Total training time: 3.54 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 458.92, NNZs: 155, Bias: 5.000000, T: 712800, Avg. loss: 12.138139\n",
      "Total training time: 3.73 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 481.73, NNZs: 135, Bias: 5.000000, T: 748440, Avg. loss: 10.896289\n",
      "Total training time: 3.91 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 477.15, NNZs: 127, Bias: 5.000000, T: 784080, Avg. loss: 12.197740\n",
      "Total training time: 4.11 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 492.71, NNZs: 144, Bias: 20.000000, T: 819720, Avg. loss: 10.974683\n",
      "Total training time: 4.30 seconds.\n",
      "-- Epoch 24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 476.67, NNZs: 148, Bias: -5.000000, T: 855360, Avg. loss: 11.072155\n",
      "Total training time: 4.48 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 455.79, NNZs: 149, Bias: 20.000000, T: 891000, Avg. loss: 10.873231\n",
      "Total training time: 4.66 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 491.03, NNZs: 150, Bias: 15.000000, T: 926640, Avg. loss: 10.904174\n",
      "Total training time: 4.84 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 494.26, NNZs: 142, Bias: 0.000000, T: 962280, Avg. loss: 11.009833\n",
      "Total training time: 5.02 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 476.29, NNZs: 148, Bias: 0.000000, T: 997920, Avg. loss: 10.988815\n",
      "Total training time: 5.19 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 456.87, NNZs: 128, Bias: 0.000000, T: 1033560, Avg. loss: 11.179611\n",
      "Total training time: 5.38 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 468.76, NNZs: 139, Bias: 10.000000, T: 1069200, Avg. loss: 11.092193\n",
      "Total training time: 5.55 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 213.78, NNZs: 136, Bias: 2.000000, T: 1104840, Avg. loss: 2.560724\n",
      "Total training time: 5.72 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 209.85, NNZs: 149, Bias: 0.000000, T: 1140480, Avg. loss: 2.643674\n",
      "Total training time: 5.89 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 211.17, NNZs: 160, Bias: 2.000000, T: 1176120, Avg. loss: 2.733742\n",
      "Total training time: 6.07 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 207.21, NNZs: 174, Bias: 1.000000, T: 1211760, Avg. loss: 2.643266\n",
      "Total training time: 6.25 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 204.61, NNZs: 167, Bias: 3.000000, T: 1247400, Avg. loss: 2.894450\n",
      "Total training time: 6.43 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 203.88, NNZs: 160, Bias: 3.000000, T: 1283040, Avg. loss: 2.792933\n",
      "Total training time: 6.60 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 136.50, NNZs: 166, Bias: 1.600000, T: 1318680, Avg. loss: 1.021794\n",
      "Total training time: 6.78 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 109.32, NNZs: 177, Bias: 0.200000, T: 1354320, Avg. loss: 0.984139\n",
      "Total training time: 6.96 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 99.28, NNZs: 194, Bias: 1.200000, T: 1389960, Avg. loss: 0.984037\n",
      "Total training time: 7.15 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 95.07, NNZs: 187, Bias: 1.200000, T: 1425600, Avg. loss: 1.009129\n",
      "Total training time: 7.35 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 92.93, NNZs: 193, Bias: 1.200000, T: 1461240, Avg. loss: 1.017393\n",
      "Total training time: 7.52 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 91.50, NNZs: 190, Bias: 0.800000, T: 1496880, Avg. loss: 1.046631\n",
      "Total training time: 7.71 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 92.14, NNZs: 189, Bias: 1.400000, T: 1532520, Avg. loss: 1.028113\n",
      "Total training time: 7.90 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 83.22, NNZs: 198, Bias: 0.800000, T: 1568160, Avg. loss: 0.649716\n",
      "Total training time: 8.09 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 76.27, NNZs: 206, Bias: 0.880000, T: 1603800, Avg. loss: 0.628644\n",
      "Total training time: 8.28 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 70.31, NNZs: 207, Bias: 0.760000, T: 1639440, Avg. loss: 0.630329\n",
      "Total training time: 8.47 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 65.29, NNZs: 207, Bias: 0.880000, T: 1675080, Avg. loss: 0.629806\n",
      "Total training time: 8.66 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 60.87, NNZs: 209, Bias: 0.800000, T: 1710720, Avg. loss: 0.636403\n",
      "Total training time: 8.85 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 57.17, NNZs: 211, Bias: 0.880000, T: 1746360, Avg. loss: 0.639066\n",
      "Total training time: 9.03 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 54.08, NNZs: 210, Bias: 0.840000, T: 1782000, Avg. loss: 0.634027\n",
      "Total training time: 9.22 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 52.83, NNZs: 225, Bias: 0.800000, T: 1817640, Avg. loss: 0.549229\n",
      "Total training time: 9.40 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 51.68, NNZs: 226, Bias: 0.736000, T: 1853280, Avg. loss: 0.545187\n",
      "Total training time: 9.60 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 50.58, NNZs: 227, Bias: 0.656000, T: 1888920, Avg. loss: 0.545105\n",
      "Total training time: 9.79 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 49.52, NNZs: 228, Bias: 0.624000, T: 1924560, Avg. loss: 0.545818\n",
      "Total training time: 9.96 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 48.48, NNZs: 225, Bias: 0.616000, T: 1960200, Avg. loss: 0.545692\n",
      "Total training time: 10.15 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 47.48, NNZs: 228, Bias: 0.600000, T: 1995840, Avg. loss: 0.544349\n",
      "Total training time: 10.35 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 46.51, NNZs: 225, Bias: 0.624000, T: 2031480, Avg. loss: 0.544707\n",
      "Total training time: 10.53 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 46.28, NNZs: 227, Bias: 0.630400, T: 2067120, Avg. loss: 0.524273\n",
      "Total training time: 10.72 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 46.06, NNZs: 228, Bias: 0.609600, T: 2102760, Avg. loss: 0.522969\n",
      "Total training time: 10.91 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 45.84, NNZs: 227, Bias: 0.593600, T: 2138400, Avg. loss: 0.522939\n",
      "Total training time: 11.09 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 45.63, NNZs: 228, Bias: 0.585600, T: 2174040, Avg. loss: 0.522823\n",
      "Total training time: 11.28 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 45.41, NNZs: 227, Bias: 0.587200, T: 2209680, Avg. loss: 0.522595\n",
      "Total training time: 11.47 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 45.20, NNZs: 227, Bias: 0.580800, T: 2245320, Avg. loss: 0.522430\n",
      "Total training time: 11.66 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 44.99, NNZs: 228, Bias: 0.572800, T: 2280960, Avg. loss: 0.522261\n",
      "Total training time: 11.85 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 44.95, NNZs: 228, Bias: 0.560320, T: 2316600, Avg. loss: 0.517937\n",
      "Total training time: 12.04 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 44.91, NNZs: 228, Bias: 0.573120, T: 2352240, Avg. loss: 0.517460\n",
      "Total training time: 12.24 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 44.86, NNZs: 227, Bias: 0.555840, T: 2387880, Avg. loss: 0.517203\n",
      "Total training time: 12.43 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 44.82, NNZs: 228, Bias: 0.565120, T: 2423520, Avg. loss: 0.517404\n",
      "Total training time: 12.61 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 44.78, NNZs: 227, Bias: 0.549760, T: 2459160, Avg. loss: 0.517382\n",
      "Total training time: 12.80 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 44.73, NNZs: 227, Bias: 0.554240, T: 2494800, Avg. loss: 0.517481\n",
      "Total training time: 12.99 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 44.73, NNZs: 227, Bias: 0.555712, T: 2530440, Avg. loss: 0.516438\n",
      "Total training time: 13.19 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 44.72, NNZs: 227, Bias: 0.555072, T: 2566080, Avg. loss: 0.516315\n",
      "Total training time: 13.39 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 44.71, NNZs: 227, Bias: 0.555840, T: 2601720, Avg. loss: 0.516287\n",
      "Total training time: 13.58 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 44.70, NNZs: 227, Bias: 0.558656, T: 2637360, Avg. loss: 0.516223\n",
      "Total training time: 13.78 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 44.69, NNZs: 227, Bias: 0.552576, T: 2673000, Avg. loss: 0.516227\n",
      "Total training time: 13.96 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 44.69, NNZs: 227, Bias: 0.554854, T: 2708640, Avg. loss: 0.516006\n",
      "Total training time: 14.15 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 44.69, NNZs: 227, Bias: 0.554483, T: 2744280, Avg. loss: 0.515992\n",
      "Total training time: 14.35 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 44.69, NNZs: 227, Bias: 0.554944, T: 2779920, Avg. loss: 0.515978\n",
      "Total training time: 14.53 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 44.69, NNZs: 227, Bias: 0.554739, T: 2815560, Avg. loss: 0.515980\n",
      "Total training time: 14.72 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 44.68, NNZs: 227, Bias: 0.554150, T: 2851200, Avg. loss: 0.515978\n",
      "Total training time: 14.92 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 44.68, NNZs: 227, Bias: 0.554255, T: 2886840, Avg. loss: 0.515920\n",
      "Total training time: 15.10 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 44.68, NNZs: 227, Bias: 0.554307, T: 2922480, Avg. loss: 0.515918\n",
      "Total training time: 15.29 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 44.68, NNZs: 227, Bias: 0.554314, T: 2958120, Avg. loss: 0.515918\n",
      "Total training time: 15.49 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 44.68, NNZs: 227, Bias: 0.554319, T: 2993760, Avg. loss: 0.515918\n",
      "Total training time: 15.68 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 44.68, NNZs: 227, Bias: 0.554332, T: 3029400, Avg. loss: 0.515917\n",
      "Total training time: 15.87 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 44.68, NNZs: 227, Bias: 0.554330, T: 3065040, Avg. loss: 0.515904\n",
      "Total training time: 16.05 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 44.68, NNZs: 227, Bias: 0.554325, T: 3100680, Avg. loss: 0.515904\n",
      "Total training time: 16.25 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 44.68, NNZs: 227, Bias: 0.554316, T: 3136320, Avg. loss: 0.515903\n",
      "Total training time: 16.43 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 44.68, NNZs: 227, Bias: 0.554307, T: 3171960, Avg. loss: 0.515903\n",
      "Total training time: 16.62 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 44.68, NNZs: 227, Bias: 0.554295, T: 3207600, Avg. loss: 0.515903\n",
      "Total training time: 16.82 seconds.\n",
      "Convergence after 90 epochs took 16.82 seconds\n",
      "[0.75342312 0.74747475 0.74567901 0.75151515 0.74646465]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   49.7s finished\n"
     ]
    }
   ],
   "source": [
    "#Confirm generalizability with 5 fold cross validation\n",
    "print(cross_val_score(sgd_adapt, train_X, train_y, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output for comparision\n",
    "sgd_deets.to_pickle('Data/scores/SGD.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pumpitup",
   "language": "python",
   "name": "pumpitup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
