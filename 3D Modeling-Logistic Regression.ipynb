{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in standard packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in ML packages/modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bwils\\anaconda3\\envs\\pumpitup\\lib\\site-packages\\distributed\\node.py:151: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 62785 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Scheduler: \"tcp://127.0.0.1:62788\" processes: 3 cores: 6>,\n",
       " {0: <Nanny: tcp://127.0.0.1:62813, threads: 2>,\n",
       "  1: <Nanny: tcp://127.0.0.1:62807, threads: 2>,\n",
       "  2: <Nanny: tcp://127.0.0.1:62810, threads: 2>})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in dask package and set up to allow for faster compute times. Distributes computing among all availabel preocessors\n",
    "from dask import dataframe as dd\n",
    "import joblib\n",
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "cluster.scheduler, cluster.workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in training/testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in train/test data\n",
    "train_X = pd.read_pickle('Data/train_test/train_X.pkl')\n",
    "test_X = pd.read_pickle('Data/train_test/test_X.pkl')\n",
    "train_y = pd.read_pickle('Data/train_test/train_y.pkl')\n",
    "test_y = pd.read_pickle('Data/train_test/test_y.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend DaskDistributedBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   23.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7520538720538721"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's try an out of the box Logisitic Regression\n",
    "logi = LogisticRegression(verbose=True)\n",
    "with joblib.parallel_backend('dask'):\n",
    "    logi.fit(train_X, np.ravel(train_y))\n",
    "logi.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not terrible. We can make some adjustments to the hyperparameters to see if they increases our accuracy. We'll save the score and parameters for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>C</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>dual</th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>intercept_scaling</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>multi_class</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>penalty</th>\n",
       "      <th>random_state</th>\n",
       "      <th>solver</th>\n",
       "      <th>tol</th>\n",
       "      <th>verbose</th>\n",
       "      <th>warm_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR_OBO</th>\n",
       "      <td>0.752054</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy    C class_weight   dual  fit_intercept  intercept_scaling  \\\n",
       "LR_OBO  0.752054  1.0         None  False           True                  1   \n",
       "\n",
       "       l1_ratio  max_iter multi_class n_jobs penalty random_state solver  \\\n",
       "LR_OBO     None       100        auto   None      l2         None  lbfgs   \n",
       "\n",
       "           tol  verbose  warm_start  \n",
       "LR_OBO  0.0001     True       False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dataframe to store metrics and parameters\n",
    "logi_deets = pd.DataFrame(logi.get_params(), index=['LR_OBO'])\n",
    "logi_deets.insert(0, value=logi.score(test_X, test_y), column='Accuracy')\n",
    "logi_deets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend DaskDistributedBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   25.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.657979797979798"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First let's see if we do better with balanced class weights\n",
    "logi_2 = LogisticRegression(class_weight='balanced', verbose=True)\n",
    "with joblib.parallel_backend('dask'):\n",
    "    logi_2.fit(train_X, np.ravel(train_y))\n",
    "logi_2.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>C</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>dual</th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>intercept_scaling</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>multi_class</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>penalty</th>\n",
       "      <th>random_state</th>\n",
       "      <th>solver</th>\n",
       "      <th>tol</th>\n",
       "      <th>verbose</th>\n",
       "      <th>warm_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR_OBO</th>\n",
       "      <td>0.752054</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_BAL</th>\n",
       "      <td>0.657980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy    C class_weight   dual  fit_intercept  intercept_scaling  \\\n",
       "LR_OBO  0.752054  1.0         None  False           True                  1   \n",
       "LR_BAL  0.657980  1.0     balanced  False           True                  1   \n",
       "\n",
       "       l1_ratio  max_iter multi_class n_jobs penalty random_state solver  \\\n",
       "LR_OBO     None       100        auto   None      l2         None  lbfgs   \n",
       "LR_BAL     None       100        auto   None      l2         None  lbfgs   \n",
       "\n",
       "           tol  verbose  warm_start  \n",
       "LR_OBO  0.0001     True       False  \n",
       "LR_BAL  0.0001     True       False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#store metrics and parameters\n",
    "a = logi_2.get_params()\n",
    "a['Accuracy'] = logi_2.score(test_X, test_y)\n",
    "logi_deets = pd.concat([logi_deets, pd.DataFrame(a, index=['LR_BAL'])], axis=0, join='outer')\n",
    "logi_deets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using class weights does not improve the accuracy, in fact it decreases it. Let's try each of the penalty options for improvement and some different values for C for each. We will need to use the liblinear solver to access the L1 penalty option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    }
   ],
   "source": [
    "#Run through for loop for hyperparamter tuning of C and penalty\n",
    "C = [0.1, 0.5, 1, 5, 10]\n",
    "penalty = ['l1', 'l2']\n",
    "count=1\n",
    "for p in penalty:\n",
    "    for c in C:\n",
    "        logi_pen = LogisticRegression(solver='liblinear', C=c, penalty=p, verbose=True)\n",
    "        logi_pen.fit(train_X, np.ravel(train_y))\n",
    "        deets = logi_pen.get_params()\n",
    "        deets['Accuracy']=logi_pen.score(test_X, test_y)\n",
    "        logi_deets = pd.concat([logi_deets, pd.DataFrame(deets, index=['LR_PEN{}'.format(count)])], axis=0, join='outer')\n",
    "        count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>C</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>dual</th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>intercept_scaling</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>multi_class</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>penalty</th>\n",
       "      <th>random_state</th>\n",
       "      <th>solver</th>\n",
       "      <th>tol</th>\n",
       "      <th>verbose</th>\n",
       "      <th>warm_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR_OBO</th>\n",
       "      <td>0.752054</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_BAL</th>\n",
       "      <td>0.657980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_PEN1</th>\n",
       "      <td>0.749428</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_PEN2</th>\n",
       "      <td>0.752997</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_PEN3</th>\n",
       "      <td>0.752727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_PEN4</th>\n",
       "      <td>0.753535</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_PEN5</th>\n",
       "      <td>0.753333</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_PEN6</th>\n",
       "      <td>0.753199</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_PEN7</th>\n",
       "      <td>0.753199</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_PEN8</th>\n",
       "      <td>0.752121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_PEN9</th>\n",
       "      <td>0.753266</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_PEN10</th>\n",
       "      <td>0.753468</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Accuracy     C class_weight   dual  fit_intercept  \\\n",
       "LR_OBO    0.752054   1.0         None  False           True   \n",
       "LR_BAL    0.657980   1.0     balanced  False           True   \n",
       "LR_PEN1   0.749428   0.1         None  False           True   \n",
       "LR_PEN2   0.752997   0.5         None  False           True   \n",
       "LR_PEN3   0.752727   1.0         None  False           True   \n",
       "LR_PEN4   0.753535   5.0         None  False           True   \n",
       "LR_PEN5   0.753333  10.0         None  False           True   \n",
       "LR_PEN6   0.753199   0.1         None  False           True   \n",
       "LR_PEN7   0.753199   0.5         None  False           True   \n",
       "LR_PEN8   0.752121   1.0         None  False           True   \n",
       "LR_PEN9   0.753266   5.0         None  False           True   \n",
       "LR_PEN10  0.753468  10.0         None  False           True   \n",
       "\n",
       "          intercept_scaling l1_ratio  max_iter multi_class n_jobs penalty  \\\n",
       "LR_OBO                    1     None       100        auto   None      l2   \n",
       "LR_BAL                    1     None       100        auto   None      l2   \n",
       "LR_PEN1                   1     None       100        auto   None      l1   \n",
       "LR_PEN2                   1     None       100        auto   None      l1   \n",
       "LR_PEN3                   1     None       100        auto   None      l1   \n",
       "LR_PEN4                   1     None       100        auto   None      l1   \n",
       "LR_PEN5                   1     None       100        auto   None      l1   \n",
       "LR_PEN6                   1     None       100        auto   None      l2   \n",
       "LR_PEN7                   1     None       100        auto   None      l2   \n",
       "LR_PEN8                   1     None       100        auto   None      l2   \n",
       "LR_PEN9                   1     None       100        auto   None      l2   \n",
       "LR_PEN10                  1     None       100        auto   None      l2   \n",
       "\n",
       "         random_state     solver     tol  verbose  warm_start  \n",
       "LR_OBO           None      lbfgs  0.0001     True       False  \n",
       "LR_BAL           None      lbfgs  0.0001     True       False  \n",
       "LR_PEN1          None  liblinear  0.0001     True       False  \n",
       "LR_PEN2          None  liblinear  0.0001     True       False  \n",
       "LR_PEN3          None  liblinear  0.0001     True       False  \n",
       "LR_PEN4          None  liblinear  0.0001     True       False  \n",
       "LR_PEN5          None  liblinear  0.0001     True       False  \n",
       "LR_PEN6          None  liblinear  0.0001     True       False  \n",
       "LR_PEN7          None  liblinear  0.0001     True       False  \n",
       "LR_PEN8          None  liblinear  0.0001     True       False  \n",
       "LR_PEN9          None  liblinear  0.0001     True       False  \n",
       "LR_PEN10         None  liblinear  0.0001     True       False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logi_deets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adjustments to the penalty and regularization strength show that, though slight, a higher regularization strength increases the accuracy and that the L2 penalty also perfomrs better than L1.\n",
    "\n",
    "As a final check we will increase the number of iterations the model is allowed to run through for minimzation and run through a cross validation check to make sure we are still abel to generalize well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7534680134680135"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run model with more iterations to see if we can improve accuracy\n",
    "logi_iter = LogisticRegression(penalty='l2', C=10, max_iter=250, verbose=True, solver='liblinear')\n",
    "logi_iter.fit(train_X, np.ravel(train_y))\n",
    "logi_iter.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No great improvement, we will stick with the default 100 iterations max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>C</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>dual</th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>intercept_scaling</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>multi_class</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>penalty</th>\n",
       "      <th>random_state</th>\n",
       "      <th>solver</th>\n",
       "      <th>tol</th>\n",
       "      <th>verbose</th>\n",
       "      <th>warm_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR_OBO</th>\n",
       "      <td>0.752054</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_BAL</th>\n",
       "      <td>0.657980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_PEN1</th>\n",
       "      <td>0.749428</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_PEN2</th>\n",
       "      <td>0.752997</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_PEN3</th>\n",
       "      <td>0.752727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_PEN4</th>\n",
       "      <td>0.753535</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_PEN5</th>\n",
       "      <td>0.753333</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l1</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_PEN6</th>\n",
       "      <td>0.753199</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_PEN7</th>\n",
       "      <td>0.753199</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_PEN8</th>\n",
       "      <td>0.752121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_PEN9</th>\n",
       "      <td>0.753266</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_PEN10</th>\n",
       "      <td>0.753468</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_ITER_250</th>\n",
       "      <td>0.753468</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>250</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy     C class_weight   dual  fit_intercept  \\\n",
       "LR_OBO       0.752054   1.0         None  False           True   \n",
       "LR_BAL       0.657980   1.0     balanced  False           True   \n",
       "LR_PEN1      0.749428   0.1         None  False           True   \n",
       "LR_PEN2      0.752997   0.5         None  False           True   \n",
       "LR_PEN3      0.752727   1.0         None  False           True   \n",
       "LR_PEN4      0.753535   5.0         None  False           True   \n",
       "LR_PEN5      0.753333  10.0         None  False           True   \n",
       "LR_PEN6      0.753199   0.1         None  False           True   \n",
       "LR_PEN7      0.753199   0.5         None  False           True   \n",
       "LR_PEN8      0.752121   1.0         None  False           True   \n",
       "LR_PEN9      0.753266   5.0         None  False           True   \n",
       "LR_PEN10     0.753468  10.0         None  False           True   \n",
       "LR_ITER_250  0.753468  10.0         None  False           True   \n",
       "\n",
       "             intercept_scaling l1_ratio  max_iter multi_class n_jobs penalty  \\\n",
       "LR_OBO                       1     None       100        auto   None      l2   \n",
       "LR_BAL                       1     None       100        auto   None      l2   \n",
       "LR_PEN1                      1     None       100        auto   None      l1   \n",
       "LR_PEN2                      1     None       100        auto   None      l1   \n",
       "LR_PEN3                      1     None       100        auto   None      l1   \n",
       "LR_PEN4                      1     None       100        auto   None      l1   \n",
       "LR_PEN5                      1     None       100        auto   None      l1   \n",
       "LR_PEN6                      1     None       100        auto   None      l2   \n",
       "LR_PEN7                      1     None       100        auto   None      l2   \n",
       "LR_PEN8                      1     None       100        auto   None      l2   \n",
       "LR_PEN9                      1     None       100        auto   None      l2   \n",
       "LR_PEN10                     1     None       100        auto   None      l2   \n",
       "LR_ITER_250                  1     None       250        auto   None      l2   \n",
       "\n",
       "            random_state     solver     tol  verbose  warm_start  \n",
       "LR_OBO              None      lbfgs  0.0001     True       False  \n",
       "LR_BAL              None      lbfgs  0.0001     True       False  \n",
       "LR_PEN1             None  liblinear  0.0001     True       False  \n",
       "LR_PEN2             None  liblinear  0.0001     True       False  \n",
       "LR_PEN3             None  liblinear  0.0001     True       False  \n",
       "LR_PEN4             None  liblinear  0.0001     True       False  \n",
       "LR_PEN5             None  liblinear  0.0001     True       False  \n",
       "LR_PEN6             None  liblinear  0.0001     True       False  \n",
       "LR_PEN7             None  liblinear  0.0001     True       False  \n",
       "LR_PEN8             None  liblinear  0.0001     True       False  \n",
       "LR_PEN9             None  liblinear  0.0001     True       False  \n",
       "LR_PEN10            None  liblinear  0.0001     True       False  \n",
       "LR_ITER_250         None  liblinear  0.0001     True       False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = logi_iter.get_params()\n",
    "a['Accuracy'] = logi_iter.score(test_X, test_y)\n",
    "logi_deets = pd.concat([logi_deets, pd.DataFrame(a, index=['LR_ITER_250'])], axis=0, join='outer')\n",
    "logi_deets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7534680134680135"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Re-run best model\n",
    "logi_f = LogisticRegression(penalty='l2', C=10, verbose=True, solver='liblinear')\n",
    "logi_f.fit(train_X, np.ravel(train_y))\n",
    "logi_f.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][0.75544332 0.75521886 0.75140292 0.75611672 0.74994388]\n"
     ]
    }
   ],
   "source": [
    "#Confirm generalizability via 5-fold cross validation\n",
    "print(cross_val_score(logi_f, train_X, train_y, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation shows a pretty consistent result. We can be confident that this model will generally relativeley well. Let's take a look at a Confusion matrix to see which classes our best Logistic Regression model is doing best with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.74      0.89      0.81      8098\n",
      "functional needs repair       0.55      0.13      0.21      1074\n",
      "         non functional       0.79      0.68      0.73      5678\n",
      "\n",
      "               accuracy                           0.75     14850\n",
      "              macro avg       0.69      0.57      0.58     14850\n",
      "           weighted avg       0.74      0.75      0.73     14850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Visual class metrics using confusion matrix and classification report\n",
    "y_pred = logi_f.predict(test_X)\n",
    "cm=confusion_matrix(test_y, y_pred, labels=logi_f.classes_)\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=logi_f.classes_)\n",
    "plt.figure(figsize=(40,8))\n",
    "disp.plot()\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "print(classification_report(test_y, y_pred, labels=logi_f.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model performed best on the functional label with non functional just behind it and functional needs repair well below the other two. This makes sense as there are many less cases of functional needs repair so the model doesn't have as much data to learn from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output for comparision\n",
    "logi_deets.to_pickle('Data/scores/LR.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pumpitup",
   "language": "python",
   "name": "pumpitup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
